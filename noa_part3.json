{
  "bundle": {
    "name": "noa-cecca-stemcell-bundle-part3",
    "version": "P3",
    "created": "2025-09-16T00:00:00Z",
    "style": "kernel-first • message-passing • async-only • no-globals • zero-bloat",
    "entry": "kernel/bootstrap",
    "modules": {
      "docs/3-plane-knowledge-cluster-pipeline.txt": {
        "language": "text",
        "code": "Here’s the blueprint—clean, automatic, and ruthless about safety.\n\n# What you’re building (plain English)\n\nArk-AI-NOA grows its own capabilities through a **three-plane pipeline**:\n\n1. a **Sandbox/Research Cluster** that ingests and experiments in isolation,\n2. a **Coordinator (Control) Cluster** that evaluates, scores, and decides promotion, and\n3. the **Deployed NOA App Cluster** that runs your live agents.\n   The whole thing is **automatic**: new “capability packs” are discovered, digested, tested, constitution-checked, canaried, and—if they clear the bar—promoted to prod with rollbacks on rails.\n\n---\n\n# High-level architecture\n\n```mermaid\ngraph TD\n  subgraph SANDBOX / RESEARCH\n    D[Sources: repos, models, drivers,\\nplugins, datasets] --> I[Ingestor]\n    I --> S[Sandbox Runners (ephemeral)]\n    S --> G[SBOM & Capability Graph Builder]\n    S --> T[Test Benches: unit/integration/soak]\n    S --> R[Risk & License Analyzer]\n  end\n\n  subgraph COORDINATOR (CONTROL PLANE)\n    G --> C[Capability Registry]\n    T --> SC[Scorecards (perf/cost/safety)]\n    R --> SC\n    C --> P[Promotion Controller]\n    SC --> P\n    P --> J[[Trifecta-Court\\nConstitutional Pack]]\n  end\n\n  subgraph DEPLOYED NOA APP\n    P --> K[Canary Release]\n    K --> M[Monitoring & SLOs]\n    M -->|OK| PRO[Production Rollout]\n    M -->|Degrade| RB[Auto Rollback]\n  end\n\n  J --> P\n  PRO --> Tele[Telemetry → Feedback]\n  Tele --> C\n```\n\n**Principles**\n\n* **Local-first & zero-trust:** everything is signed, content-addressed, and reproducible.\n* **No DinD:** heavy lifting uses host/outer-plane tooling (BuildKit/containerd/systemd); sandboxes are VM/namespace isolated.\n* **Air-gappable:** Promotion can run fully offline with pre-staged artifacts.\n* **One command, full pipeline:** goals → actions → artifacts with audit trails and restore points.\n\n---\n\n# What is a “Capability Pack”?\n\nA capability is anything new NOA might learn or adopt: a tool/agent/plugin, a model, a driver/toolchain version, a dataset, or a micro-agent stack. Every capability ships as a **signed pack**:\n\n```yaml\nkind: Capability\napiVersion: noa/v1\nmetadata:\n  id: \"browser.automation.headless.v3\"\n  type: tool|agent|model|driver|dataset|stack\nspec:\n  purpose: \"Hardened browser automation profile with devtools\"\n  inputs: [ \"HTTP\", \"Auth profile\", \"Headless binary\" ]\n  outputs: [ \"HAR\", \"Screenshots\", \"DOM traces\" ]\n  deps: { os: [\"win11\",\"ubuntu22\"], gpu: [\"nvidia>=535\"], net: [\"egress-allowlist\"] }\n  risks: { privacy: \"low\", supply_chain: \"medium\", license: \"permissive\" }\n  tests:\n    unit: [\"startup.spec\", \"policy.spec\"]\n    integration: [\"site-login.spec\", \"anti-bot.spec\"]\n    soak: { duration: \"2h\", error_budget: \"0.5%\" }\n  rollout:\n    canary: { cohort: \"5%\", time: \"1h\", abort_on: { p95_latency_ms: \">+15%\", fail_rate: \">1%\" } }\n  budgets: { monthly_cost_usd: 50, vram_gb: 4, iops: 20k }\n  observability: { logs: true, traces: true, redaction: \"PII-by-default\" }\nsignature:\n  sha256: \"…\"\n  issuer: \"NOA-CA\"\n```\n\n---\n\n# Automatic lifecycle (end-to-end)\n\n```mermaid\nsequenceDiagram\n  participant Src as Source\n  participant SBX as Sandbox\n  participant CTRL as Coordinator\n  participant COURT as Trifecta-Court\n  participant PROD as NOA App\n\n  Src->>SBX: Discover/Clone (drivers, models, tools, datasets)\n  SBX->>SBX: Build & Isolate (ephemeral VM/namespace, sealed secrets)\n  SBX->>SBX: Run tests (unit → integration → soak)\n  SBX->>CTRL: Publish SBOM, risk profile, scorecard\n  CTRL->>COURT: Constitutional checks (policy/safety/license)\n  COURT-->>CTRL: Verdict (approve/deny/conditional)\n  CTRL->>PROD: Canary (5% cohort, feature-flagged)\n  PROD->>CTRL: Telemetry (SLOs, regressions)\n  alt OK\n    CTRL->>PROD: Promote to 100% + persist Capability Graph\n  else Degrade\n    CTRL->>PROD: Auto-rollback + incident note\n  end\n  PROD->>CTRL: Feedback loop → future model/tool choices\n```\n\n**What’s automatic**\n\n* Drift detectors wake the pipeline (new version found, SBOM delta, failing SLO, cost spike).\n* Sandbox assembles exact dependency tuples (**host-aware**, no DinD), generates SBOM, and runs benches.\n* Scorecards and constitutional checks run without prompting.\n* Promotion and rollback follow **predeclared abort conditions**—no heroics.\n\n---\n\n# How the **Trifecta-Court** fits\n\nThink of it as a constitutional governor with three levers:\n\n* **Executive (NOA ExecutiveCommander)** — proposes and executes; can issue **limited emergency hotfixes** under strict time/scope.\n* **Legislative (Board Agents)** — define policy: safety bars, cost ceilings, license allowlists/denylists, and promotion windows.\n* **Judicial (Court engine)** — enforces the constitution automatically:\n\n  * static checks: licenses, provenance, supply chain, data residency, RBAC\n  * dynamic checks: red-team prompts, fail-closed egress, privacy redaction, jailbreak resistance\n  * **veto/approve/conditional** outcomes; programmable overrides with quorum rules.\n\n**Override math (example):** Court veto requires **2/3 Legislative quorum** to override; emergency hotfix must pass **post-facto Court review** within 24h or is auto-reverted.\n\n---\n\n# Coordinator (Control Plane) responsibilities\n\n* **Capability Registry** (content-addressed): versions, provenance, and compatibility matrix per OS/GPU/driver.\n* **Promotion Controller:** interprets **PromotionPolicy**:\n\n  * risk tiering → which tests to run/how long to soak\n  * **canary/config**: cohorts, flags, kill-switches\n  * **budget bars**: cost, VRAM, IOPS, latency\n  * **time windows**: maintenance vs business hours\n* **Model/Tool Selection feedback:** updates selector priors from real telemetry (accuracy/latency/cost/safety).\n\n**PromotionPolicy sketch**\n\n```yaml\napiVersion: noa/v1\nkind: PromotionPolicy\nspec:\n  tiers:\n    low:  { tests: [\"unit\",\"short-integration\"], canary: {cohort: \"10%\", time: \"30m\"} }\n    med:  { tests: [\"unit\",\"integration\",\"soak:1h\"], canary: {cohort:\"5%\", time:\"2h\"} }\n    high: { tests: [\"unit\",\"integration\",\"soak:4h\",\"redteam\"], canary: {cohort:\"2%\", time:\"24h\"} }\n  gates:\n    p95_latency_ms: \"+10% max\"\n    fail_rate: \"≤0.5%\"\n    cost_delta: \"≤+5%\"\n    safety_events: \"0\"\n  court_required: [\"driver\",\"model\",\"dataset-high-risk\"]\n  rollback_on: [\"gate_breach\",\"court_revocation\",\"SLA_page\"]\n```\n\n---\n\n# Sandbox/Research Cluster (how it stays safe yet useful)\n\n* **Isolation first:** per-capability ephemeral VM or container namespace; **outer-plane** runners; no shared creds; network egress is **default-deny**.\n* **Host-aware prep:** detects OS/GPU/IOPS and stages exact driver/toolkit tuples; warms datasets/models on fast NVMe; creates restore snapshots.\n* **Evidence factory:** emits SBOM, test logs, traces, perf/cost telemetry, and a **Capability Graph** delta (what this capability provides, depends on, or conflicts with).\n\n---\n\n# Deployed App Cluster (how it stays stable)\n\n* **Feature flags + cohorts** for canary; real-time kill-switch.\n* **Error budgets** govern pace: if SLOs are hot, promotions slow/freeze.\n* **Policy as code** in the same repo as capabilities—**the court executes code, not vibes**.\n* **Autonomous rollback** when any gate breaches (no waiting for humans).\n\n---\n\n# Data & secrets flow (boring but critical)\n\n* All artifacts are **signed**; only **allow-list** endpoints reachable.\n* Secrets sealed to platform HSM/TPM/DPAPI; short-lived tokens per sandbox.\n* PII redaction at **ingest**; only synthetic data in tests unless explicitly allowed by policy.\n* Every run produces a **provenance bundle**: inputs, decisions, outputs, hashes.\n\n---\n\n# Example: adding a new browser-automation agent\n\n1. **Ingest:** Clone tools + headless binary; build hardened profile pack.\n2. **Sandbox:** Unit tests (launch, policy); integration (login flow); soak (2h); outputs HAR/screenshots.\n3. **Scorecard:** p95 < +10%, fail rate < 0.5%, cost within budget.\n4. **Court:** License OK, egress rules enforced, red-team passes.\n5. **Canary:** 5% of tasks; auto-rollback on regression; else promote to 100%.\n6. **Feedback:** Selector learns this agent is better for auth-heavy pages; updates routing.\n\n---\n\n# Simple operator mental model\n\n* **You** write goals.\n* **Sandbox** proves the capability safely.\n* **Coordinator** decides based on policy + data.\n* **Court** guarantees you didn’t violate your own constitution.\n* **NOA** rolls forward or back **by itself**.\n\n---\n\n# Implementation checklist (copy-ready)\n\n* Define **Capability** + **PromotionPolicy** CRDs (YAML as above).\n* Stand up: **Registry**, **Promotion Controller**, **Trifecta-Court** (policy engine with static+dynamic checks).\n* Wire **drift watchers**: SBOM delta, version feeds, SLO guardrails, cost monitors.\n* Provision **Sandbox runners** (ephemeral VM/pod with default-deny egress, sealed secrets).\n* Add **feature-flag service** + cohort router in prod.\n* Pipe **telemetry** (latency, fail, cost, safety events) back to Coordinator → Selector.\n* Enforce **no-DinD**; use host BuildKit and systemd where applicable; snapshot before risky ops.\n\n---\n\n## Why this works\n\nIt treats new capability like **code + policy + evidence**—not a blind install. The **trifecta-court** makes governance executable; the **coordinator** makes decisions with hard numbers; and the **sandbox** lets you move fast without breaking prod. Net effect: a system that **learns continuously** yet stays **unimpeded**.\n"
      },
      "docs/api_connectors_frontend.md": {
        "language": "markdown",
        "code": "# API, Connectors & Front‑End of ark‑os‑noa\n\n## Gateway API\n\nThe **Gateway API** is the central entry point for interacting with ark‑os‑noa’s backend services.  Implemented using FastAPI, it exposes endpoints for ingesting sources, spawning capsules, toggling CRM behaviours, ingesting models and administering the system.\n\n### Key Endpoints\n\n| Endpoint | Method | Description |\n|---------|--------|-------------|\n| `/digest` | POST | Submit a digest request.  The request includes sources (e.g. repo URL, API base URL), intent (integrate, analyse), and optional metadata.  It triggers the Intake Service and returns a job ID. |\n| `/capsule/spawn` | POST | Spawn a new Capsule environment.  Returns Capsule identifiers and access tokens.  Used when custom stacks need to be run manually or via the front‑end. |\n| `/crm/toggle` | POST | Toggle the CRM Strangler Proxy mode for a specific endpoint (e.g. enable write‑through for `/contacts`).  Allows incremental migration from external CRM to internal implementation. |\n| `/models/ingest` | POST | Add a model to the local registry.  Accepts a model identifier (e.g. Hugging Face repo) and optional metadata.  The Model Serving service pulls the model and makes it available through the ModelSelector. |\n| `/models/benchmark` | POST | Run evaluations on local or remote models.  Returns latency, cost and accuracy metrics that feed into the ModelSelector’s decision graph. |\n| `/admin/*` | GET/POST | Administrative endpoints for tasks such as inspecting job statuses, viewing SBOMs, retrieving logs, enabling/disabling features (NATS, Supabase, vcluster) and rotating secrets.  Protected via authentication and authorisation. |\n\nAll endpoints accept and return JSON; error responses include descriptive messages and relevant codes.  The Gateway uses request identifiers and attaches trace IDs to facilitate debugging and correlation across services.\n\n## Connectors & Integrations\n\nark‑os‑noa interacts with the outside world via **Adapters** and **Connectors**.  These modules encapsulate authentication, rate limiting, and protocol details, allowing the rest of the system to remain agnostic to third‑party specifics.\n\n### Built‑in Connectors\n\n- **GitHub Connector:** Uses the GitHub API to search, clone and pull repositories.  It supports scoping by organisation or repository and can read commit logs and PR metadata.\n- **CRM Connector:** Provides read/write access to CRM systems (e.g. Salesforce, HubSpot).  Initially operates in shadow mode (read‑only) via the CRM Strangler Proxy; write‑through can be toggled per endpoint.  Handles pagination, rate limits and authentication.\n- **Model Hub Connector:** Interfaces with external model repositories (e.g. Hugging Face).  Supports pulling models, downloading tokenizers and retrieving licences.  Works in conjunction with the Model Serving service.\n- **Other API Connectors:** Additional connectors (e.g. for Slack, Notion, Jira) can be added by implementing the Adapter interface.  Each connector is packaged as its own microservice or plugin to preserve modularity.\n\n### Internal Connectors\n\n- **Registry & Object Store:** Adapters communicate with the private OCI registry and MinIO using signed URLs.  They ensure that images and artefacts are pushed/pulled securely and that content addressing is respected.\n- **Database & Vector Store:** Adapters abstract database interactions.  They provide typed functions to query or insert metadata, run logs and embeddings without exposing SQL directly to the application logic.\n\n## Front‑End (Admin Console)\n\nThe **Admin Console** is a web interface built with Next.js.  Its primary function is to give administrators and power users visibility and control over the system.  Major features include:\n\n* **Jobs Dashboard:** Displays active and past digest jobs, their statuses, progress bars and any errors.  Users can drill down into individual jobs to view their `profile.json`, `system_card.md`, SBOMs and vulnerability reports.\n* **Capacities & Capsules:** Shows currently running Capsules, their resource usage and health status.  Offers controls to spawn or destroy Capsules.\n* **Artefacts Explorer:** Lists generated artefacts (zip files, PDFs, embeddings, SBOMs).  Allows downloading via signed URLs and cross‑referencing to their origins.\n* **SBOM & Security:** Provides a dedicated section to review SBOMs, vulnerabilities, licences and risk scores.  Policies can be configured here (e.g. accepted licence list, vulnerability severity thresholds).\n* **Model Registry & Selector:** Displays available models, their metadata, benchmarks and usage statistics.  Administrators can add models to the ingestion queue or deprecate existing ones.  The ModelSelector’s decisions and rationales are visible for transparency.\n* **CRM Controls:** Allows toggling of CRM endpoint modes (shadow/write‑through), viewing recent calls, and measuring divergence between external CRM data and internal state.\n* **Settings & Feature Flags:** Provides toggles for enabling/disabling optional services (NATS, Supabase, vcluster) and adjusting environment variables.  Also offers secret rotation and certificate management.\n\n## Interaction Patterns\n\n* **External Clients:** Use the Gateway API to submit work.  They receive job IDs and can query progress or results.  Authentication tokens limit access based on roles.\n* **Internal Agents:** Call endpoints via Adapters.  For example, a CommandChiefAgent may call `/digest` to start digestion for a new source or `/models/ingest` to add an in‑house model.  Internal calls attach run IDs and context for traceability.\n* **Front‑End Users:** Access the Admin Console to monitor and control the system.  When they trigger actions (e.g. toggling a CRM endpoint), the console issues calls to the Gateway API on their behalf.\n\nBy exposing a clear API and a rich front‑end, ark‑os‑noa ensures that humans and agents can seamlessly interact with the system, inspect its state and adapt its behaviour without compromising security or traceability.\n"
      },
      "docs/Ark AI NOA — Data Architecture & Autonomous Intelligence.txt": {
        "language": "text",
        "code": "﻿Ark AI NOA - Data Architecture & Autonomous \nIntelligence\nData Architecture\nInternal-First Philosophy: Ark AI NOA is built on an internal-first data philosophy. All \ncritical data and artifacts remain inside the trust boundary of the system's private \ninfrastructure[1]. This means the platform avoids external dependencies for storage and \ncomputation whenever possible. Only finished, signed outputs are allowed to leave the \nenclave, ensuring that internal work-in-progress, models, and intermediate data stay \nprotected. By \"shipping only signed artifacts outward\"[1], Ark AI NOA maintains tight \ncontrol over integrity and confidentiality. This approach reduces exposure to external \nbreaches and keeps sensitive intelligence in-house.\nStorage Components & Structure: The data plane is composed of multiple integrated \nstorage systems, each serving a specific role[2]:\n*\tPrivate OCI Registry: Acts as an internal container image registry for environment \ncapsules, model images, and build artifacts. It stores versioned container layers \nand ensures that all runtime environments (Capsules) and build outputs are \navailable internally for fast retrieval[2]. By using content-addressable image tags \n(e.g. by SHA256), every image or capsule can be uniquely identified and verified for \nintegrity.\n*\tMinIO (S3-Compatible Object Store): Houses large binary artifacts and \ndatasets[2]. This includes things like model weight files, training datasets, code \npackage ZIPs, PDFs of reports, and Software Bill of Materials (SBOM) documents. \nMinIO's S3 interface makes it easy for the agents to store and retrieve bulk data \nusing standard APIs. Versioned artifacts (e.g. zipped outputs from each run, or \ndataset snapshots) can be stored with immutable naming (content hashes or \ntimestamp prefixes) to ensure reproducibility.\n*\tPostgreSQL + pgvector: Serves as the system's metadata and knowledge \ndatabase[3]. Postgres holds structured data - run metadata, execution traces, \nagent logs, and indices - while the pgvector extension enables storing high-\ndimensional embeddings for semantic search[3]. This combination lets the \nplatform record fine-grained execution details and also maintain a vector memory \nof unstructured data (like documentation, code embeddings, or semantic \nsummaries) for later retrieval. For example, when the Digest Agent ingests a new \ncode repository, it generates embeddings of the code and stores them in pgvector; \nlater, other agents can query these vectors to recall relevant functions or \ndocuments by semantic similarity.\n*\tSupabase (Postgres gateway): Initially used for developer-facing ergonomics and \nauth, wrapping the Postgres database with a convenient API layer[4]. Supabase \nprovides authenticated access endpoints and row-level security until those \nfunctions are fully internalized into Ark's own services. In essence, it's a stop-gap \nthat makes it easier to manage user authentication/authorization and real-time \nsubscriptions for data changes, all backed by the core Postgres store. Over time, \nthe goal is to eliminate this external dependency and run all such services \ninternally, but during development it accelerates progress.\nAll these components work in concert. For example, when a MicroAgentStack completes a \ntask, it might push a container image to the OCI registry (if it built a new tool image), upload \nlarge results or datasets to MinIO, and log the run's metadata (timestamps, agent \ndecisions, outcomes) along with any vectorized embeddings of new information into \nPostgres. Each artifact is cross-referenced across stores: the database keeps pointers \n(URLs, hashes) to objects in MinIO or images in OCI, establishing a unified lineage of data.\nVersioning & Artifact Lineage: Every piece of data in Ark AI NOA is content-addressed and \nversioned to ensure reproducibility and traceability. Artifacts are named or tagged by their \nhash (SHA-256) or by a version ID, and the system records these identifiers in a metadata \ntrail[5]. This immutability policy guarantees that once an artifact (a model weight file, a \ndataset, a generated report, etc.) is created and recorded, it can always be retrieved \nexactly as produced[5]. Alongside immutability, a lineage policy is enforced: each \ndeliverable artifact carries references back to its inputs, the agents or tools that produced \nit, and the model versions used[5]. This means a final report or decision output isn't just a \nblack box - it has an attached provenance graph linking all source data, prompts, and \nintermediate results that led to it. Such lineage tracking is crucial for trust and auditability \nin an autonomous system.\nTo manage data lifecycle, Ark AI NOA defines retention classes. Short-term/volatile data \n(e.g. ephemeral working files, intermediate computations) are retained briefly and purged \nregularly, freeing space and minimizing risk of stale sensitive data lingering[5]. Long-term \ndata such as specification docs, final packaged outputs, and any signed release artifacts \nare retained much longer, as they represent accumulated knowledge or deliverables that \nmust be preserved[5]. The platform's storage retention policies encode these rules, \nautomatically expiring or archiving data based on its classification. For instance, raw logs \nfrom a micro-agent run might be kept only for a few days for troubleshooting, whereas the \nsummary report and SBOM from that run could be stored indefinitely in an archive bucket \nfor future reference or compliance.\nIntegration of Artifacts, Embeddings, and Logs: A key strength of the data architecture is \nhow it integrates various data types into a coherent whole. When the Digest Agent \nperforms a scan of code or data sources, it produces multiple outputs: structured \nmetadata (like an SBOM listing dependencies), semantic embeddings of the content, and \nhuman-readable summaries[6][7]. The SBOM file might be stored in MinIO or attached to a \nrun log, the embeddings go into the pgvector index (Postgres), and the summary is saved \nas a Markdown report artifact. The system ties these together via unique IDs or references \nso that, for example, a particular repository's digest will have a corresponding SBOM \nobject (in MinIO) and an entry in the vector index, linked by the same repo ID or hash. Later, \nan agent can look up that repo's entry, retrieve the SBOM to check for known \nvulnerabilities, and query the vector index to find related content (like similar libraries \nacross projects). All of this occurs without leaving the internal environment.\nSimilarly, model weights and fine-tuned models are managed as first-class artifacts. \nWhen a Board Agent fine-tunes a model for its domain (say the CFO agent fine-tuning a \nfinance-focused LLM on company ledgers), the new model weights are stored either in the \nOCI registry (packaged as a Docker/OCI image for deployment) or in MinIO as a checkpoint \nfile, with a version tag. The Model Selector Agent is then informed of the new model version \nvia an updated registry entry[8][9], and the Postgres metadata store tracks its performance \nstats. In effect, new learned intelligence is captured as versioned artifacts (fine-tuned \nmodels) and immediately integrated into the system's knowledge base, rather than only \nliving in memory.\nOCI Build & Image Management: To execute tasks in isolated, reproducible \nenvironments, Ark AI NOA relies on container images built and stored internally. The \nplatform uses BuildKit (the modern Docker build engine) in an external sidecar mode to \nbuild images without needing Docker-in-Docker (DinD) inside agent contexts[10]. \nWhenever a MicroAgentStack needs a specialized environment (for example, with certain \nlibraries or tools), the system's Strategy/CTO agent or the CommandChiefAgent for that \nstack will coordinate with BuildKit to assemble the required image. The build context and \nDockerfile (or analogous build instructions) are provided to BuildKit running on the host, \nensuring that the container build runs at the host level (outer plane) rather than trying to \nspawn a nested container from inside an agent[10]. This avoids the complexity and \nperformance hit of nested virtualization. Once built, the resulting image is pushed to the \nprivate OCI registry under a namespace for that capsule or task. The MicroAgentStack \ncan then pull and run this image as its execution sandbox.\nThe Capsule concept (also referred to as the Full-Illusion pattern) is central here: each \nMicroAgentStack perceives that it has a fresh, isolated container environment, but this is \nachieved by the orchestrator launching a container on the host's container runtime (such \nas containerd) on behalf of the agent, rather than the agent process launching one itself. \nThe Full-Illusion aspect means the container appears as a fully functional isolated system \n(with necessary tools, files, and network rules) from the agent's perspective, even though \nit's tightly managed by the host. The Strategy/CTO Board Agent explicitly focuses on this \nCapsule (Full-Illusion) architecture, ensuring \"no Docker-in-Docker\" and tight platform \ncohesion[11]. By using host-level control, the platform can give the agents the illusion of \nan unlimited number of fresh containers (\"capsules\") without ever compromising security \nor leaving the internal data plane.\nVirtual Disk Layering (VHDX-in-VHD): Under the hood, Ark AI NOA employs an advanced \nvirtual disk layering strategy to manage these capsule environments efficiently. Instead of \ntreating each container as an opaque image pulled from the registry every time, the system \nlayers virtual disks to speed up launches and isolate changes. The base container image \n(for example, a minimal OS with common libraries) can be stored as a VHDX (Virtual Hard \nDisk) file on disk. When a new capsule is needed, the orchestrator creates a differencing \nVHD (or an overlay layer) that references the base VHDX as read-only. This new layer is \nessentially an empty filesystem that will capture all the writes (changes) made during the \ncapsule's session, while reads for unchanged files go through to the base VHD. In effect, \nthe capsule gets a copy-on-write filesystem: it has the illusion of a full writable disk, but \nonly differences consume space. Because the base VHDX is reused, launching a new \ncontainer becomes as quick as mounting the base plus an empty overlay, rather than \ncopying dozens of GBs or pulling layers over the network each time.\nThe mention of \"VHDX/VHD inside VHDX\" refers to the ability to nest or chain these virtual \ndisks. For example, one could have a base OS VHDX, and on top of it a second VHDX that \nadds language-specific tooling (say Python or Node.js installed). This second-layer VHDX \ncould itself be treated as read-only base for an even more specialized environment (e.g., \nwith a particular application). By stacking these, the system can compose environments \nquickly: a MicroAgentStack needing a Python environment could use the generic OS base \nplus the Python layer, then a small ephemeral layer for any task-specific files. Each layer is \na VHD that can be mounted and unmounted as needed. In some cases, even a VHD inside \nanother VHD might be used - for instance, storing a pre-initialized environment file (like a \ntraining dataset image) inside a base image. The ability to mount a VHD within a running \ncapsule's filesystem (like loop-mounting a disk image file that itself resides on the base \ndisk) provides additional flexibility, such as quickly injecting large datasets or \npreconfigured caches into a container without rebuilding its image. All of this layering is \ndone within the host's control, which means it benefits from the host's file system \nperformance and security settings, and again, no Docker daemon inside the container is \nneeded to manage it.\nIn summary, the Data Architecture of Ark AI NOA is highly modular and internalized. It \nblends containerization and database techniques to ensure that whether it's an AI model, \na dataset, a log, or an entire ephemeral runtime filesystem - everything is versioned, \nlinked, and stored within the platform's own walls. This internal-first, content-addressed \ndesign sets the stage for secure and efficient operations, as described next in storage \nstrategies.\nStorage Strategies\nData Classification & Lifecycle Management: All data in the system is categorized by \nsensitivity and longevity requirements. Ark AI NOA's agents attach a classification to each \npiece of data (for example: public knowledge, internal proprietary, sensitive/PII, secrets, \netc.), and this classification dictates how and where it is stored and who/what can access \nit. High-sensitivity data is never sent to external services and is only processed by local \nmodels or tools (this is enforced by the ModelSelector's use of a privacy tier attribute when \nchoosing models)[12]. For instance, if a task involves private customer data, the \nModelSelectorAgent will invoke only an on-premise model (or a sandboxed tool) rather \nthan an API call to an external LLM, as per the \"offline/local fallbacks when privacy tier \ndemands\" policy[13]. By encoding such rules, the system automatically safeguards \nsensitive information by design.\nLifecycle management is then applied according to data type. As mentioned, transient \nworking data (e.g. a temporary code clone or a compiled binary used during a \nMicroAgentStack operation) is tagged for short-term retention and gets auto-pruned. More \npermanent knowledge artifacts (like knowledge graph entries, vector embeddings, \nfinalized reports) are tagged for long-term retention or archival. The archive process often \nhappens at the end of a workflow: when a MicroAgentStack finishes, it enters an \"Archive\" \nphase where it registers what needs to be preserved[14]. At that point, logs are \ncompressed and stored, SBOMs and checksums of outputs are saved to storage, and \neverything is stamped with a retention policy tag (e.g. \"expire after 30 days\" for raw logs, \n\"keep 1 year\" for compliance SBOMs, \"keep indefinitely\" for final deliverables)[14]. This \nautomated archival step ensures nothing falls through the cracks - every run produces an \nauditable record and artifacts that either get cleaned up or saved intentionally.\nSecure Storage Practices: Security is woven through all layers of storage. Containers and \nprocesses run with user namespaces (userns) enabled, meaning that even if an agent \nthinks it's running as \"root\" inside a capsule, on the host it's mapped to an unprivileged \nUID. This prevents a breakout from gaining host root permissions. In addition, strict \nseccomp syscall filtering is applied to capsules, limiting them to only the system calls \nnecessary for their tasks. For example, a capsule might be blocked from calling mount or \nkexec or other dangerous syscalls, even if compromised, which greatly reduces the attack \nsurface. Each capsule or agent process is further isolated by Linux cgroups and \nAppArmor/SELinux profiles as appropriate, so that their access to the filesystem and \nnetwork can be finely controlled.\nAll data at rest in the storage backends is encrypted. The MinIO object store can be \nconfigured with server-side encryption (each object encrypted with a key, with keys \nmanaged by an internal KMS or hardware module). Postgres may use disk-level encryption \n(through OS tools or transparent data encryption if available) for its files, and backups of \nthe database are also encrypted. The OCI registry's underlying storage (often just a blob \nstore or filesystem for layers) is similarly encrypted. This ensures that if any storage \nmedium were somehow accessed directly, the contents remain protected.\nAccess Scoping and Audit: Ark AI NOA follows a least-privilege access model for both \nhumans and agents accessing storage[15]. Each MicroAgentStack or Board Agent is issued \ntemporary, scoped credentials when it needs to read or write to a storage service. For \nexample, when a capsule needs to upload an artifact to MinIO, the system doesn't give it \nfull admin keys; instead, it generates a temporary token that grants write access only to a \nspecific bucket or path, and maybe only for a limited time window. Once the operation is \ndone, the token expires. Every read/write is logged and auditable[15] - the platform's \naudit log (in Postgres) records which agent or component accessed which data, at what \ntime, and whether it was allowed. These audits not only help in post hoc analysis but can \nalso feed into real-time security agents; for instance, a Security Board Agent monitors logs \nfor any unusual access patterns (like a capsule trying to read another capsule's data) and \ncan intervene or raise alerts.\nAccess control between capsules is tightly managed. Capsules are isolated workspaces: \nby default, one capsule cannot see the filesystem of another. The orchestrator mounts into \neach capsule only the directories or volumes it needs. As an example, each \nMicroAgentStack might get a dedicated directory on a shared volume (like /stacks/stack-\nabc123/) which is mounted as its working directory inside the container. Only that stack's \nprocesses have access to that path; other stacks either have their own distinct paths or are \nrun under different user credentials such that even if they tried, they couldn't list or open \nanother's files. On the MinIO side, this is mirrored by bucket policies: perhaps each stack \nor each project has a separate bucket or prefix, and tokens are issued per-stack. Mount \norchestration is handled by the host orchestrator service: it sets up bind-mounts or \nattaches volumes to container runtimes at launch time. For instance, if a task needs a \nreference dataset, the orchestrator might mount a read-only volume containing that \ndataset's VHD into the capsule. The capsule then sees /data/datasetX available but \ncannot see anything else from the host.\nAnother aspect is user-space file systems and fuse: if agents need to handle secrets or \nkeys, those might be exposed via in-memory file systems or secret stores that are not \npersisted to disk. The Security Agent often injects needed credentials at runtime (for \nexample, placing an API key file into the capsule) and ensures it's removed afterwards. \nThese secrets are stored encrypted in Postgres or a vault until needed, and only decrypted \ninto a capsule's memory space when absolutely required, and even then accessible only \nto the process that needs it.\nTo sum up, the storage strategy emphasizes containment and oversight. By using \ncontainer-native isolation (userns, seccomp, mount namespaces) and encryption + \nauditing, Ark AI NOA's data is protected both from external attackers and from accidental \nor malicious cross-access by internal components. The system knows who accessed \nwhat and when at all times, and no agent or stack is given carte blanche to rummage \nthrough data that isn't relevant to its current mission.\nContainer-Native & Capsule-Integrated Design: Because the entire architecture is built \nwith containers (Capsules) as the unit of execution, the storage is designed to plug \nseamlessly into those containerized workflows. All internal services (OCI registry, MinIO, \nPostgres) are themselves running as part of the Ark cluster (often as containerized services \nor on dedicated hosts within the same network), so capsules can reach them with low \nlatency. Access endpoints are often hostnames on an internal network (like \nminio.infra.svc or similar) that are only resolvable within the cluster. Capsules have \nnetwork access to these endpoints but often not to the broader Internet unless specifically \nallowed (an outbound internet connection might be restricted to certain research tasks \nunder supervision). This container-native storage approach means an agent in a capsule \ncan use the same mechanisms a microservice would: e.g., it can issue an HTTP PUT to the \nMinIO service to upload a file, or open a Postgres connection to store some vectors. The \ndifference is these credentials and addresses are injected by Ark's orchestrator when it \nlaunches the capsule, based on that capsule's identity and task.\nDuring capsule startup (the Bootstrap phase of a stack), the orchestrator sets up all \nnecessary mounts and credentials for that environment[10]. For example, it might mount a \nwriteable empty volume for /out (where outputs will be placed), a read-only volume for \n/tools (preloaded with common utilities or libraries), and a read-only mount of the code \nrepository under /src if the task is to analyze some code. Simultaneously, it supplies \nenvironment variables or config files containing short-lived credentials and URLs for \ninternal services (like a pre-signed URL to put results into MinIO, or a one-time password \nfor a specific database table). Once the capsule is up, the agents inside can operate freely \nin their confined space, using those mounts and credentials to do their work, but they \ncannot escalate privileges to go beyond them. If they try to access a file path or network \naddress not provided, they'll either see nothing or be blocked.\nWhen the capsule completes its task and is torn down, the orchestrator will typically \nrevoke any issued tokens (just in case they were not used) and will unmount and dispose of \nthe workspace. Temporary data is deleted unless flagged for retention. If the run was \nsuccessful, the orchestrator knows which outputs to gather (since it provided the path or \nbucket to use). It then registers those outputs in the system (for example, calculating a \nSHA256 and updating the Postgres metadata with the artifact and its lineage). In case of \nfailure, the orchestrator can still archive the logs from the capsule for debugging, as per \nretention policy.\nMount Orchestration Between Capsules: In scenarios where multiple capsules (stacks) \nneed to cooperate, Ark AI NOA carefully controls any shared mounts. By default, capsules \ndo not share a filesystem. However, sometimes a controlled interchange is needed - for \nexample, one stack might produce a model file that another stack should use. Instead of \nmounting one capsule's volume into another (which could violate isolation), the system \nwill typically employ the storage services as intermediaries: the first stack can push the \nmodel file to MinIO, and the second stack, when it starts, is given a pre-signed download \nlink or the object path to retrieve it. This way, data flows through the audited storage layer \nrather than direct disk sharing. This pattern forces data exchanges to go through secure, \nlogged channels, preventing any hidden coupling between capsule environments.\nIn rare cases where low-latency sharing is needed (for example, two capsules in a \npipeline), Ark might use a shared memory or IPC mechanism, but even then it's \norchestrated and supervised. The rule remains that any such sharing should be explicit \nand minimal.\nBy combining these strategies, Ark AI NOA's storage design achieves a balance of \nflexibility, performance, and security. Agents get the data access they need to be \neffective, but always via the narrowest gate possible, and always leaving a trail. The \ninternal-first approach, combined with rigorous isolation and lifecycle rules, means the \ndata remains trustworthy and available for the higher-level intelligence processes that \ndepend on it.\nIntelligence Formation and Growth\nArk AI NOA is not a static system - it is designed to continuously learn and evolve. The \narchitecture of agents and agent stacks is geared towards intelligence formation, where \neach operation feeds into a growing knowledge base and improves future performance. \nThere is a deliberate lifecycle of learning that each piece of information goes through: \nObservation → Abstraction → Hypothesis → Integration.\n*\tObservation: The system's agents constantly observe new inputs and the \nenvironment. This includes ingesting external data (via the Digest Agent's \nweb/repo/API crawling), monitoring internal events (like logs, metrics), and taking \nnote of user instructions or goals given to NOA. For example, when connected to \ncompany repositories or APIs, the Digest Agent will discover and fetch data \nsources continuously[6]. Each MicroAgentStack also observes the results of its own \nactions in real-time (e.g., test outcomes, error messages).\n*\tAbstraction: Raw observations are then abstracted into more useful \nrepresentations. In practice, this means parsing and structuring information. The \nDigest Agent, after fetching data, performs a Parse step where language-aware \nparsers extract metadata and build an SBOM[6] (capturing the essential \ncomponents and dependencies of code, for instance). It then analyzes the data, \ngenerating embeddings for semantic content and even constructing elements of a \nknowledge graph of key entities and their relationships[16]. This is abstraction: \nturning concrete data into vectors, graphs, and summary narratives. Likewise, if a \nMicroAgentStack is running a data analysis, it might abstract raw numbers into \nsummary statistics or identified anomalies.\n*\tHypothesis: With abstractions in hand, agents form hypotheses - potential insights \nor plans that explain the observations or achieve goals. For example, from a parsed \nSBOM and vulnerability database, the Security Agent might hypothesize \"these \ncomponents may be outdated and risky\". The Strategy Agent, given a business goal \nand some market data, might hypothesize several approaches (scenarios) to \nachieve it. In essence, this is the creative reasoning phase: the agents use their LLM \nreasoning capabilities to propose solutions, explanations, or strategies. A \nMicroAgentStack's CommandChiefAgent might formulate a hypothesis like, \n\"Feature X can be implemented by integrating API Y, given the patterns from similar \nprojects\". These hypotheses aren't wild guesses - they are grounded in the \nabstracted knowledge the system has accumulated.\n*\tIntegration: The final step is integrating validated hypotheses back into the \nsystem's knowledge base. If a hypothesis proves useful or correct (e.g., a suggested \nsolution worked, or a predicted risk was confirmed and mitigated), the system \nincorporates that lesson. This can happen in several ways. The Digest Agent's \noutput is one form of integration: after analyzing and summarizing, it produces a \ndigest report (Markdown, JSON indices, vector DB upserts) that is stored for future \nreference[17]. That knowledge becomes part of the collective memory. Another \nform is model fine-tuning: when a Board Agent in charge of a domain gets new \ndomain data, the system can fine-tune that agent's underlying model on the new \ndata, effectively integrating the new knowledge into the model's weights[18]. For \ninstance, after a big project post-mortem, the relevant Board Agent (say, the COO \nagent focused on processes) might fine-tune on the lessons and retrospective data, \nyielding a model that embodies those lessons for future planning. Additionally, \nintegration happens via updating embeddings and knowledge graphs - new \nconcepts learned are added as new nodes and vectors, enriching what the agents \ncan draw upon.\nThroughout this cycle, the agents and agent stacks play specific roles in growing \nintelligence:\n*\tThe Digest Agent (which is part of the Board's R&D arm) is a primary source of \nobservation and abstraction for external knowledge. It continuously brings in fresh \ndata (code from repos, documentation, CRM records, etc.), parses it into structured \nforms (SBOMs, metadata) and unstructured forms (embeddings, summaries), and \nupdates the long-term stores[6][7]. It is essentially the research librarian of the \nsystem, ensuring that NOA and other agents have a rich library of current \ninformation to draw from. By doing scheduled or triggered digests, it enables \nknowledge accumulation over time - the more it runs, the more comprehensive \nthe internal knowledge base (both vector store and relational facts) becomes.\n*\tThe Board Agents contribute to hypothesis formation and vetting. Each Board \nAgent is an expert in a domain (strategy, compliance, security, etc.) and can analyze \na situation using its specialized perspective. When NOA (the top-level Executive \nOrchestrator) is faced with a complex goal, it will consult the Board for diverse \nopinions[19]. Each Board Agent might recall relevant past cases from memory, \nevaluate the current data (often pulling from the knowledge stores curated by \nDigest), and propose a course of action. In doing so, they refine the raw intelligence \ninto concrete strategic options. The Strategy/CTO Agent, for example, leverages \nknowledge of the system architecture and past engineering outcomes to suggest an \napproach, while the CFO Agent checks these against cost metrics and historical \nspend patterns (which are stored as telemetry). This collective deliberation \nimproves the quality of any single agent's idea and embeds cross-domain \nknowledge into decisions. The Board Agents also set policies that encode learned \nbest practices - e.g., the Legal Agent might integrate a new regulatory requirement it \nlearned (from ingesting legal updates) into the compliance policy that all future \ntasks must check.\n*\tThe MicroAgentStacks are where hypotheses are executed and tested in real time. \nEach MicroAgentStack is like a small experimentation lab: it's spun up to attempt \na specific task or approach. The CommandChiefAgent in the stack takes a plan (a \nhypothesis of how to achieve the goal) and coordinates Operators to carry it out[10]. \nDuring execution, a lot of learning happens: if an approach fails, that's recorded. If it \nsucceeds, the outcome (artifacts, logs, performance stats) is fed back. Notably, as \npart of the lifecycle, every stack archives its logs and results[14]. These archives are \nnot just for compliance; they are used as fodder for future learning. The Digest \nAgent or others may later parse these logs to extract insights (for example, patterns \nof failure that could be addressed by a new safety check, or reusing a particularly \neffective prompt that was generated). In this way, each micro-agent execution feeds \nthe hive mind. The system effectively performs continuous A/B testing and learning: \nspin up multiple stacks in parallel to try different variants (horizontal scaling for \nexploration), see which yields the best result, and integrate that knowledge for next \ntime. Over time, the platform might even train meta-models on these logs (for \ninstance, training a smaller model to predict which actions lead to success vs. \nfailure, thus giving NOA a \"gut feeling\" based on past data).\n*\tMemory Systems: Ark AI NOA blends several forms of memory to support \nintelligence growth:\n*\tEpisodic Memory (Logs/Traces): Every agent action and result is logged with a \ntrace ID. These serve as an episodic memory of what happened, accessible for \naudit and also for learning. Agents can query past traces; for example, NOA might \nretrieve the trace of a similar project done last month to avoid repeating mistakes. \nThe logs are structured (with event types, timestamps, outcome codes) making it \npossible to do analytics on them (like \"how many times have we succeeded \nbuilding X with approach Y?\").\n*\tSemantic Memory (Vector Store): By encoding text and code into embeddings and \nstoring in pgvector, the system gains a semantic recall ability. Agents can ask \nquestions like \"have we seen something like this error before?\" or \"find all \ndocuments related to topic Z\" and get results based on meaning, not just keywords. \nFor instance, if an agent is tasked with integrating a payment API, it can query the \nvector store for anything related to \"payment integration\" - perhaps the digest from \na CRM, or code from a previous integration project - and instantly retrieve the \nrelevant pieces to inform its plan. This greatly shortens learning curves, as the \nsystem doesn't forget what it encountered in the past.\n*\tDeclarative Memory (Knowledge Graph/Database): Some facts are stored more \nsymbolically - e.g., a knowledge graph node for each service with edges for \ndependencies and data flows, or a database table of known bugs and their fixes. \nAgents (especially the Security and Compliance ones) use this kind of memory to \nenforce rules and checks. For example, the Security Agent might query a table of \n\"disallowed licenses\" when reviewing an open-source component (populated by \nDigest Agent's parsing of license files). This represents institutional knowledge and \npolicies that grow over time (when a new license is deemed problematic, it gets \nadded to that table).\n*\tProcedural Memory (Fine-tuned Models and Skills): Not all knowledge is explicit. \nBy fine-tuning models or training smaller helper models, Ark AI NOA encodes \nrepeated behaviors into the model weights themselves. Each Executive seat's \nmodel can be fine-tuned on domain-specific Q&A or historical decisions[18]. Over \ntime, the CFO's language model might become extremely adept at financial \nquestions specific to the organization, because it's been trained on every financial \ndecision and outcome the company had. This is analogous to a person's muscle \nmemory or intuition honed by experience. Additionally, the platform might develop \ntools or scripts (small programs) through learning - if a certain operation is done \nfrequently and is automatable, an agent might create a new operator or script, \nwhich is then stored in the repository and becomes part of the toolset for future \nstacks (this is like learning a new skill and adding it to the team's toolkit).\nImportantly, the system treats failures as learning opportunities. When something goes \nwrong - say a MicroAgentStack fails its task - the event is captured and could trigger a mini \npost-mortem analysis by the Digest or another agent. Perhaps the Digest Agent will include \nthat failure case in its next summary, or the NOA will record a \"lesson learned\" in a \nknowledge base. Agents have access to these lessons in subsequent planning. This closes \nthe loop of continuous improvement: observation of failure → hypothesis of why → \nintegration of mitigation. In fact, the presence of a post-mortem output is explicitly part of \nNOA's responsibilities[20] (NOA produces post-mortems as outputs of goals), indicating \nthe system is designed to reflect on outcomes.\nThrough these mechanisms, Ark AI NOA's intelligence doesn't plateau; it compounds over \ntime. Each agent, from top-level NOA to the smallest micro operator, contributes to a \ncollective learning process. The more projects it runs, the more data it digests, the smarter \nand more efficient it should get at future tasks. This is in contrast to a naive system that \nwould treat each task independently. Here, memory and learning are first-class citizens of \nthe architecture. The interplay of agents, memory stores (vector DB, graphs, logs), and \nmodel refinement creates an ever-growing knowledge core - essentially an internal \nknowledge base and an evolving set of policies/models that embody the organization's \ncollective experience.\nCritical Thinking: Branchwise Foresight & Decision Frameworks\nOne of the most distinctive aspects of Ark AI NOA is how it approaches complex decision-\nmaking. The system employs a Branchwise Foresight methodology - essentially a \nrigorous form of scenario-based planning and critical evaluation - to anticipate outcomes \nand choose the best course of action. Unlike a straightforward single-path plan, \nBranchwise Foresight involves exploring multiple possible branches of a plan (like a \ndecision tree of scenarios) and assessing each before committing. This forward-looking \ncapability is enhanced by several structured techniques: scenario planning, tripwires, \npremortem analysis, reversibility checks, expected value scoring, and mind mapping for \noption pruning. Together, these provide a sort of \"brain trust\" for the AI, enabling it to \nreason about the future much like a team of skilled strategists would.\nScenario Planning: Rather than relying on one forecast, NOA and the Board Agents \ndevelop multiple plausible future scenarios for any significant goal. Effective scenario \nplanning typically means outlining a few (often 3-4) distinct scenarios that challenge \ndifferent assumptions[21]. For each scenario, the agents imagine what the world looks like \nif that scenario comes true - what events lead to it, what risks and opportunities exist \nunder it. For example, if the task is to roll out a new product feature, scenarios might \ninclude \"massive user adoption\", \"tepid response\", \"competitor launches rival \nsimultaneously\", etc. The Strategy Board Agent is especially involved here, since its role \nexplicitly includes scenario and risk intelligence[22]. The agent draws on internal \nknowledge and possibly external trend data to craft these narratives. The goal isn't to \npredict exactly which scenario will happen, but to ensure preparedness across a range of \nfutures[21]. Each scenario is used to test the current plan: the Board asks \"If scenario X \nunfolds, does our plan hold up? What would we do?\". This often reveals vulnerabilities or \ncontingencies that need addressing. Scenario planning thus forces the system to have \ncontingency plans and to design solutions that are robust under uncertainty. It also feeds \ninto the next tools - for each scenario, the Board can set tripwires and do premortems.\nTripwires and Trigger Points: A tripwire is a predefined signal or threshold that triggers a \nreevaluation or decision[23]. In practice, after exploring scenarios, the agents decide on \ncertain key indicators to watch - metrics or events that, if observed, will \"trip\" the wire and \ncause the system to adapt strategy. For example, in a project scenario, a tripwire might be \n\"If progress is <50% by week 2, trigger fallback plan\" or \"If API error rate exceeds 5%, halt \nand notify Security Agent.\" These are essentially early warning systems that prompt a \ncourse correction without waiting for full failure. They are set up during planning: the Board \nAgents leverage their domain knowledge to choose meaningful tripwires (the CFO sets a \nbudget overrun tripwire, the COO sets a schedule slip tripwire, etc.). Tripwires combat \nhuman (and AI) biases like sunk-cost fallacy and confirmation bias by predetermining an \naction when objective conditions are met[24][25]. When running autonomously, NOA \nmonitors these conditions via the telemetry data. If a tripwire condition triggers, NOA or the \nrelevant Board Agent will immediately pause and reassess the plan, possibly shifting to an \nalternative branch that was prepared. This ensures the system is not blindly sticking to a \nplan that's going awry - it has built-in reflexes to catch issues early. Moreover, tripwires \nallow the AI to commit to a risky path with the comfort that if certain danger signs appear, it \nwill know to pull back[26]. They create a balance between decisiveness and adaptability, \nwhich is crucial for autonomous operation.\nPremortem Risk Analysis: Before a major plan is executed, Ark AI NOA performs a \npremortem analysis - effectively imagining that the plan has failed horribly and then \nreasoning backward to figure out why[27]. This technique, inspired by human project \nmanagement practices, is used by the Board (particularly the Risk/Compliance and \nStrategy agents). In a premortem session, the agents assume \"the project has derailed or \nthe outcome was a disaster\" and list all possible causes. This might surface risks like \n\"model selection was flawed and gave wrong answers,\" \"data source X turned out to be \nunavailable,\" or \"we underestimated the time needed for integration.\" By articulating these \nupfront, the system can then address each: either by mitigating it (adding a step to verify \nmodel answers, having a backup data source, buffering the timeline) or by at least \nmonitoring it (setting a tripwire for signs of that failure mode). The premortem essentially \nbroadens the system's peripheral vision, making it less likely to be blindsided. It also helps \nbreak any single-track optimism - in human teams it counteracts groupthink[28], and for \nthe AI, it counteracts the tendency of a single LLM's bias toward optimistic outputs by \nensuring multiple \"voices\" (Board agents) contribute worst-case thinking. By \"assuming \nthe patient has died\" (the project failed) and asking \"what went wrong?\"[29], Ark AI NOA \nmoves into execution with a clearer awareness of pitfalls and a set of contingency plans \nassociated with those potential pitfalls.\nReversibility & Expected Value Scoring: Every decision or branch is evaluated on how \nreversible it is and what its expected outcome value is. NOA, with input from Board \nagents, categorizes decisions as one-way doors (hard or impossible to reverse) or two-way \ndoors (easy to change course). The rule of thumb is to proceed faster and more \nexperimentally through two-way door decisions, but to be very cautious and get consensus \non one-way door decisions. For instance, deleting a large dataset is one-way (irreversible) \nunless backups exist, whereas deploying a new microservice is two-way (you can roll it \nback if issues). Ark AI NOA will lean into action for reversible things - it might launch an \nexperiment without lengthy deliberation if it knows it can undo it - whereas for irreversible \nactions it will seek extra validation (for example, run more extensive tests, involve the \nhuman operator for confirmation, or at least double-check via multiple agents voting). This \nconcept ties closely to expected value (EV) scoring: each branch scenario can be given \nan EV, combining the likelihood of success and the impact (value) of that success, minus \ncosts/risks. The Board Agents, especially CFO (value/cost) and Strategy (probabilities), \nquantify each major option. For example, Option A might have a 50% chance of yielding \n100 units of value (EV = 50), Option B 80% chance of 60 value (EV = 48), etc. They also \nfactor in risk cost (like potential loss if fails). The system uses these scores to guide \nchoices, favoring higher EV paths provided risk is acceptable. However, it doesn't blindly \npick EV-max if an option carries catastrophic risk in a low probability case (that's where \nscenario planning nuance comes in - an option that looks good in expectation might be \navoided if one scenario outcome is extremely bad and irreversible). Essentially, NOA \nadopts a rational decision framework augmented with safety multipliers: it attempts to \nmaximize expected utility while bounding downside risk, much like a well-trained human \ndecision committee would.\nMind Mapping & Option-Space Pruning: At the start of tackling a problem, NOA will often \ngenerate a mind map - a sprawling exploration of possible approaches, sub-tasks, and \nconsiderations. This is done by the CommandChiefAgent (for a stack-level problem) or by \nNOA with Board input for bigger goals. Using the creativity of the LLMs, it lays out an option \nspace: different strategies, tools that could be used, relevant past examples, etc. This \nmind map can be thought of as a decision tree or graph of ideas. Of course, not all \nbranches are viable or efficient, so the agents then apply pruning heuristics. They eliminate \noptions that violate known constraints (e.g., a plan that would require external data when \npolicy forbids it), or those that are dominated by other options (if approach X is strictly \nbetter than Y in all aspects, drop Y). They also use feasibility checks from domain experts - \nthe CTO agent might prune ideas that are technically not feasible or too complex to \nimplement in time, the CFO prunes anything wildly over budget, and so on. This \ncollaborative filtering continues until a manageable subset of promising approaches \nremain. The mind map helps ensure no obvious avenue was missed early on; it's \nessentially an ideation phase to counteract tunnel vision. Once pruned, the remaining \nbranches are then deeply analyzed (with the above methods like premortem, EV scoring). \nThe result is a well-considered plan that still had a wide net cast initially. If needed, the \nmind map can be revisited (for example, if all remaining options fail, maybe a previously \npruned one needs reconsideration). This mirrors how a human team might brainstorm \nfreely then narrow down to the best ideas.\nAutonomous Agent Utilization of Frameworks: What makes all these frameworks \npowerful is that Ark AI NOA's agents execute them autonomously and continuously. The \nBoard of Agents essentially institutionalizes critical thinking. For instance, as NOA is \nplanning, it \"consults its board of directors (multiple LLM/MLLM endpoints) for diverse \nadvice, risk analysis, and scenario planning\"[19]. Each Board Agent brings one of these \nframeworks to the table: the Strategy agent pushes scenario planning, the \nRisk/Compliance agent runs through premortem scenarios, the Ops agent sets tripwires \nand monitors reversibility (as an operational concern), and so on. They debate and iterate \nin a loop (entirely within the AI, though traces are logged) akin to a committee meeting. This \nmeans the Branchwise Foresight isn't a one-time activity but an ongoing mindset; even \nduring execution, if conditions change, the same critical thinking patterns are invoked to \nadjust the plan.\nFor example, imagine during a project, a new external factor arises (perhaps a new \nregulation gets announced). The Legal Board Agent will recognize this (because it's \nmonitoring news or updates as part of its duties) and will inject a new scenario into \nconsideration on the fly: \"Scenario: new regulation imposes constraint X next month.\" The \nteam will branch the plan, perhaps suggesting that the project accelerate certain \ncomponents or add a compliance review step. NOA can then spin up a MicroAgentStack to \nhandle that addition. Meanwhile, tripwires might be adjusted for the new reality, and \nexpected value rescored with updated probabilities. All of this happens without a human in \nthe loop, unless a threshold for human escalation is reached. The system is effectively \nalways running a mental simulation of the future in the background of its operations, \npowered by these frameworks.\nAnother concrete autonomous use: When delegating to a MicroAgentStack, NOA doesn't \njust fire-and-forget. It gives the CommandChiefAgent of that stack context on the plan's \nbranch, including any tripwires relevant to that task and the rationale behind the chosen \napproach. The MicroAgentStack, during its Validate phase, might do a mini-premortem of \nits own (for example, before finalizing outputs, the stack's Guard agents check \"What \ncould be wrong with this deliverable?\" maybe running tests or sanity checks, essentially a \npremortem on the output). If something's off, they loop back and adjust. This showcases \nthat critical thinking is not only at the strategic level but also at the tactical level of \nexecution.\nIn summary, Branchwise Foresight and its toolkit (scenarios, tripwires, premortems, \nreversibility, EV analysis, mind maps) imbue Ark AI NOA with a structured form of \nimagination and caution. It's like having a built-in strategist, risk manager, and project \nmanager inside the AI, ensuring that the system's autonomy is exercised with foresight and \nnot recklessness. This drastically increases the resilience of plans and the likelihood of \nsuccess, as the system can preempt many problems and dynamically navigate around \nobstacles. It's one of the key differentiators that make Ark AI NOA an autonomous \nexecutive, not just an automation script.\nCross-Linking with the Ark AI NOA Architecture\nAll the above strategies and components come together within Ark AI NOA's overarching \narchitecture, forming a cohesive intelligent system. At the top stands NOA \n(ExecutiveCommanderChiefAgent) - the single global orchestrator that receives high-\nlevel goals and is ultimately responsible for delivering results[30]. NOA acts as the chief \nexecutive, coordinating all other agents and resources. It uses the Data Architecture and \nStorage as its operational substrate and the Branchwise Foresight frameworks as its \ndecision-making ethos. Whenever NOA is given a new objective, it translates that into a \nWorkPlan (a structured game plan with tasks, checkpoints, and deliverables)[31]. In doing \nso, it immediately leverages the knowledge base (Postgres/pgvector) to see if similar goals \nhave been achieved before, and it engages the Board Agents to stress-test the plan under \ndifferent scenarios.\nBoard Agents form the next layer down - effectively NOA's executive team or \"board of \ndirectors\"[32][33]. Each Board Agent has a specialization (Strategy/CTO, COO, CFO, Legal, \nSecurity, Growth, Digest R&D, etc.) and a corresponding sphere of authority and expertise. \nThey are persistent agents (likely each implemented with a dedicated LLM, possibly fine-\ntuned for their domain, or a combination of tools) that NOA can consult or delegate to as \nneeded. When a new plan is formulated, NOA assigns relevant portions to different Board \nmembers. For example, the CFO agent will outline the budget and cost controls, the \nSecurity agent will impose any necessary security measures or reviews (like requiring an \nSBOM check as part of deliverables), and the Digest (R&D) agent might be tasked to gather \nany background research needed. The Board is explicitly tied into the Branchwise \nForesight process - collectively, they perform the risk analysis, scenario planning, and \noversight for NOA[19]. In effect, NOA rarely makes a unilateral major decision; it relies on \nthis internal advisory panel to vet ideas. This is analogous to how a CEO works with a board \nin a company, but here it's all within the AI, ensuring multidimensional thinking.\nThe Board Agents also have the authority to spawn MicroAgentStacks for execution. \nAccording to the operating rules, each Board Agent can deploy multiple MicroAgentStacks \nto complete tasks in their domain[34]. For instance, if the Growth Agent (partnerships) \nneeds to integrate data from a new CRM, it might spin up a MicroAgentStack to handle the \nETL and analysis of that data. If the Security Agent needs to do a thorough audit of an open-\nsource library being introduced, it launches a MicroAgentStack that runs scanners and \nproduces an attestation report. NOA oversees this at a high level, ensuring resources are \nallocated properly and timing is synchronized, but the Board Agents have discretion to \nmanage the how. This design allows parallelism and domain-specific focus - multiple \nMicroAgentStacks can run in parallel under different Board sponsors, all contributing to \nthe overall goal.\nModelSelectorAgents act as a support system for the Board and NOA. Whenever an agent \n(NOA or a Board member) needs to execute a particular task that could use an AI model or \na tool, they consult a ModelSelectorAgent to pick the best model for the job[35][36]. For \nexample, if the Legal Agent needs to analyze a contract, the ModelSelector might decide \nthat a 70B parameter legal-specific model fine-tuned on law (which is available internally) \nis the best choice over a generic model. The ModelSelector uses metadata about tasks - \nincluding size, required accuracy, latency tolerance, cost limits, and privacy level - to \nmake its decision[37]. It looks at what models are installed (some may be local via Ollama, \nsome might be accessible via API, etc.) and which have historically performed well on \nsimilar tasks[38][39]. It might even do a quick performance estimate or ensemble if \nneeded. In the architecture, the ModelSelectorAgents are like specialized consultants: \nthey aren't involved in strategic planning per se, but whenever an agent is about to act (like \nrun an LLM prompt or perform an analysis), they ensure the right \"tool\" (model or function) \nis chosen. This ties directly into the data architecture because the model catalog \n(potentially stored as JSON or in Postgres) includes references to model artifacts stored in \nthe OCI registry or to endpoints. The fine-tuning pipeline described earlier also feeds into \nModelSelector: once a Board fine-tunes a model and registers it, the ModelSelectorAgents \nupdate their registry and can immediately start routing tasks to the new model if it's \nsuperior[40][41]. This dynamic model selection ensures Ark AI NOA is always using the \nbest available intelligence for each subtask, and it keeps costs in check by picking smaller \nmodels when appropriate, as per the default policy guidelines[13].\nThe Capsule/Full-Illusion pattern is central to how these agents and stacks are executed \non the infrastructure. When NOA or a Board Agent decides to launch a MicroAgentStack, it \neffectively requests a new capsule environment from the infrastructure (via the \nStrategy/CTO agent's orchestration logic, or a lower-level scheduler service). The Full-\nIllusion approach means that each MicroAgentStack gets a fresh, isolated runtime that \nappears as a full system (complete with tools, network access, etc.), but it's actually \nmanaged by the host. This approach is realized through the container and virtual disk \nstrategy discussed: using the outer-plane container runtime (BuildKit, containerd) to \ncreate these environments without exposing Docker inside the agent contexts[10]. The \nresult is that from the perspective of NOA and the Board, they can create and destroy \n\"mini-computers\" (capsules) on demand, with whatever specifications needed (like \ndifferent OS images, specific toolchains), all defined by images in the OCI registry. They \ndon't worry about the dirty details of virtualization - that's handled behind the scenes by \nthe Full-Illusion mechanism.\nThis ties back to data: because these capsules are ephemeral and isolated, all the data \nexchanges go through the internal storage services. For example, suppose the Growth \nAgent spins up a capsule to process CRM records. That capsule will fetch the raw data \nfrom perhaps MinIO (where it was dropped by a previous integration) and after processing, \nit might output a cleaned dataset back to MinIO and update a database table. The capsule \nthen terminates. The Board agent, monitoring via telemetry, sees the job is done and picks \nup the results from MinIO/DB for further analysis or for another stack to consume. At every \nstep, the internal data architecture ensures that what one capsule produces can be found \nand used by others, but without direct coupling.\nReal-Time Adaptive Decisioning Example: To illustrate how all these pieces work \ntogether, consider a concrete scenario: Ark AI NOA is given a goal to \"Develop and deploy a \nnew feature that uses machine learning to recommend products to users.\"\n*\tPlanning Phase: NOA receives this goal and breaks it into sub-tasks: (1) research \nrecommendation algorithms, (2) gather relevant user data, (3) train a model, (4) \nintegrate into the product, (5) deploy and monitor. It engages the Board: The \nStrategy Agent comes up with technical approaches (collaborative filtering vs. \nneural nets) and does scenario planning for different user response outcomes. The \nGrowth Agent suggests which data sources (CRM, past sales) to use. The Legal \nAgent warns to be mindful of user privacy (which triggers the plan to anonymize data \n- adding a task for a MicroAgentStack to perform data sanitization). The CFO Agent \nprovides a cost cap for training (e.g., prefer using internal GPU resources overnight \nvs. expensive API calls). They collectively perform a premortem and identify a risk: \n\"What if the recommendation quality is poor and drives users away?\" - so they add \na mitigation step to do A/B testing with a smaller user group first (and a tripwire: if \nuser engagement drops by >5%, rollback the feature). All these considerations are \nwoven into a master plan, and each has an owner agent.\n*\tExecution Phase: NOA now orchestrates multiple MicroAgentStacks in parallel: \none stack is launched to handle data gathering (under the Growth Agent's \nsupervision), another to prototype algorithms (under the Strategy Agent's \nsupervision, perhaps using a specialized ModelStack for training with \nModelSelector picking optimal training models), and another to prepare \ndeployment infrastructure (under the CTO agent). These stacks operate in their own \ncapsules. The data gathering stack pulls data from internal databases via the Data \nPlane (Postgres/MinIO), processes it (removing personal identifiers as per Legal's \nrequirement), and then uploads a cleaned dataset to a secure MinIO bucket. As it \nfinishes, it logs an event which the training stack is waiting for (perhaps via a \nmessage in Postgres or simply by polling that bucket). The training stack, once data \nis ready, trains a model using an appropriate ML library. Here, ModelSelectorAgent \nmight have been involved to choose whether to fine-tune an existing recommender \nmodel from the registry or train from scratch. The chosen model (say a fine-tuned \ngemma:7b for recommendations) was pulled from the OCI registry. After training \n(which might produce a new model file), the stack registers the model artifact in the \nOCI registry (tagging it recommender:v1) and also generates evaluation metrics. \nMeanwhile, the deployment stack has built the integration code (maybe a new \nmicroservice container) and is waiting for the model. When ready, it pulls \nrecommender:v1 from the OCI registry, bundles it into the service, and deploys it to \na staging environment (since the CTO agent's policy is no direct prod deployment \nwithout testing).\n*\tAdaptive Loop: Now comes adaptive decisioning: Suppose during testing, the A/B \ntest results indicate that the recommendations are somewhat off-mark for a certain \nsegment of users. The tripwire set by the Strategy or Growth agent triggers: the \nengagement for new users dropped beyond the threshold. The telemetry (metrics \npipeline feeding into Postgres) flags this, and the Growth Agent immediately calls \nfor a pause on full deployment. NOA convenes the Board (internally) to assess the \nsituation. The Board analyzes the data: the Strategy Agent hypothesizes that the \nmodel is biased toward popular products and ignores niche interests; the Digest \nAgent quickly searches internal knowledge (vector DB) and finds a related research \npaper in the knowledge store that suggests a hybrid approach could help. Here the \nIntelligence Growth aspect is evident: because the system had digested relevant \ninfo (maybe from that research paper or previous similar projects), it can recall a \npotential solution. NOA then spins up a new MicroAgentStack to implement this \nadjustment - perhaps blending collaborative filtering with the ML model. This stack \nmight reuse some of the previous work (it pulls the last model, fine-tunes it further \nor adds rules). Thanks to versioned artifacts, nothing is lost - the previous model \nv1 is still in the registry, and the dataset in MinIO can be reused. The new stack \nproduces recommender:v2. The Board evaluates it on the metrics (maybe the CFO \ncares about compute cost increase, the Growth cares about engagement fix - all \nthese metrics are stored and compared in Postgres). If satisfied (the scenario \nplanning might simulate how this improvement addresses the earlier scenario of \nuser disengagement), they greenlight deployment. The Security Agent runs a final \nSBOM scan on the new model/service (via Digest Agent's tools) before launch - all \ndone by another MicroAgentStack as needed - and posts the SBOM to the internal \nledger for compliance (stored in MinIO and referenced in Postgres)[42]. Then the \nfeature goes live.\n*\tAftermath: NOA packages the deliverables (documentation of the feature, the final \nmodel, deployment manifests) and ensures everything is archived properly (the \nStorage policies archive logs of all stacks, link the lineage: e.g., recommender:v2 is \nlinked to v1, the dataset, the code commit hash, etc. all logged in Postgres)[43]. A \npost-mortem is automatically generated by the Digest Agent summarizing what was \nlearned - \"initial model had issue X, we fixed by Y, now engagement is up Z%\" - and \nthat report (with citations to internal data) is stored for future reference, maybe \neven sent to a human operator or stakeholder. The entire process from goal to \nresult was handled within Ark AI NOA's architecture, demonstrating autonomous \nadaptive decision-making at scale.\nIn this example, we see how NOA, BoardAgents, ModelSelectorAgents, \nMicroAgentStacks, and the data/storage infrastructure all interplay: NOA provides top-\nlevel coordination and final say, BoardAgents inject domain expertise and critical thinking \n(scenario planning, risk checks), ModelSelectorAgents ensure optimal use of AI models, \nMicroAgentStacks do the actual work in isolated Capsules using internal data, and the \nStorage/Data plane connects everything while preserving institutional memory. The \nCapsule/Full-Illusion approach allowed all those stacks to run simultaneously in a safe \nway, without stepping on each other or exposing data, and with minimal overhead (since \nimages and data were efficiently shared via layering and internal networks). The decisions \nat each juncture were informed by internal data - from past project traces to embedded \nresearch knowledge to real-time telemetry - showcasing that Ark AI NOA truly runs on its \nown accumulated intelligence.\nFinally, this architecture implements a virtuous cycle: the more NOA and its agents \noperate, the more they learn, and the better their decision-making becomes over \ntime. The design ensures that every outcome (success or failure) feeds back into the \nsystem (via stored knowledge or model updates), enabling an ever-improving autonomous \norganization. By cross-linking data architecture with agent logic and critical thinking \nframeworks, Ark AI NOA embodies a self-refining intelligence - one that can take on \ncomplex, dynamic tasks with a remarkable degree of autonomy, foresight, and reliability. \n"
      },
      "docs/ark-ai-noa_ build-setup-instructions.txt": {
        "language": "text",
        "code": "\nArk-OS-NOA Build Instruction Manual\nSummary\nArk-OS-NOA is a local-first agentic operating system designed to run on Windows 11 Professional hardware without relying on external services. It treats your machine as an autonomous ecosystem: a hive-mind of specialized micro-agents orchestrated by an executive controller that plans, acts, learns, adapts and self-upgrades your software and hardware environment. It offers offline privacy, near-zero latency and full customization because all models, data and tools are stored locally 1 . The system's layered architecture combines a sandbox/research plane for digesting new capabilities, a coordinator/ control plane that evaluates and promotes those capabilities, and a deployed application plane that runs the live agents. An internal Trifecta-Court governs promotions-ensuring that no new model, tool or micro-agent enters production without passing constitutional checks for safety, cost and compliance. This manual describes how to build, configure and package Ark-OS-NOA as a Windows 11 Professional application (.exe) with fully automated command-line operations.\n1 Background and Philosophy\nModern enterprise AI stacks are rapidly moving away from monolithic cloud models toward agentic operating systems that coordinate multiple AI workers and tools. Running agents locally provides several advantages: your data never leaves your machine, performance is far faster than cloud APIs, the system can run completely offline, there are no per-token API fees and you can customize every component 1 . An AI agent operating system manages resources, orchestrates tasks and provides a framework for multiple agents to work together 2 .\nArk-OS-NOA builds on these principles with some key innovations:\n Micro-agent stacks: inspired by micro-services, micro-agents are tiny specialized AI components that handle one task extremely well . They use minimal compute, run locally and can be composed into larger workflows. Benefits include higher speed, lower cost, specialization and privacy .\n Dynamic UI and data centrality: the interface adapts automatically to the underlying data structures and user permissions . Real-time dashboards update as agents ingest data and run tasks.\n Three-plane architecture: a sandbox/research cluster digests and tests new capabilities, a coordinator cluster decides promotions using constitutional policies, and a deployed cluster runs the live agents.\n Trifecta-Court governance: a three-branch governor-executive (NOA executive), legislative (Board/ ModelSelector agents) and judicial (Court engine)-ensures that only safe, cost-effective and policy-compliant capabilities reach production. Emergency overrides require quorum and all decisions are auditable.\n Offline model management: models are downloaded directly from Hugging Face repositories and cached locally. The environment variable HF_HUB_OFFLINE=1 prevents any network calls; only the cached files are used .\n2 High-Level Architecture\nArk-OS-NOA divides the system into three cooperating planes:\n1. Sandbox/Research Plane - An isolated environment (for example, a Hyper-V virtual machine or WSL2 instance) where new models, tools and agents are ingested. In this plane the system:\n2. Clones or downloads candidate models, code and data.\n3. Builds them in an ephemeral sandbox so they cannot harm the host.\n4. Runs unit, integration and soak tests to generate scorecards, SBOMs (software bills of materials) and risk profiles.\n5. Uses built-in micro-agents to digest functions of the host OS-fingerprinting hardware (CPU/GPU/ TPU, RAM/VRAM, storage), OS primitives (Windows services, drivers, WSL/Hyper-V, registry keys), network topology and security posture. This environment graph anticipates mismatches and pre-configures caches, toolkits or rollback points.\n6. Produces evidence bundles for the coordinator.\n7. Coordinator/Control Plane - A control server (running on the same PC or a dedicated service) that:\n8. Maintains a capability registry and compatibility matrix.\n9. Evaluates sandbox scorecards for performance, cost and safety.\n10. Runs the Trifecta-Court: the executive commander proposes promotions; the legislative board sets policy thresholds; the judicial court runs static and dynamic checks (licenses, supply-chain provenance, jailbreak red-team prompts) and issues verdicts (approve, deny, conditional). If court vetoes, promotions stop.\n11. Manages feature flags, canary cohorts, budget enforcement and rollback triggers. It monitors performance and error budgets; breaches cause automatic rollbacks. This plane also selects optimal models and tools based on real-time telemetry.\n12. Deployed Application Plane - A packaged Windows application (.exe) that hosts the live agents. It includes:\n13. The NOA ExecutiveCommanderChiefAgent (the master orchestrator).\n14. A Board of domain-specific agents and ModelSelector agents that choose which micro-agents and models to use.\n15. Multiple micro-agent stacks, each comprising a CommandChief agent and one or more specialized micro-agents (for searching, coding, summarizing, planning, etc.). Micro-agents are created or shut down on demand.\n16. Storage subsystem: local databases (PostgreSQL with pgvector, or Qdrant/Chroma) for embeddings, MinIO or S3-compatible object storage for binaries and datasets, and a vector memory layer for retrieval-augmented generation.\n17. Dynamic UI built with Electron or a cross-platform framework that renders dashboards, logs and tool outputs in real time.\nTogether, these planes enable new capabilities to be ingested, tested, vetted and promoted automatically without disrupting the live system.\n3 Core Capabilities\nThe following features differentiate Ark-OS-NOA from simple agent frameworks:\n3.1 Local-First Operation\nRunning models and agents locally gives you total control over data, no network latency and no API costs. The Arsturn guide notes that a local AI agent operating system provides total privacy, low latency, offline operation and unlimited customization 1 . All models and data stay on your PC; nothing is sent to the cloud unless you explicitly permit it.\n3.2 Agentic Operating System Functions\nAn AI agent OS manages resources and orchestrates tasks for multiple agents . Ark-OS-NOA implements:\n Goal & Task Management: The ExecutiveCommander decomposes user goals into actionable tasks. High-level goals (e.g., \"digest all engineering docs and generate a micro-agent plan\") are broken into smaller tasks for micro-agents to execute.\n Perception & Input: Agents can ingest data from local files, websites (via offline cached content) and user input. The perception module tokenizes, classifies and embeds data into the memory layer for later retrieval.\n Memory & Knowledge: A vector database stores both short-term conversation history and long-term documents . Agents use retrieval-augmented generation (RAG) to query relevant embeddings when reasoning.\n Reasoning & Planning: The LLM kernel (see Section 4.6) enables agents to reason, plan and decide next steps. It manages context switching and concurrency. AIOS-inspired features such as intelligent resource management, context switching and parallel execution improve efficiency .\n Action & Tool Use: Agents can run code, call APIs, manipulate files and interact with the OS. Built-in tool managers handle external API calls, while micro-agents perform specialized tasks like generating Python code or summarizing documents.\n Orchestration & Scheduling: A scheduler assigns tasks based on resource availability and priority. The context manager saves and restores agent state 9 . The coordinator allows multiple agents to run in parallel 10 and ensures smooth context switching 11 .\n Granular Permissions: Every agent runs under a role-based permission model. Access to files, tools and network functions is controlled by policies in the Board's constitution 12 .\n3.3 Dynamic UI\nArk-OS-NOA provides a dynamic user interface that adapts to the current data structures and user permissions. The Orbitype analysis of agentic cloud OS notes that dynamic UI layers eliminate manual configuration by adapting interfaces to data and roles 5 . The NOA UI engine binds dashboard components (charts, logs, forms) to the underlying memory schema; when new vector tables or agent outputs appear, UI widgets are created automatically. Users can pin widgets, create custom layouts and monitor agent progress live.\n3.4 Offline Model Management\nModels are downloaded directly from Hugging Face and stored locally. To ensure offline operation you should:\n1. Download the model repository on a machine with internet access using git clone https:// huggingface.co/<model-id> or the huggingface-cli tool.\n2. Copy the repository into the NOA cache directory on the target machine (e.g., %USERPROFILE%\n\\.cache\\huggingface\\hub ).\n3. Set environment variables: \n$env:HF_HOME = \"$env:USERPROFILE\\.cache\\huggingface\"\n$env:HF_HUB_CACHE = \"$env:HF_HOME\\hub\"\n$env:HF_HUB_OFFLINE = \"1\"\nThe HF_HUB_OFFLINE variable prevents any HTTP calls and forces the library to read only cached files 6 .\n4. In your Python code, load models using from_pretrained with the local path: \nfrom transformers import AutoModelForCausalLM, AutoTokenizer model = AutoModelForCausalLM.from_pretrained(\"C:\\\\models\\\\llama-3\"); tokenizer = AutoTokenizer.from_pretrained(\"C:\\\\models\\\\llama-3\");\nBy caching models and setting HF_HUB_OFFLINE=1 , you can run inference and fine-tuning without any network connectivity 6 .\n3.5 Micro-Agent Stacks\nMicro-agents are tiny models or scripts that perform one specific task extremely well-extracting entities, summarizing a document, or classifying an email. A micro-agent:\n Focuses on a single task, uses minimal compute, runs locally and integrates easily into workflows\n13 .\n Provides speed, cost-efficiency, specialization, scalability and privacy benefits .\nArk-OS-NOA organizes micro-agents into stacks: each stack has a CommanderChiefAgent that orchestrates one or more micro-agents to accomplish a goal. For example, a \"Research Stack\" may include a web-search micro-agent, a summarization micro-agent and a citation manager. Stacks can be spawned or removed dynamically by the ExecutiveCommander; the coordinator monitors their performance and kills under-performing stacks.\n3.6 Resource Management and Parallelism\nBorrowing from AIOS, the coordinator implements intelligent resource management to allocate CPU/ GPU/IO resources based on real-time demand 14 . Smooth context switching allows agents to transition between tasks without losing state 11 , and parallel execution ensures that multiple micro-agents can run concurrently 10 . Built-in tools and utilities simplify agent development 15 , while granular permission systems enforce security 12 .\n3.7 7-Layer Stack Reference\nAlthough Ark-OS-NOA uses its own architecture, it draws inspiration from the open-source seven-layer agent stack described by FutureAGI: infrastructure, language model engine, agent framework, memory & context, tools & integrations, orchestration & workflows, and interfaces 16 . This modular stack highlights the importance of separating concerns so components can be replaced without rewriting the entire system. It also emphasizes vendor independence, scalability and cost control 17 .\n4 Installation Prerequisites\n4.1 Hardware Requirements\nComponent\tRecommendation\nOperating System\nWindows 11 Professional (64-bit) with latest updates and optional Hyper-V/WSL2 features enabled.\nCPU\nMulti-core (8+ cores preferred) to run micro-agents in parallel.\nGPU\nNVIDIA GPU with 6 GB VRAM for LLM inference; optional but recommended.\nMemory\n32 GB RAM or higher for running multiple models and vector databases.\nStorage\n1 TB SSD/NVMe; models and caches may consume hundreds of gigabytes.\nNetwork\nOnly required for initial downloads; offline operation thereafter.\n4.2 Software Dependencies\n1. Python 3.10+ - core language for agent logic. Install via the official Windows installer and add Python to your PATH.\n2. Git - used to clone model repositories and manage code.\n3. Node.js (optional) - required if you build the dynamic UI with Electron or Tauri.\n4. PostgreSQL - install the Windows distribution and enable the pgvector extension, or choose an alternative vector store like Qdrant or Chroma.\n5. MinIO - S3-compatible object storage server for caching models, datasets and SBOMs.\n6. PyTorch - for running transformer models; install the CUDA-enabled version if you have a GPU.\n7. Transformers and huggingface_hub libraries - for model loading; install with pip.\n8. LangChain or LlamaIndex - for building agent flows and retrieval-augmented generation.\n9. PyInstaller - to package the Python application into a standalone Windows executable. It can be installed via pip: pip install pyinstaller 18 .\nNote: When using PyInstaller, ensure you also install the matching pyinstaller-hookscontrib package. After installation, verify the command is available with pyinstaller -version 18 . The final build step will package your Python scripts, dependencies and data into a single .exe file.\n5 Preparing Your Environment\n5.1 Set Up Python Environment\n\n3. Install core packages: \npip install torch transformers huggingface_hub langchain llama-index pgvector psycopg2-binary minio uvicorn fastapi pip install pyinstaller pyinstaller-hooks-contrib\n5.2 Download and Cache Models\nTo run models offline:\n1. On a machine with internet access, clone the desired models and tokenizers: \ngit lfs install git clone https://huggingface.co/meta-llama/Llama-3-8B-instruct C: \\models\\llama-3-8b\n2. Copy the directory to the target PC (e.g., C:\\models ).\n3. Set environment variables as described in Section 3.4 to force offline mode 6 .\n4. Verify offline loading by running a quick script: \nfrom transformers import AutoModelForCausalLM, AutoTokenizer model_path = \"C:\\\\models\\\\llama-3-8b\" tokenizer = AutoTokenizer.from_pretrained(model_path) model = AutoModelForCausalLM.from_pretrained(model_path) print(tokenizer.decode(model.generate(tokenizer.encode(\"Hello\", return_tensors=\"pt\"), max_length=20)[0]))\nThe script should run without internet. If it attempts to fetch remote files, ensure that HF_HUB_OFFLINE=1 is set.\n5.3 Install Vector Database\n\n3. Define tables for embeddings (id, doc_id, vector, metadata). Use LangChain or LlamaIndex connectors to store and retrieve embeddings.\nOption B - Qdrant or Chroma\n1. Download prebuilt Qdrant binary (a single executable) or run via Docker for Windows. Qdrant is optimized for high-dimensional vectors and can run offline.\n2. Configure persistent storage path in the configuration file. Use the Python qdrant-client to upsert and search vectors.\n5.4 Set Up Object Storage\nRun MinIO as a Windows service or inside a container. MinIO will store large files (models, datasets, SBOMs) in an S3-compatible API. Configure a bucket called arkos with versioning. Set environment variables for access key and secret key in your micro-agent scripts.\n5.5 Install and Configure LangChain/LlamaIndex\nUse LangChain or LlamaIndex to build agentic workflows. Define a tool for each micro-agent (e.g., search_tool , code_executor , summarizer ) and register them in a central AgentToolkit . Create a custom planner (ReAct, tree-of-thought, or T-ultra) that sequences tools. LangChain's MultiActionAgent or LlamaIndex's ServiceContext can orchestrate micro-agents to fulfil a goal.\n6 Building Ark-OS-NOA\n6.1 Project Structure\nOrganize your repository as follows (example):\narkos/\n+-- noa_app/                 # Python package for the NOA application\n   +-- __main__.py          # Entry point - runs the ExecutiveCommander\n   +-- commander.py         # ExecutiveCommanderChiefAgent implementation    +-- board_agents/\n      +-- board.py         # Board orchestrator and policy definitions\n      +-- digest_agent.py  # Research/Digest agent associated with the board\n      +-- model_selectors.py # ModelSelector agents\n   +-- stacks/\n      +-- __init__.py\n      +-- research_stack.py # Example micro-agent stack       +-- ...\n   +-- tools/\n      +-- search.py        # Micro-agent tools (search, code execution, etc.)\n   +-- sandbox/\n      +-- sandbox_runner.py # Functions to create and manage sandbox VMs/ containers\n   +-- coordinator/\n      +-- registry.py      # Capability registry and metadata store\n      +-- court.py         # Trifecta-Court implementation\n      +-- promotion.py     # Promotion controller (canary and rollback logic)\n   +-- ui/\n      +-- main.tsx         # React/Electron UI entry\n      +-- components/      # UI components and dashboards\n   +-- config.py            # Configuration (paths, environment variables)\n+-- models/                  # Cached Hugging Face models\n+-- build_scripts/\n    +-- package.py           # PyInstaller build script\n    +-- generate_sbom.py     # Script to generate SBOMs\nThis structure separates concerns: core logic, agent definitions, sandbox functions, coordinator services and UI. You can adjust names to match your preferences.\n6.2 Implementing the Executive Commander\nThe ExecutiveCommanderChiefAgent is the heart of the deployed plane. It:\n1. Loads configuration and environment variables.\n2. Connects to the vector database and object storage.\n3. Initializes the Board agents and ModelSelector agents, passing them memory and tool references.\n4. Listens for user goals (entered through the UI or read from a file) and decomposes them into tasks.\n5. Delegates tasks to micro-agent stacks. If a stack does not exist for a task, it asks the board to deploy one.\n6. Monitors stack outputs and resolves dependencies. When all sub-tasks are complete, it returns the result to the user.\n7. Records telemetry (latencies, errors, resource use) and sends it to the coordinator for analysis.\nThe commander can be implemented as an asynchronous Python class using asyncio . The board and model-selector agents can run in their own threads or processes. Each micro-agent should be stateless where possible so that the commander can shut it down or respawn it as needed.\n6.3 Building Micro-Agent Stacks\nDefine micro-agents as Python functions or classes with a consistent interface (e.g., run(input: dict) -> dict ). Example micro-agents might include:\n IngestAgent - reads files and embeds them in the vector database.\n SearchAgent - queries the vector database or offline web cache using semantic search.\n SummarizeAgent - summarizes text using a local summarization model.\n CodeExecutorAgent - runs code in a secure sandbox and returns results or errors.\n PlanAgent - uses the LLM to plan sequences of actions.\nGroup related micro-agents into a stack. Each stack has a CommanderChief that:\n1. Initializes micro-agents.\n2. Accepts tasks from the ExecutiveCommander.\n3. Schedules micro-agents in the appropriate order.\n4. Aggregates outputs and returns a combined result.\nDesign stacks to be composable-stacks can call other stacks as subroutines. For instance, a \"Digest Stack\" may use the SearchAgent to fetch data and then the SummarizeAgent to digest it.\n6.4 Implementing the Coordinator and Court\nThe coordinator runs as a separate service (could be a FastAPI app) that:\n1. Registers capabilities: Each new model, tool or micro-agent is represented as a capability document (YAML or JSON) with metadata about purpose, inputs/outputs, dependencies, risks and tests.\n2. Runs promotions: The promotion controller selects candidate capabilities from the sandbox, reads their scorecards and decides whether to canary them in production. It uses thresholds defined by the legislative board (latency increase 10 %, failure rate 0.5 %, cost delta 5 %, zero safety events). Breaches trigger auto-rollback.\n3. Operates the Trifecta-Court: The court enforces policy by performing static checks (license compliance, supply-chain integrity, RBAC) and dynamic checks (prompt injection tests, privacy analysis). It can veto, approve or approve with conditions. Courts can also revoke capabilities if telemetry later shows they violate policy.\n4. Maintains the capability registry: A database mapping capability IDs to versions, statuses (sandbox, canary, production), SBOMs and risk profiles.\nImplementing the court requires writing rules in a domain-specific language or using a policy engine like [Open Policy Agent]. The board defines the constitution as code, and the court runs that code automatically. Court decisions are logged and auditable.\n6.5 Building the Dynamic UI\nThe UI can be built with Electron, Tauri or a .NET UI toolkit. Key features:\n Dashboard: shows active agents, stacks, tasks, and their status. Data visualizations update automatically using websockets or an event bus. The UI must support dynamic creation of widgets when new micro-agents or vector tables appear .\n Goal Input: a text box for entering high-level goals. When submitted, the ExecutiveCommander receives the goal via a local API (FastAPI/Flask) and begins planning.\n Logs & Telemetry: real-time feed of logs from agents, sandbox runs, promotions and court verdicts. Users can drill down into SBOMs and test results.\n Settings: configuration panel for environment variables, resource budgets, offline caches and role permissions.\nWhen packaging the application, include the UI bundle within the noa_app\\ui folder and serve it using a local HTTP server or directly from Electron.\n6.6 Packaging into a Windows Executable\n1. Ensure all Python modules are installed within the virtual environment.\n2. Use PyInstaller to build the application. Create a spec file if your application requires data files, models and external binaries: \n\n3. Run the build script: \nPyInstaller will create dist\\arkos-noa.exe . When launched, this executable starts the ExecutiveCommander, spins up the coordinator (if configured to run locally), launches the UI and initializes micro-agent stacks. Terminal commands (setting environment variables, starting MinIO, launching Postgres) should be executed automatically in Python via subprocess or os.system .\nProvide clear log messages and handle errors gracefully.\n4. Test the .exe on a clean Windows 11 VM to verify that all dependencies are bundled. If missing DLLs or libraries are reported, add them to the spec file.\n5. Sign the executable with a code-signing certificate if distributing to others.\n7 Operational Workflow\n7.1 Starting the System\n1. Launch arkos-noa.exe . The application should display the UI and log messages indicating initialization.\n2. On first run, the application will fingerprint the host environment (OS version, CPU/GPU, memory, storage, network) and build an Environment & Function Graph. This information influences model selection and sandbox preparation (e.g., pre-staging CUDA libraries on systems with GPUs).\n3. The ExecutiveCommander loads existing micro-agent stacks and capabilities from the registry. It also starts watchers for drift detection (SBOM deltas, version updates, resource anomalies).\n4. The UI shows the system state: stacks, agents, resource usage and pending promotions. 7.2 Running a Goal\n1. Enter a goal in the UI (e.g., \"Summarize the last quarter's sales data\").\n2. The ExecutiveCommander decomposes the goal into tasks and selects appropriate stacks. For example, it might deploy a DataIngestStack to ingest spreadsheets, a AnalysisStack to compute metrics and a SummaryStack to generate natural-language summaries.\n3. Each stack runs its micro-agents. The SearchAgent queries the vector DB; the SummarizeAgent uses a local summarization model; the CodeExecutor runs Python scripts if needed.\n4. When all tasks are complete, the commander aggregates results and returns them to the UI.\n5. Telemetry is sent to the coordinator for monitoring and learning. If tasks breached budgets (e.g., high latency), the coordinator logs the event and may adjust model selection or trigger a rollback of the offending capability.\n7.3 Adding New Capabilities\n1. Copy or clone the new model/tool/agent into the sandbox input directory. Create a capability specification (YAML) describing its purpose, inputs/outputs, dependencies, risks and tests.\n2. The sandbox runner detects the new capability and spins up an isolated VM/container. It installs dependencies, runs unit and integration tests, collects SBOMs and risk metrics.\n3. The sandbox sends the scorecard and SBOM to the coordinator. The Board evaluates the results against policy thresholds and passes the request to the Court.\n4. The Court applies constitutional checks (license compliance, supply chain integrity, dynamic red-teaming) and returns a verdict (approve, approve with conditions or reject). Conditional approvals may require enabling kill-switches or limiting resource usage.\n5. If approved, the promotion controller runs a canary deployment: enabling the capability for a small percentage of tasks or limited time. It monitors latency, error rates, cost and safety. If metrics are within thresholds, the capability is promoted to production; otherwise it is rolled back automatically.\n7.4 Updating and Self-Upgrading\nArk-OS-NOA can self-upgrade by ingesting new versions of existing models or agents. When drift watchers detect that a model has an available upgrade, they trigger the sandbox pipeline. The Court ensures that upgrades do not introduce regressions or violate policy. Promotions follow the same canary process. All upgrade decisions are logged for audit.\n8 Security and Compliance\nArk-OS-NOA is designed with privacy and security as first principles. Key practices include:\n Local storage - all data, models and logs remain on the host. Internet access is optional and disabled by default.\n Role-based access control - Board agents define which micro-agents can access particular files, networks or devices. Sensitive operations require human approval.\n SBOMs and provenance - The sandbox generates SBOMs for all capabilities, enabling supply-chain auditing and license compliance. The Trifecta-Court rejects capabilities that violate open-source licenses or originate from untrusted sources.\n Environment isolation - Sandbox VMs/containers ensure that new code cannot impact the deployed environment until it passes testing.\n Secure secrets - Secrets (API keys, credentials) are sealed to the Windows Data Protection API (DPAPI) and never exposed to agents directly.\n Audit logging - All actions (goal submissions, promotions, court verdicts, rollbacks) are logged and tamper-evident.\n9 Extending Ark-OS-NOA\n Create new micro-agents by adding Python modules implementing the run() interface. Update the stack configurations and capability specifications accordingly. Use the sandbox to test them.\n Add new models by downloading them offline and adding them to the cache. Update the model selector configuration to include the new model and its supported tasks.\n Customize UI dashboards by editing the ui/components directory. Use dynamic data binding to display new metrics or logs.\n Integrate hardware sensors by writing micro-agents that query Windows APIs (e.g., WMI for system health) and ingest results into the environment graph.\n10 Conclusion\nArk-OS-NOA combines the privacy and performance advantages of local-first AI with the power of agentic architecture. Its micro-agent stacks, dynamic UI and Trifecta-Court governance provide a robust framework for building autonomous, self-upgrading applications that can run offline on Windows 11 Professional. By following this manual-setting up your environment, caching models, implementing the agent framework, configuring the coordinator and packaging the system as an executable-you can build a comprehensive AI operating layer that digests everything, adapts to its host and orchestrates complex workflows without external dependencies.\n\n1\t2\t7 Build a Local AI Agent Operating System: A Complete Guide\nhttps://www.arsturn.com/blog/building-a-local-first-ai-agent-operating-system-a-guide\n3\t4 13 The Rise of AI Micro-Agents: Tiny Models Automating Big Tasks - DEV Community\nhttps://dev.to/koolkamalkishor/the-rise-of-ai-micro-agents-tiny-models-automating-big-tasks-386m\n 5 Orchestrate Apps with Orbitype's Agentic Cloud OS https://www.orbitype.com/posts/nMGYCZ/orchestrate-apps-with-orbitypes-agentic-cloud-os\n 6 Environment variables\nhttps://huggingface.co/docs/huggingface_hub/en/package_reference/environment_variables\n 8\t9 10 11 12 14 15 Understanding AI Agent Operating Systems: A Comprehensive Guide https://www.ema.co/additional-blogs/addition-blogs/ai-agent-operating-systems-guide\n 16 17 Open-Source AI Agent Stack 2025: Complete Enterprise Guide https://futureagi.com/blogs/open-source-stack-ai-agents-2025\n18 How to Install PyInstaller - PyInstaller 6.15.0 documentation\nhttps://pyinstaller.org/en/stable/installation.html\n1\n\n1\n\n1\n\n"
      },
      "docs/Ark-AI-NOA_The Local-First Agentic OS.txt": {
        "language": "binary",
        "encoding": "base64",
        "code": "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"
      },
      "docs/arkos-expanded-explained.txt": {
        "language": "text",
        "code": "\n# ark‑os‑noa: Expanded Explanation & Intelligence Playbook\n\nThis document provides an exhaustive description of the ark‑os‑noa platform and expands on how intelligence forms and grows within the system.  It also explains how virtual hard disk (VHDX) images could be used within this architecture and offers an extended framework for **Branchwise Foresight & Mind Mapping**.  The content consolidates information from the system’s design documents and our discussions to ensure no details are omitted.\n\n## 1. Recap of Core Components\n\n### NOA – ExecutiveCommanderChiefAgent\nNOA stands at the top of the hierarchy.  It transforms high‑level business goals into actionable work plans, assigns Board Agents and **MicroAgentStacks**, enforces policies and model selection, and ensures packaging and archiving.  NOA prohibits privileged Docker‑in‑Docker usage, instead relying on sidecars and outer BuildKit/containerd to run builds securelyhttps://stackoverflow.com/questions/76224543/multiple-microservices-in-one-docker-container#:~:text=Show%20activity%20on%20this%20post.\n\n### Board Agents\nThe Board Agents act like an executive team.  Each owns a domain (Strategy/CTO, COO, CFO, Legal, Security, Growth/Partnerships and Digest).  They commission MicroAgentStacks, enforce policies, request ModelSelector assistance and govern spending, risk, compliance and partnerships.  The Digest Agent sits here and acts as R&D.\n\n### ModelSelectorAgents\nModelSelectorAgents choose the optimal AI model or tool per task.  They consider task type, input size, privacy tier, latency budget and cost.  Decisions and rationales are logged for audit.  The selector draws on a catalogue of local and remote models, cost/latency forecasts and model performance telemetry.\n\n### MicroAgentStacks\nA MicroAgentStack is an on‑demand work pod containing a **CommandChiefAgent**, Operators, Adapters and Guards.  It runs through a five‑stage lifecycle (Bootstrap, Execute, Validate, Package, Archive).  Each stack uses the Capsule pattern to avoid nested Docker and relies on sidecars to talk to the outer runtimehttps://stackoverflow.com/questions/76224543/multiple-microservices-in-one-docker-container#:~:text=Show%20activity%20on%20this%20post.\n\n### Digest Agent\nThe Digest Agent digests code, data, APIs, SaaS and AI models.  It performs discovery, fetching, parsing, analysis, summarisation, surfacing and security scanning.  Outputs include digest reports, knowledge graphs, embeddings and SBOM/security reports.\n\n### Backend Services\nThe digest pipeline is decomposed into microservices—Intake, Classifier, Graph Extract, Embeddings, Environment Synthesis, Safety, Runner, Integrator and Registrar—plus auxiliary services such as the CRM Strangler Proxy and Model Serving.  These services communicate via an event bus (Redis Streams) and run inside the Capsule environment.\n\n### Data & Storage Plane\nThe platform uses a private OCI registry, MinIO object storage, Postgres (plus Supabase for developer convenience) and a vector store (pgvector or Qdrant).  Policies enforce immutability, lineage, retention, least‑privilege access and provenance tracking.  Secrets are stored in Vault and never passed via environment variables.\n\n### Combined Framework & Architecture\nThe system layers strategy (NOA, Board Agents), execution (MicroAgentStacks, services), infrastructure (Capsule, event bus, data plane) and intelligence (ModelSelectorAgents, Digest Agent).  This modular architecture allows horizontal scaling, robust security and continuous adaptationhttps://stackoverflow.com/questions/76224543/multiple-microservices-in-one-docker-container#:~:text=Show%20activity%20on%20this%20post.\n\n### APIs, Connectors & Front‑End\nThe Gateway API (FastAPI) exposes endpoints for digesting sources, spawning capsules, toggling CRM behaviours, ingesting models and administering the system.  Connectors (GitHub, CRM, model hub, etc.) encapsulate external integrations, while the Next.js Admin Console offers dashboards for jobs, capsules, artefacts, SBOMs, models and CRM controls.\n\n## 2. Forming and Growing Intelligence\n\nark‑os‑noa develops intelligence by moving information through a series of **stages** that progressively enrich raw data into actionable knowledge.  Each stage interacts with the data storage model to persist intermediate artefacts and enable feedback loops.\n\n### Stage 1: Discovery & Ingestion\n\n* **Trigger:** A Board Agent or NOA identifies sources to digest—repositories, APIs, CRMs, datasets or models.\n* **MicroAgentStack:** An intake stack uses Adapters to authenticate and fetch sources.  Provenance and commit metadata are recorded in Postgres and the registry.\n* **Data Storage Integration:** Raw sources and metadata are stored in the object store (MinIO) and registry (for images).  Each artefact is content‑addressed and tagged for retrieval.\n\n### Stage 2: Parsing & Semantic Representation\n\n* **Parsing:** The Graph Extract service uses language‑specific parsers (Python AST, ts‑morph, go/ast, Rust syn, JavaParser) and schema parsers (OpenAPI, GraphQL) to build call graphs and extract symbols, types, endpoints and configuration surfaces.\n* **SBOM Generation:** The Safety service employs tools like Syft to construct a software bill of materials—enumerating dependencies and licences.\n* **Knowledge Graphs:** Extracted entities and relationships are formalised into `kg.json` files.  These graphs create a structured view of the system’s architecture and interactions.\n* **Storage Integration:** Graphs, SBOMs and system cards are saved in MinIO and recorded in Postgres.  Graph edges link to original files stored in MinIO and to digests in the registry.\n\n### Stage 3: Embeddings & Semantic Indexing\n\n* **Embedding Generation:** The Embeddings service segments code and documentation into chunks and converts them into vector embeddings via models selected by a ModelSelectorAgent (e.g. sentence transformers or llama.cpp embeddings).\n* **Vector Store Upsert:** Embeddings are stored in pgvector or Qdrant along with metadata referencing their source file and graph node.  This provides a searchable semantic index across all digested artefacts.\n* **Storage Integration:** The embedding index resides in the vector store; each upsert is logged in Postgres.  The embedding models themselves are stored as OCI images or in MinIO.\n\n### Stage 4: Model Evaluation & Selection\n\n* **Benchmarking:** When new models are ingested, the Model Serving service runs benchmarks, measuring latency, cost and accuracy on representative workloads.  Results feed back into the ModelSelector’s knowledge base.\n* **Selection:** For each task, a ModelSelectorAgent decides which model to use based on task classification, complexity, privacy tier and constraints.  The decision, rationale, predicted cost and latency are logged in the Trace.\n* **Execution:** The chosen model processes the task.  Outputs (summaries, embeddings, classifications) are stored in MinIO/pgvector and linked to the run ID.\n* **Storage Integration:** Benchmark results and model metadata live in Postgres/Supabase; model artefacts (e.g. GGUF files) live in MinIO or the registry.\n\n### Stage 5: Feedback, Learning & Adaptation\n\n* **Trace Analysis:** After execution, the Registrar Service writes a Trace capturing inputs, actions, models used, outputs, durations and outcomes.  These traces accumulate in Postgres and are used to compute success patterns, failure modes, cost hot‑spots and other metrics.\n* **Policy Adjustment:** NOA and Board Agents review aggregated telemetry to update model selection policies, budgets, licence allow lists and vulnerability thresholds.  The ModelSelector’s heuristics may be retrained or replaced by learned policies.\n* **Auto‑patch Loop:** When tests fail or vulnerabilities are discovered, Graph Extract proposes code modifications; Runner applies patches and reruns tests; Safety verifies the fix.  Approved patches may be offered back to source repositories via PRs.\n* **Storage Integration:** Traces and telemetry live in Postgres; updated policies are saved in configuration repositories and reflected in subsequent runs.\n\n### Stage 6: Foresight & Strategic Planning\n\n* **Mind Mapping:** Using the knowledge graph and embeddings, the system constructs mind maps—visual representations of relationships between components, domains and tasks.  These maps help identify impact areas, missing connections and potential integration opportunities.\n* **Branchwise Foresight:** The Board and NOA employ scenario planning and decision‑tree analysis to evaluate multiple future paths before committing resources.  This process is described in detail below and uses the knowledge base built in earlier stages.https://www.databricks.com/blog/generalists-specialists-evolution-ai-systems-toward-compound-ai#:~:text=We%E2%80%99re%20seeing%20the%20same%20evolution,aren%E2%80%99t%20perfect%20for%20every%20job\n* **Learning Simulation:** For major decisions, MicroAgentStacks can simulate different courses of action (e.g. migrating a CRM function internally versus keeping it external) using test workloads, synthetic data or replayed traffic.  The results feed into the Branchwise Foresight evaluation.\n* **Storage Integration:** Mind maps, decision trees and simulation outputs are stored in MinIO and Postgres.  They are versioned and linked to the decisions they informed.\n\n## 3. Integrating VHDX Files\n\n### What is a VHDX?\n\nA **VHDX** is a virtual hard disk format used by Hyper‑V and other hypervisors to represent disk images.  It can contain an entire filesystem and operating system.  Using VHDX files in ark‑os‑noa can provide a portable, reproducible environment for running MicroAgentStacks or preserving states.\n\n### Integration Strategies\n\n1. **Stack Packaging:** Each MicroAgentStack could be exported as a VHDX image at the end of its lifecycle.  This captures the exact file system state (including compiled artefacts, logs and caches) and can be rehydrated later for forensic analysis or reproducibility.  The VHDX would be stored in MinIO and content‑addressed via SHA‑256.\n\n2. **Nested VHDX (VHDX inside VHDX):** For complex stacks with multiple layers (e.g. a Capsule hosting several nano‑containers), nested VHDX images could represent inner environments.  The outer VHDX would contain the base OS and capsule tooling; each inner VHDX would encapsulate a nano‑container’s root filesystem.  This structure mirrors the Capsule pattern—outer environment owns security and shared resources, while inner environments remain isolated.\n\n3. **Offline Mobility:** VHDX files enable offline mobility.  A stack can be paused, exported as VHDX, moved to another host and resumed without network dependence.  This can be useful for air‑gapped deployments or regulated environments requiring offline review.\n\n4. **Testing & Rollback:** By snapshotting a stack’s VHDX before a risky operation, the system can roll back to a known good state if the operation fails.  This complements the auto‑patch loop by allowing stateful rollback in addition to code‑level diffs.\n\n5. **Integration with Data Plane:** VHDX files are large binary objects, so they should be stored in MinIO with lifecycle policies (e.g. retain for 30 days).  Metadata referencing a VHDX (stack name, run ID, size, hash) would be stored in Postgres.  When nested VHDX files are used, their parent‑child relationships are recorded in the metadata to facilitate reconstruction.\n\nBy using VHDX files judiciously, ark‑os‑noa can complement container‑based Capsule environments with OS‑level snapshots and offline portability.  However, they should be employed for advanced scenarios (archival, forensic, regulated deployments) and not replace the lightweight container workflow in everyday operations.\n\n## 4. Expanded Branchwise Foresight & Mind Mapping\n\n**Branchwise Foresight** is a disciplined way to explore multiple possible futures, assess risks and rewards, and choose resilient strategies.  It combines scenario planning, decision trees, premortems, expected value (EV)/regret analysis and tripwire instrumentation.\n\n### The 7‑Step Playbook (Fast, Ruthless, Repeatable)\n\n1. **Lock the Target & Guardrails:** Clearly define the decision, success metric and 3–5 non‑negotiables (legal, cash, brand, time).  If an option violates a guardrail, prune it immediately.\n\n2. **Expose the Drivers & Uncertainties:** Identify a handful of variables that truly drive outcomes (e.g. price, latency, adoption, regulation, supply).  Assign low/base/high ranges for each; avoid overfitting.\n\n3. **Sketch the Path Lattice:** Draw 3–5 key decision points over time, with 2–3 actions at each point.  This forms a branching futures map.  Keep branches manageable (≤12); complexity will explode if unchecked.\n\n4. **Run a Premortem on Every Branch:** For each branch, imagine it’s six months later and the path has failed—why?  Capture failure modes, single points of failure and hidden couplings.  Use this to refine or prune branches.\n\n5. **Score Quickly:** Evaluate each branch using:\n   - **Expected Value (EV):** Rough calculation across the variable ranges; it need not be precise—directional estimates suffice.\n   - **Regret:** Minimise how bad it would feel if a different path wins big.  Lower regret is better.\n   - **Reversibility:** Ask whether the decision is a one‑way door.  If a path is reversible and upside > downside, favour action.\n\n6. **Choose a Robust‑Best Path:** Pick options that can survive variance and still succeed.  Prefer robustness over fragility; antifragile options that benefit from volatility are ideal.  Pre‑wire tripwires (leading indicators and thresholds) and pivot branches in advance.\n\n7. **Instrument & Iterate:** Define 3–5 leading indicators (e.g. customer acquisition cost trend, cycle time, approval status) linked to thresholds.  Review metrics on a cadence; update probabilities and prune or grow branches accordingly.  If a path breaches a tripwire, pivot to the predetermined alternative.\n\n### How to Identify Wrong Paths Fast\n\n* **Dominated:** If a branch performs worse on every key criterion versus another branch, kill it.\n* **Non‑reversible + Low Upside:** Avoid one‑way doors with limited payoff.\n* **Single‑Point Catastrophic Risk:** If one failure knocks you out completely, redesign or drop that path.\n* **Goodhart Traps:** Paths that win only by gaming metrics rather than creating real value should be discarded.\n* **Dependency Hell:** Too many external approvals or partners on the critical path → defer or re‑sequence.\n* **Cashflow Cliff:** Burn rate exceeds runway before hitting a milestone that unlocks financing → re‑scope.\n\n### Scoring Grid Example\n\n```\nPath   EV (0–10)   Regret (0–10, lower=better)   Reversible?   Time to Signal   Key Tripwire\nA      7           4                              Yes           2 weeks          CAC > $X for 2 sprints\nB      9           2                              No            8 weeks          Partner MSA signed by D+60\nC      6           6                              Yes           1 week           NPS < Y for 2 cycles\n```\n\nIn this example, Path B has the highest EV but is irreversible.  Following the playbook, you would only choose Path B if you had two independent green lights (e.g. tripwire + milestone).  Otherwise, you’d pick Path A or C based on EV, regret and how quickly you can detect issues.\n\n### Mini‑Toolbox\n\n* **Decision Tree:** Map decisions into a tree with uncertainties at each node.\n* **Premortem:** Use Gary Klein’s technique to surface failures upfront by assuming failure and working backwards.\n* **Monte Carlo Simulation:** For the few variables that matter, run simulations to quantify uncertainty ranges.\n* **Regret Analysis:** Construct a min‑max regret table to evaluate large bets with fat tails.\n* **Backcasting:** Start from the desired win state and work backwards to plan actions.\n* **Red Team:** Assign someone or an AI agent to critique and stress‑test your favourite path.\n\n### AI Prompts for Branchwise Foresight\n\nThese prompts can be issued to a ModelSelectorAgent or LLM for deeper analysis:\n\n* **Failure Enumeration:** “List the top 10 ways Path X fails.  For each, give early warning signals, likelihood (L/M/H), impact (1–10), and a mitigation or redesign.”\n* **Decision Tree Generation:** “Build a 3‑level decision tree for this choice with branches for [uncertainty A/B/C]; mark irreversible nodes.”\n* **Regret Table:** “Provide a min‑max regret table for Paths A/B/C across these ranges: [ranges].  Recommend the robust‑best option.”\n* **Tripwire Proposal:** “Propose tripwires (metric + threshold + time window) that trigger pivot from Path A → B.”\n\n### Common Failure Patterns to Avoid\n\n* **Analysis Paralysis:** Spending excessive time perfecting trees; keep the branch count manageable and iterate.\n* **Point Estimates:** Treating uncertain variables as fixed numbers; use ranges or distributions instead.\n* **Vanity KPIs:** Focusing on metrics that move but don’t matter; tie tripwires to cash, time or risk.\n* **Sunken‑Cost Loyalty:** Refusing to pivot after a tripwire fires because of the sunk costs.\n\n### One‑Page Output Template\n\nEvery Branchwise Foresight exercise should produce a concise summary:\n\n1. **Decision, Success Metric & Guardrails**\n2. **Path Lattice (thumbnail)**\n3. **Premortem Highlights (top 5 risks)**\n4. **EV/Regret/Reversibility Table**\n5. **Chosen Path & Immediate Next Action**\n6. **Tripwires & Pivots (who monitors, thresholds)**\n\nThis summary becomes part of the run’s Trace and informs future learning.  The knowledge graph records the relationships between decisions, variables, models, outcomes and the selected path.\n\n## 5. Integration of Branchwise Foresight with Intelligence Growth\n\nBranchwise Foresight is not a separate process; it is embedded in the intelligence stages:\n\n* During **discovery and parsing**, the system identifies decision points and uncertainties (e.g. external dependencies, licensing risks).\n* The **knowledge graph** and **embeddings** allow the system to map options to underlying entities and drivers.\n* **Model evaluation** helps estimate outcomes of different paths (e.g. time to develop internal CRM vs. cost of using external CRM).  Benchmarks feed EV calculations.\n* **Feedback loops** update probabilities and regrets based on real outcomes, making future foresight exercises more accurate.\n* Branchwise Foresight outputs (decision trees, scoring tables) are stored in Postgres and MinIO, indexed for future retrieval.  Over time, the system learns which foresight heuristics correlate with success and can refine them.\n\n## Conclusion\n\nark‑os‑noa is a sophisticated agentic platform that blends microservices, secure container orchestration, internal data planes and AI.  Intelligence emerges through a pipeline of discovery, semantic representation, model selection, feedback loops and strategic foresight.  The data plane underpins every stage by storing artefacts, metadata, embeddings and decision traces with immutability and provenance.  VHDX files offer an optional mechanism for packaging and migrating entire environments or nested capsules, complementing container‑based workflows.\n\nBy integrating Branchwise Foresight and Mind Mapping, the system enables robust, informed decision making.  It systematically maps options, evaluates trade‑offs and sets up tripwires to pivot early.  Coupled with continuous learning from past runs and model evaluations, ark‑os‑noa can navigate complex, uncertain landscapes and continue to evolve its intelligence."
      },
      "docs/backend.md": {
        "language": "markdown",
        "code": "# Backend — Services & Infrastructure of ark‑os‑noa\n\n## Purpose\n\nThe **backend** of ark‑os‑noa comprises all of the runtime services and infrastructure that turn high‑level plans into concrete work.  It includes the event bus, microservices that implement the **Expanded Digest Pipeline**, sidecars that enable the **Capsule** pattern, and internal data stores.  Together, these components provide a robust, scalable and secure environment for executing tasks, orchestrated by NOA and the Board Agents.\n\n## Services & Microservices\n\n### Core Pipeline Services\n\nThe digest‑everything pipeline is decomposed into a series of microservices, each responsible for a discrete stage.  Running them as independent services ensures that each can scale, fail and be updated independently, which is aligned with microservice best practices【43537238352704†L1068-L1088】.\n\n1. **Intake Service:** Receives digest requests; validates inputs (repo URLs, API endpoints, model lists); creates provenance records and initializes workspace directories.\n2. **Classifier Service:** Detects programming languages, build systems, service types (CLI, API, library) and licences.  Produces a `profile.json` summarising the source.\n3. **Graph Extract Service:** Parses code and schemas to build call graphs, data flow graphs and config surfaces.  Supports multi‑language parsing (Python, JS/TS, Go, Rust, Java).  Outputs `kg.json` and `system_card.md`.\n4. **Embeddings Service:** Generates embeddings for code and documentation using models selected by ModelSelectorAgents.  Upserts vectors to pgvector or Qdrant.\n5. **Env Synthesis Service:** Emits Dockerfiles, docker‑compose YAML, Kubernetes manifests, `.env.example`, `Makefile` targets and config schemas.  Ensures reproducible builds using outer BuildKit (no DinD).\n6. **Safety Service:** Runs SBOM generation (Syft), vulnerability scans (Grype/Trivy), secret scans (Gitleaks) and static analysis (Semgrep).  Applies policy gates; stops the pipeline on critical issues.\n7. **Runner Service:** Builds and runs the source in a controlled container environment; executes existing tests or generates smoke tests; produces `demo.md`.\n8. **Integrator Service:** Generates adapters (SDKs for Python, Node, Go), telemetry hooks and policy stubs; prepares packaging instructions.\n9. **Registrar Service:** Writes outputs and metadata to storage (registry, MinIO, Postgres); registers embeddings; updates indexes for search.\n\n### Auxiliary Services\n\n* **CRM Strangler Proxy:** Provides a transparent layer between internal clients and an external CRM.  It records requests/responses, supports *shadow* and *write‑through* modes, and allows incremental internal re‑implementation of CRM features.\n* **Model Serving:** Hosts local models using frameworks like llama.cpp, Ollama or vLLM.  Exposes endpoints for inference and embedding generation.  Each model server is packaged in its own container with health checks.\n* **Gateway API:** A FastAPI service exposing endpoints: `/digest`, `/capsule/spawn`, `/crm/toggle`, `/models/ingest`, `/models/benchmark`, `/admin/*`.  Acts as the single entry point for external clients and the front‑end.\n\n## Event Bus & Orchestration\n\n* **Redis Streams:** Provides the primary event bus for inter‑service communication.  Services consume and produce events in a decoupled fashion.  The bus also supports message persistence and backpressure.\n* **NATS (optional):** A lightweight publish/subscribe system for high fan‑out or cross‑cluster communication.  Enabled via a feature flag.\n* **Workflow Engine:** A simple DAG engine built on Redis to coordinate pipeline tasks with retries and backoff.  Temporal or Argo Workflows can be integrated later for more sophisticated orchestrations.\n\n## Capsule Sidecars\n\nAll containers run inside a “Capsule” to simulate container‑in‑container and Kubernetes‑in‑Kubernetes workflows without the security and performance drawbacks【716409907369096†L1037-L1067】.  Capsule sidecars include:\n\n1. **Build‑Proxy:** A lightweight service that proxies inner `docker build` and `nerdctl` commands to the outer BuildKit daemon.  It exposes a local socket inside the Capsule but forwards build requests externally, avoiding duplicate layer storage.\n2. **Service‑Mirror:** Watches inner service definitions and publishes corresponding services in the outer service mesh with mTLS and SLO configurations.  This allows inner services to be reachable and observable from the outer plane.\n3. **Policy Agent (OPA):** Enforces egress rules, resource quotas, and other policies at the Capsule boundary.  It integrates with eBPF to block unauthorised traffic.\n4. **Telemetry Agent:** Collects traces, metrics and logs from the inner services and sidecars.  It forwards data to the central observability stack with proper trace‑ID propagation.\n5. **vcluster (optional):** Provides a lightweight Kubernetes API server inside the Capsule for tools that require kubectl.  It maps pods to the parent cluster’s nodes without duplicating container runtimes.\n\n## Data Stores\n\n* **OCI Registry:** Stores container images, compiled outputs and Capsule definitions.  The registry uses content‑addressed storage and enforces immutable tags.\n* **MinIO:** Stores large artefacts, zipped deliverables, SBOMs and data sets.  Supports versioning and server‑side encryption.\n* **Postgres (+ Supabase):** Maintains metadata (profiles, system cards, run logs), traces, job statuses and vector search indices.  Supabase provides developer APIs and pgvector integration.\n* **Vector Store:** For embeddings.  The backend can be `pgvector` in Postgres or an external Qdrant instance.  A feature flag chooses which driver to enable.\n\n## Security & Compliance\n\nThe backend enforces numerous policies:\n\n- **No DinD:** Build operations are forwarded to outer BuildKit/containerd; containers run with user namespaces and seccomp, preventing container‑root escalation【43537238352704†L1068-L1088】.\n- **Licence & vulnerability gates:** The Safety service halts builds on critical issues; the Board Agents define accepted licence lists and vulnerability thresholds.\n- **Secrets management:** Secrets are never stored in environment variables.  They are mounted as files via Vault or similar systems, and sidecars are responsible for retrieving them.\n- **Audit trails:** Every API call, pipeline event and model selection decision logs context (who, what, when, rationale).  These logs live in Postgres and are tied to run IDs.\n\n## Development & Testing\n\n* **Makefile:** Provides convenience targets (`make up`, `make down`, `make logs`, `make demo`, `make scan`, `make lock-images`) for developers.  It ensures consistent environment setup and teardown.\n* **Docker‑Compose:** Defines services and dependencies; profiles enable optional components like NATS, Supabase and vcluster.  Compose is used for local development.  For production, manifests under `k8s/` can be applied to a Kubernetes cluster.\n* **Automated tests:** Unit and integration tests run within the Runner Service; security scanners run in the Safety Service.  CI pipelines (to be implemented post‑launch) build images, run tests, generate SBOMs and publish artefacts.\n\nBy modularising the backend into clear services and infrastructure layers, ark‑os‑noa achieves the flexibility of microservices with the discipline of reproducible builds and strong security controls.\n"
      },
      "docs/board_agents.md": {
        "language": "markdown",
        "code": "# Board Agents — Executive Team of ark‑os‑noa\n\n## Definition & Role\n\nThe **Board Agents** sit at the top of the **ark‑os‑noa** organisation just below NOA.  They are analogous to an executive board in a company: each agent owns a domain (strategy, operations, finance, legal, security, partnerships, research) and has authority to commission **MicroAgentStacks** to execute work.  By design they are *few in number* but *broad in scope*—their purpose is to translate NOA’s vision into specific missions, ensure alignment with ElementArk/DeFlex’s business model, and provide governance across all stacks and agents.\n\n## Roster & Responsibilities\n\n- **Strategy/CTO Agent** – Sets technical direction: system architecture, Capsule (Full‑Illusion) adoption, environment policies (no Docker‑in‑Docker), cohesion across services.\n- **COO Agent** – Owns operational runbooks, SLAs, scheduling and change management.  Coordinates delivery timelines and resource utilisation.\n- **CFO/FinOps Agent** – Manages budgets and spend telemetry.  Optimises cost across compute, storage and model usage.\n- **Legal/Compliance Agent** – Ensures licence compliance, data governance, export controls and regulatory adherence.  Maintains policy frameworks.\n- **Security Agent** – Enforces secrets management, supply‑chain security, SBOM attestation and vulnerability thresholds.  Gatekeeper for risk.\n- **Growth/Partnerships Agent** – Curates ingestion roadmaps for repos, APIs and CRMs; drives ecosystem strategy and partnership integrations.\n- **Digest Agent (R&D)** – Sits on the board as the research arm.  Its role is to *digest everything* (code, data, SaaS, models) and surface insights.  See `digest_agent.md` for details.\n\n## Operating Rules\n\n1. **Delegation:** Board Agents can spin up one or more **MicroAgentStacks** to accomplish tasks.  Each stack has its own **CommandChiefAgent** orchestrating the details, leaving the Board Agent to focus on strategy and oversight.\n2. **Specialisation:** When a task requires sophisticated model selection, a Board Agent requests a **ModelSelectorAgent** to choose the most appropriate AI model or tool.  This ensures tasks are executed with the right balance of cost, latency and accuracy.\n3. **Governance:** Board Agents enforce policies across stacks—licensing, vulnerability gates, security posture, and budget limits.  They maintain decision logs and risk registers for audit.\n4. **Parallelism:** Multiple stacks can run concurrently.  Board Agents schedule tasks to maximise throughput while respecting resource constraints.\n\n## Capabilities\n\n* **Multi‑project scheduling:** assign and monitor numerous tasks across different domains and stacks; handle dependencies and deadlines.\n* **Cross‑repo initiatives:** coordinate wide‑sweep digest operations (e.g., SBOM/security posture across all repos) by commissioning multiple stacks.\n* **Program governance:** maintain an overarching view of risks, mitigations, budget spend, and deliverable quality.\n* **Policy enforcement:** integrate security scanners, licence gates, and compliance checks into the workflow.\n\n## Tools & Signals\n\nBoard Agents interact with the system through:\n\n- **Research & analysis tools:** for web search, code parsing and data exploration within the current year’s context.\n- **Change control & telemetry:** CI/CD gates, policy engines (e.g. OPA), vulnerability scanners and cost dashboards.\n- **Observability feeds:** real‑time traces, metrics and logs aggregated from MicroAgentStacks and sidecars.  These signals inform decisions on scaling up/down stacks or raising alerts.\n\n## Relationship to Other Components\n\n* **NOA:** Board Agents receive missions from NOA and report status back.  They provide domain expertise and enforce governance while letting NOA handle high‑level planning and cross‑domain coordination.\n* **MicroAgentStacks:** Board Agents are the owners of stacks.  They commission stacks to achieve defined objectives and decommission them when tasks complete.  Each stack operates autonomously but reports progress to its Board Agent.\n* **ModelSelectorAgents:** When tasks require AI model inference, Board Agents request a ModelSelector to choose among local or hosted models.  The selection is recorded in the trace for audit.\n* **Digest Agent:** The Digest Agent is part of the Board but behaves like an R&D lab—collecting raw information, synthesising knowledge graphs and summarising findings for the board to act on.\n\nBy keeping the Board Agents separate from execution details yet close enough to enforce policy, ark‑os‑noa achieves a balance between **strategic oversight** and **operational agility**.\n"
      },
      "docs/combined.md": {
        "language": "markdown",
        "code": "# NOA — ExecutiveCommanderChiefAgent\n\n## Definition & Purpose\n\nNOA (sometimes called the **ExecutiveCommanderChiefAgent**) is the top‑level orchestrator of\nthe **ark‑os‑noa** platform.  It acts like a CEO for the agent ecosystem: it translates\nhigh‑level business goals into concrete plans, delegates work to Board Agents and\n**MicroAgentStacks**, and ensures that every deliverable meets business, technical, and\ncompliance requirements.\n\n## Framework\n\n* **Inputs:** high‑level goals, success criteria, budgets, SLAs, risk appetite and\n  constraints.  NOA normalises these into a **WorkPlan**.  Each plan captures tasks,\n  checkpoints, deadlines and deliverables.\n* **Outputs:** action plans, stack assignments, acceptance tests and post‑mortems.  For\n  each goal NOA produces a package of artefacts (e.g. zip file and compiled PDF).\n* **Control loop:** Sense → Plan → Act → Verify → Report.  NOA constantly senses\n  progress and risks, replans when necessary, acts by spawning or destroying\n  **MicroAgentStacks**, verifies outputs against acceptance criteria, and finally reports\n  to the business owner.\n\n## Goals\n\n1. **Disambiguate and decompose:** convert ambiguous goals into measurable objectives and\n   step‑by‑step tasks.\n2. **Resource allocation:** assign Board Agents and MicroAgentStacks based on domain\n   expertise, constraints and availability.\n3. **Policy enforcement:** apply safety, security and legal policies; ensure no\n   Docker‑in‑Docker (**Capsule/Full‑Illusion** pattern) and maintain audit logs.\n4. **Model selection:** orchestrate **ModelSelectorAgents** to pick appropriate AI models\n   for each task, balancing accuracy, latency and cost.\n5. **Packaging & archiving:** guarantee that outputs are packaged into deliverable\n   artefacts (zip + PDF) and stored internally.\n\n## Capabilities\n\n* **Decomposition & scheduling:** build dependency graphs, schedule tasks across stacks\n  and board seats, and respect deadlines.\n* **Auto‑retry & escalation:** detect failures or blockers and retry tasks with\n  backoff; when automation fails, summarise context and ask for human input.\n* **Observability:** generate unique run IDs, attach traces and metrics, and\n  centralise logs for all stacks.\n* **Safety & compliance:** enforce licensing, vulnerability thresholds and secret\n  scanning.  Use outer BuildKit and containerd with sidecars rather than nested\n  containers to avoid security risks【43537238352704†L1068-L1088】.\n\n## Objects & Definitions\n\n* **WorkPlan:** a structured representation of a goal → tasks → checkpoints → deliverables\n  → review gates.\n* **Assignment:** mapping between Board Agents, MicroAgentStacks and tasks; includes\n  SLAs and ownership.\n* **Trace:** evidence of inputs, actions, tools, models and outputs for audit and\n  reproducibility.\n\n## Lifecycle\n\n1. **Intake & Normalise:** accept a business goal and convert it into a WorkPlan.\n2. **Resource Match:** choose which Board Agents and stacks are needed and spin them up.\n3. **Execution:** coordinate tasks across microservices; check progress with periodic\n   checkpoints.\n4. **Validation & Packaging:** verify results, run security and licence scans, and\n   package deliverables.\n5. **Report & Archive:** summarise results, produce a post‑run report, archive artefacts\n   with retention policies.\n\n## Tools & Resources\n\nNOA can invoke various tools through subordinate agents, including: web research, code &\ndata analysis, file search, and automations.  It delegates model selection to\nModelSelectorAgents and leverages microservices to execute tasks.  It works with the\ninternal data plane (OCI registry, MinIO, Postgres/pgvector, Supabase) to store and\nretrieve artefacts, always within the trust boundary.# Board Agents — Executive Team of ark‑os‑noa\n\n## Definition & Role\n\nThe **Board Agents** sit at the top of the **ark‑os‑noa** organisation just below NOA.  They are analogous to an executive board in a company: each agent owns a domain (strategy, operations, finance, legal, security, partnerships, research) and has authority to commission **MicroAgentStacks** to execute work.  By design they are *few in number* but *broad in scope*—their purpose is to translate NOA’s vision into specific missions, ensure alignment with ElementArk/DeFlex’s business model, and provide governance across all stacks and agents.\n\n## Roster & Responsibilities\n\n- **Strategy/CTO Agent** – Sets technical direction: system architecture, Capsule (Full‑Illusion) adoption, environment policies (no Docker‑in‑Docker), cohesion across services.\n- **COO Agent** – Owns operational runbooks, SLAs, scheduling and change management.  Coordinates delivery timelines and resource utilisation.\n- **CFO/FinOps Agent** – Manages budgets and spend telemetry.  Optimises cost across compute, storage and model usage.\n- **Legal/Compliance Agent** – Ensures licence compliance, data governance, export controls and regulatory adherence.  Maintains policy frameworks.\n- **Security Agent** – Enforces secrets management, supply‑chain security, SBOM attestation and vulnerability thresholds.  Gatekeeper for risk.\n- **Growth/Partnerships Agent** – Curates ingestion roadmaps for repos, APIs and CRMs; drives ecosystem strategy and partnership integrations.\n- **Digest Agent (R&D)** – Sits on the board as the research arm.  Its role is to *digest everything* (code, data, SaaS, models) and surface insights.  See `digest_agent.md` for details.\n\n## Operating Rules\n\n1. **Delegation:** Board Agents can spin up one or more **MicroAgentStacks** to accomplish tasks.  Each stack has its own **CommandChiefAgent** orchestrating the details, leaving the Board Agent to focus on strategy and oversight.\n2. **Specialisation:** When a task requires sophisticated model selection, a Board Agent requests a **ModelSelectorAgent** to choose the most appropriate AI model or tool.  This ensures tasks are executed with the right balance of cost, latency and accuracy.\n3. **Governance:** Board Agents enforce policies across stacks—licensing, vulnerability gates, security posture, and budget limits.  They maintain decision logs and risk registers for audit.\n4. **Parallelism:** Multiple stacks can run concurrently.  Board Agents schedule tasks to maximise throughput while respecting resource constraints.\n\n## Capabilities\n\n* **Multi‑project scheduling:** assign and monitor numerous tasks across different domains and stacks; handle dependencies and deadlines.\n* **Cross‑repo initiatives:** coordinate wide‑sweep digest operations (e.g., SBOM/security posture across all repos) by commissioning multiple stacks.\n* **Program governance:** maintain an overarching view of risks, mitigations, budget spend, and deliverable quality.\n* **Policy enforcement:** integrate security scanners, licence gates, and compliance checks into the workflow.\n\n## Tools & Signals\n\nBoard Agents interact with the system through:\n\n- **Research & analysis tools:** for web search, code parsing and data exploration within the current year’s context.\n- **Change control & telemetry:** CI/CD gates, policy engines (e.g. OPA), vulnerability scanners and cost dashboards.\n- **Observability feeds:** real‑time traces, metrics and logs aggregated from MicroAgentStacks and sidecars.  These signals inform decisions on scaling up/down stacks or raising alerts.\n\n## Relationship to Other Components\n\n* **NOA:** Board Agents receive missions from NOA and report status back.  They provide domain expertise and enforce governance while letting NOA handle high‑level planning and cross‑domain coordination.\n* **MicroAgentStacks:** Board Agents are the owners of stacks.  They commission stacks to achieve defined objectives and decommission them when tasks complete.  Each stack operates autonomously but reports progress to its Board Agent.\n* **ModelSelectorAgents:** When tasks require AI model inference, Board Agents request a ModelSelector to choose among local or hosted models.  The selection is recorded in the trace for audit.\n* **Digest Agent:** The Digest Agent is part of the Board but behaves like an R&D lab—collecting raw information, synthesising knowledge graphs and summarising findings for the board to act on.\n\nBy keeping the Board Agents separate from execution details yet close enough to enforce policy, ark‑os‑noa achieves a balance between **strategic oversight** and **operational agility**.\n# ModelSelectorAgents — Choosing the Right Tool for the Job\n\n## Purpose\n\nA **ModelSelectorAgent** specialises in selecting the best AI model or tool for a given task.  In the context of ark‑os‑noa, tasks vary widely—from reasoning and planning, to code analysis, to data transformation.  Selecting the wrong model can waste resources or compromise privacy.  The ModelSelector provides an intelligent arbitration layer, helping Board Agents and **MicroAgentStacks** achieve high quality results while respecting cost, latency and privacy constraints.\n\n## Framework\n\n* **Inputs:** Each call to a ModelSelector includes a task description, input size (e.g. document length, number of files), the privacy tier (public, sensitive, confidential), latency budget, and a cost cap.  These parameters come from the requesting agent (often a Board Agent or CommandChiefAgent).\n* **Decision Graph:** The ModelSelector applies a decision graph:\n  1. **Task classification** – Is this reasoning/planning, bulk transformation, code/data manipulation, or something else?\n  2. **Complexity estimation** – How large or intricate is the input?  This influences whether to use a bigger model or a lightweight one.\n  3. **Model/Tool selection** – Choose from a catalogue of available models (remote APIs, local models served via llama.cpp/Ollama, code runners, data converters) using heuristics or learned policies.\n  4. **Guardrails assertion** – Check licensing, privacy levels and security requirements.  For example, confidential data must stay on‑prem and use local models.\n* **Outputs:** A plan specifying the chosen model or tool, the expected cost/latency, and a rationale.  The rationale becomes part of the execution **Trace**, enabling auditing and future optimisation.\n\n## Default Policy\n\nThe default policy can be tuned, but common guidelines include:\n\n1. **Reasoning / Planning tasks:** Use high‑quality generalist models (e.g. GPT‑5).  These tasks benefit from advanced reasoning and tolerance for slower latency when results matter.\n2. **Bulk transforms / formatting:** Use fast, cost‑efficient models; they handle repetitive conversions without needing deep reasoning.\n3. **Code & data tasks:** Prefer dedicated code analysis tools or local runtimes for safety.  Use sandboxed execution to evaluate code or parse data.  Employ smaller codex models when summarising code.\n4. **Offline/local fallbacks:** If the privacy tier demands on‑prem processing or if network latency is unacceptable, use local models served via llama.cpp, vLLM or similar frameworks.  This reduces latency and eliminates external data exposure.\n\n## Tools & Telemetry\n\n- **Model catalogues:** The selector maintains metadata about available models—accuracy, context limits, token costs, latency benchmarks, licensing and hardware requirements.  It syncs with the local model server and remote provider APIs.\n- **Cost/latency forecaster:** Predicts cost and latency using historical telemetry and dynamic system load.  This helps decide when to use a cheaper but slower model vs. a more expensive high‑performance one.\n- **Performance feedback:** The selector ingests feedback after tasks complete (e.g. success, error rate, user satisfaction).  Over time it learns to better match tasks to models.\n\n## Relationship to Other Components\n\n- **Board Agents:** Request ModelSelector assistance when their tasks involve AI/ML.  They set budgets and specify privacy tiers.  The ModelSelector returns a plan and rationale.\n- **MicroAgentStacks:** CommandChiefAgents invoke ModelSelectors inside their stacks when a task requires AI processing.  This ensures each stack uses consistent policies and optimal models.\n- **NOA:** Maintains overarching policies for model selection (allowed licences, vulnerability gates, GPU quotas).  The ModelSelector enforces these policies and logs decisions back to NOA’s audit trail.\n\n## Benefits\n\n* **Efficiency:** Avoids blindly calling the largest or default model for every task, saving compute and cost.\n* **Compliance:** Ensures tasks adhere to privacy and licensing requirements—confidential data stays internal.\n* **Transparency:** Provides a clear rationale for each selection so decisions can be audited and improved.\n* **Extensibility:** New models or tools can be added to the catalogue; the decision graph can be refined with new criteria or learned policies.\n\nBy delegating model/tool choice to a dedicated ModelSelectorAgent, ark‑os‑noa keeps business logic and AI expertise separate, resulting in better outcomes and traceable decisions.\n# MicroAgentStack — Cooperative Work Pods\n\n## Definition\n\nA **MicroAgentStack** is a deployable cluster of cooperative agents assembled to accomplish a bounded objective.  Think of it as a project team spun up on demand: each stack has its own **CommandChiefAgent** (the stack master), a set of specialised Operators, Adapters and Guards, and a dedicated workspace.  Stacks can be created, scaled and destroyed rapidly, making them the primary execution units within ark‑os‑noa.\n\n## Composition\n\n* **CommandChiefAgent (Stack Master):** Orchestrates the stack, decomposes tasks, assigns work to subordinate agents, monitors progress, resolves conflicts and enforces SLAs.\n* **Operators:** Specialised agents that perform specific functions.  Examples include code runners (execute code), data wranglers (transform data), doc generators (produce reports), testers (run unit/integration tests) and packagers (build zips, PDFs).\n* **Adapters:** Connectors to external systems (repos, CRMs, APIs) and publishers to internal services (registry, MinIO, Postgres).  Adapters abstract away details like auth and rate‑limits.\n* **Guards:** Policy enforcement points—security scanners, licence checkers, quality gates.  They ensure the stack adheres to policies defined by NOA and the Board Agents.\n\n## Goals\n\n1. **Deliver end‑to‑end outcomes:** A stack should own the entire life cycle of its objective—from cloning a repo to producing a digest report, from running tests to publishing a package.\n2. **Scale horizontally:** Multiple stacks can be spun up concurrently when tasks are independent or parallelisable.  This enables large scale operations like digesting hundreds of repos simultaneously.\n3. **Clean teardown:** After completion, a stack cleans up its resources (containers, temporary volumes) and archives logs, SBOMs and artefacts with proper retention policies.\n\n## Lifecycle\n\n1. **Bootstrap:**  Given inputs (e.g. repo URL, CRM base URL, model list), the CommandChiefAgent creates a **WorkPlan**, prepares the environment and mounts necessary sidecars.  It avoids Docker‑in‑Docker by using **Capsule** sidecars to talk to the outer BuildKit/containerd environment【43537238352704†L1068-L1088】.\n2. **Execute:**  The stack runs its Operators in parallel where possible.  Retrying tasks with exponential backoff ensures resilience; failures trigger controlled retries or escalation to the Board Agent.\n3. **Validate:**  Once tasks finish, Guards run acceptance tests (e.g. unit tests, SBOM scans, licence checks) and produce human‑readable summaries.  If acceptance criteria fail, the stack either retries or fails the WorkPlan.\n4. **Package:**  On success, the stack assembles outputs into deliverables (zip file, compiled PDF, JSON indices).  It updates internal registries (OCI images, Postgres metadata, vector DB) and publishes logs and traces.\n5. **Archive:**  The stack removes its runtime environment and persists all logs, SBOMs, run IDs, and checksums.  Retention policies decide how long to keep each artefact.\n\n## One‑liners & Conventions\n\n* Stacks are named by timestamps or descriptive identifiers (e.g. `stack‑20250822‑103045`).\n* They maintain their own directory structure (`in/`, `work/`, `out/`, `logs/`) for clarity and reproducibility.\n* Each stack produces a unique run ID and attaches it to all outputs and logs for traceability.\n\n## Relationship to Other Components\n\n* **Board Agents:** Create and oversee stacks.  Each stack reports to its Board Agent.  Board Agents can run multiple stacks in parallel.\n* **ModelSelectorAgents:** When a stack requires AI processing, the CommandChiefAgent requests a ModelSelector to choose the appropriate model and logs the rationale.\n* **Digest Agent:** Often uses MicroAgentStacks to perform large‑scale digestions across many repos or datasets.  Each stack digests one or more sources and returns results to the Digest Agent.\n\nMicroAgentStacks bring structure, scalability and reliability to ark‑os‑noa’s execution model.  By isolating work into bounded pods, the system can handle complex, parallel workflows without turning into a monolith.\n# Digest Agent — R&D Engine for ark‑os‑noa\n\n## Role & Position\n\nThe **Digest Agent** operates as the research and development arm of the Board Agents.  Its primary mission is to *“digest everything”*—code repositories, datasets, documents, APIs, SaaS systems (including live CRMs) and even AI models.  By analysing these sources, the Digest Agent extracts structured knowledge, builds semantic indices, and surfaces insights that inform strategic decisions.  Though part of the Board, it behaves like a self‑contained lab, spinning up **MicroAgentStacks** to perform large‑scale digestions.\n\n## Pipeline\n\n1. **Discover:** Identify sources to digest.  This includes scanning internal GitHub repos, listing connected APIs/CRMs, and reading the current model ingestion list.  Discovery may rely on board directives or scheduled tasks.\n2. **Fetch:** Clone or synchronise the source material.  For code repos, perform a shallow clone and gather dependency lock files.  For CRMs or APIs, pull metadata and sample records while respecting rate limits.  Handle authentication using secure tokens from the secrets manager.\n3. **Parse:** Use language‑specific parsers (Python AST, ts‑morph for JS/TS, go/ast, Rust syn, JavaParser) to analyse code and extract modules, functions, classes and call graphs.  For API schemas, parse OpenAPI/GraphQL definitions.  Build an **SBOM** to capture all packages and versions.\n4. **Analyze:** Generate embeddings for code, documentation and data using models selected via the **ModelSelectorAgent**.  Build a **knowledge graph** linking functions, data structures, APIs and entities.  Identify external API calls, config surfaces and extension points.  Apply entity linking to unify references across sources.\n5. **Summarize:** Produce layered summaries: per file, per module, per repository and across repositories.  Summaries highlight the system’s purpose, architecture, dependencies, risks and extension points.  The Digest Agent uses LLMs to craft human‑readable reports and cross‑links to original sources.\n6. **Surface:** Publish outputs as markdown dossiers, dashboards and vector DB upserts.  Persist `profile.json`, `system_card.md`, `kg.json`, and embeddings.  Offer search and retrieval APIs for downstream agents.\n7. **Secure:** Scan for secrets and vulnerabilities using tools like Trivy, Grype and Gitleaks.  Classify findings by severity and quarantine sensitive information.  Tag licences and export‑control flags【43537238352704†L1068-L1088】.\n\n## Tools\n\n* **Web research:** limited to current‑year sources, retrieving official documentation and examples.\n* **Language parsers & AST tools:** Python’s `ast`, TS’s `ts‑morph`, Go’s `go/ast`, Rust’s `syn`, Java’s `JavaParser`.\n* **Security scanners:** Syft to produce SBOMs; Grype and Trivy to scan for vulnerabilities; Gitleaks to detect secrets; Semgrep for static analysis.\n* **Embeddings & vector DB:** Sentence transformers or llama.cpp embedding models; pgvector or Qdrant to store vectors and link them to original files.\n* **Visualization & reports:** Graph builders, markdown generators and PDF compilers.\n\n## Outputs\n\nThe Digest Agent delivers:\n\n* **Digest reports:** Markdown documents (e.g. `2025‑08‑22_digest_report.md`) summarising findings.\n* **Structured indices:** JSONL files representing the knowledge graph, call graph and embedding metadata.  These feed search and retrieval APIs.\n* **SBOM & security reports:** Comprehensive lists of dependencies and vulnerabilities.\n* **Vector store entries:** Embeddings upserted to the chosen vector DB for semantic search.\n\n## Relationship to Other Components\n\n* **Board Agents:** Commission digestion tasks and consume the Digest Agent’s findings when making strategic decisions.\n* **MicroAgentStacks:** Used to parallelise large digests—each stack handles a set of sources and feeds results back to the Digest Agent.\n* **ModelSelectorAgents:** Select embedding models and summarisation LLMs appropriate for each source type.  For example, code summarisation may use a codex model, while plain text summarisation uses a general LLM.\n* **Data & Storage layer:** Stores artefacts and indices in MinIO, Postgres and the vector store.  The Digest Agent ensures proper metadata tagging and retention policies.\n\nBy systematically consuming and analysing every relevant piece of information, the Digest Agent turns unstructured data into actionable knowledge for ark‑os‑noa’s decision makers.\n# Backend — Services & Infrastructure of ark‑os‑noa\n\n## Purpose\n\nThe **backend** of ark‑os‑noa comprises all of the runtime services and infrastructure that turn high‑level plans into concrete work.  It includes the event bus, microservices that implement the **Expanded Digest Pipeline**, sidecars that enable the **Capsule** pattern, and internal data stores.  Together, these components provide a robust, scalable and secure environment for executing tasks, orchestrated by NOA and the Board Agents.\n\n## Services & Microservices\n\n### Core Pipeline Services\n\nThe digest‑everything pipeline is decomposed into a series of microservices, each responsible for a discrete stage.  Running them as independent services ensures that each can scale, fail and be updated independently, which is aligned with microservice best practices【43537238352704†L1068-L1088】.\n\n1. **Intake Service:** Receives digest requests; validates inputs (repo URLs, API endpoints, model lists); creates provenance records and initializes workspace directories.\n2. **Classifier Service:** Detects programming languages, build systems, service types (CLI, API, library) and licences.  Produces a `profile.json` summarising the source.\n3. **Graph Extract Service:** Parses code and schemas to build call graphs, data flow graphs and config surfaces.  Supports multi‑language parsing (Python, JS/TS, Go, Rust, Java).  Outputs `kg.json` and `system_card.md`.\n4. **Embeddings Service:** Generates embeddings for code and documentation using models selected by ModelSelectorAgents.  Upserts vectors to pgvector or Qdrant.\n5. **Env Synthesis Service:** Emits Dockerfiles, docker‑compose YAML, Kubernetes manifests, `.env.example`, `Makefile` targets and config schemas.  Ensures reproducible builds using outer BuildKit (no DinD).\n6. **Safety Service:** Runs SBOM generation (Syft), vulnerability scans (Grype/Trivy), secret scans (Gitleaks) and static analysis (Semgrep).  Applies policy gates; stops the pipeline on critical issues.\n7. **Runner Service:** Builds and runs the source in a controlled container environment; executes existing tests or generates smoke tests; produces `demo.md`.\n8. **Integrator Service:** Generates adapters (SDKs for Python, Node, Go), telemetry hooks and policy stubs; prepares packaging instructions.\n9. **Registrar Service:** Writes outputs and metadata to storage (registry, MinIO, Postgres); registers embeddings; updates indexes for search.\n\n### Auxiliary Services\n\n* **CRM Strangler Proxy:** Provides a transparent layer between internal clients and an external CRM.  It records requests/responses, supports *shadow* and *write‑through* modes, and allows incremental internal re‑implementation of CRM features.\n* **Model Serving:** Hosts local models using frameworks like llama.cpp, Ollama or vLLM.  Exposes endpoints for inference and embedding generation.  Each model server is packaged in its own container with health checks.\n* **Gateway API:** A FastAPI service exposing endpoints: `/digest`, `/capsule/spawn`, `/crm/toggle`, `/models/ingest`, `/models/benchmark`, `/admin/*`.  Acts as the single entry point for external clients and the front‑end.\n\n## Event Bus & Orchestration\n\n* **Redis Streams:** Provides the primary event bus for inter‑service communication.  Services consume and produce events in a decoupled fashion.  The bus also supports message persistence and backpressure.\n* **NATS (optional):** A lightweight publish/subscribe system for high fan‑out or cross‑cluster communication.  Enabled via a feature flag.\n* **Workflow Engine:** A simple DAG engine built on Redis to coordinate pipeline tasks with retries and backoff.  Temporal or Argo Workflows can be integrated later for more sophisticated orchestrations.\n\n## Capsule Sidecars\n\nAll containers run inside a “Capsule” to simulate container‑in‑container and Kubernetes‑in‑Kubernetes workflows without the security and performance drawbacks【716409907369096†L1037-L1067】.  Capsule sidecars include:\n\n1. **Build‑Proxy:** A lightweight service that proxies inner `docker build` and `nerdctl` commands to the outer BuildKit daemon.  It exposes a local socket inside the Capsule but forwards build requests externally, avoiding duplicate layer storage.\n2. **Service‑Mirror:** Watches inner service definitions and publishes corresponding services in the outer service mesh with mTLS and SLO configurations.  This allows inner services to be reachable and observable from the outer plane.\n3. **Policy Agent (OPA):** Enforces egress rules, resource quotas, and other policies at the Capsule boundary.  It integrates with eBPF to block unauthorised traffic.\n4. **Telemetry Agent:** Collects traces, metrics and logs from the inner services and sidecars.  It forwards data to the central observability stack with proper trace‑ID propagation.\n5. **vcluster (optional):** Provides a lightweight Kubernetes API server inside the Capsule for tools that require kubectl.  It maps pods to the parent cluster’s nodes without duplicating container runtimes.\n\n## Data Stores\n\n* **OCI Registry:** Stores container images, compiled outputs and Capsule definitions.  The registry uses content‑addressed storage and enforces immutable tags.\n* **MinIO:** Stores large artefacts, zipped deliverables, SBOMs and data sets.  Supports versioning and server‑side encryption.\n* **Postgres (+ Supabase):** Maintains metadata (profiles, system cards, run logs), traces, job statuses and vector search indices.  Supabase provides developer APIs and pgvector integration.\n* **Vector Store:** For embeddings.  The backend can be `pgvector` in Postgres or an external Qdrant instance.  A feature flag chooses which driver to enable.\n\n## Security & Compliance\n\nThe backend enforces numerous policies:\n\n- **No DinD:** Build operations are forwarded to outer BuildKit/containerd; containers run with user namespaces and seccomp, preventing container‑root escalation【43537238352704†L1068-L1088】.\n- **Licence & vulnerability gates:** The Safety service halts builds on critical issues; the Board Agents define accepted licence lists and vulnerability thresholds.\n- **Secrets management:** Secrets are never stored in environment variables.  They are mounted as files via Vault or similar systems, and sidecars are responsible for retrieving them.\n- **Audit trails:** Every API call, pipeline event and model selection decision logs context (who, what, when, rationale).  These logs live in Postgres and are tied to run IDs.\n\n## Development & Testing\n\n* **Makefile:** Provides convenience targets (`make up`, `make down`, `make logs`, `make demo`, `make scan`, `make lock-images`) for developers.  It ensures consistent environment setup and teardown.\n* **Docker‑Compose:** Defines services and dependencies; profiles enable optional components like NATS, Supabase and vcluster.  Compose is used for local development.  For production, manifests under `k8s/` can be applied to a Kubernetes cluster.\n* **Automated tests:** Unit and integration tests run within the Runner Service; security scanners run in the Safety Service.  CI pipelines (to be implemented post‑launch) build images, run tests, generate SBOMs and publish artefacts.\n\nBy modularising the backend into clear services and infrastructure layers, ark‑os‑noa achieves the flexibility of microservices with the discipline of reproducible builds and strong security controls.\n# Data & Storage — Securing the ark‑os‑noa Data Plane\n\n## Principle\n\nThe data layer of ark‑os‑noa is built around a core principle: **keep all storage within the trust boundary**.  All artefacts—images, datasets, logs, metadata, SBOMs—are retained internally, signed and versioned.  Only signed, approved deliverables are exported.  This ensures confidentiality, integrity and provenance across the platform.\n\n## Components\n\n1. **Private OCI Registry:** Hosts container images, Capsule definitions, build outputs and adapters.  Using a private registry prevents untrusted images from entering the environment and allows BuildKit to push/pull from a controlled backend.\n2. **MinIO (S3‑compatible object store):** Serves as the main artefact store.  It holds large files (zip archives, compiled PDFs), dataset fragments, SBOM documents, vulnerability reports and even model shards.  MinIO offers versioning, server‑side encryption (SSE) and lifecycle management.\n3. **Postgres:** Stores structured metadata: run logs, profiles (`profile.json`), system cards (`system_card.md`), call graphs (`kg.json`), job statuses, policy decisions and audit trails.  Postgres also stores vector embeddings via the `pgvector` extension.\n4. **Supabase:** A self‑hosted instance of Supabase augments Postgres with developer APIs, authentication and real‑time features.  It provides a convenient interface for front‑end applications and external tools until the platform fully internalises these capabilities.\n5. **Vector Store:** Embeddings generated by the Embeddings Service are stored in either `pgvector` (Postgres) or a dedicated Qdrant cluster.  pgvector is enabled by default for simplicity; Qdrant can be turned on via a feature flag to support larger vector workloads.\n\n## Policies & Best Practices\n\n* **Immutability:** Artefacts are stored content‑addressed using SHA‑256 digests.  Tags or names are pointers to immutable content; rewriting tags triggers new versions.  This prevents tampering and ensures reproducible builds.\n* **Lineage & Provenance:** Each deliverable (zip, PDF, image) links back to its inputs, tools, models and run ID.  Build provenance is stored as JSON attestation, capturing the environment, command, dependency versions and commit hashes.\n* **Retention:** Short‑lived runs (e.g. experimental digests) are kept for a limited period; long‑term artefacts (e.g. official releases) are retained indefinitely.  Policies can be configured per project or domain.\n* **Access Control:** The data plane uses least privilege.  Microservices receive temporary scoped tokens to access the object store or registry; access is audited.  Secrets (e.g. tokens, keys) are stored in a secrets manager (Vault) and mounted as files, never as environment variables.\n\n## Integration with Other Components\n\n- **Backend services:** Interact with the registry and MinIO via signed URLs or direct API calls.  BuildKit pushes images to the registry; the Registrar Service writes artefacts to MinIO and records metadata in Postgres.\n- **Digest Agent:** Reads and writes to MinIO and Postgres; uploads embeddings to the vector store.  It uses the registry to store intermediate build images.\n- **Model Selector and Model Servers:** Use Postgres (via pgvector or Qdrant) to store model metadata and evaluation results.  Models themselves may be stored as OCI artefacts or in MinIO shards.\n- **Front‑end:** Accesses Supabase for real‑time updates and uses signed URLs to fetch artefacts from MinIO.\n\n## One‑Liners & Conventions\n\n```bash\n# Create local directories mirroring services (for dev/testing)\nmkdir -p storage/{oci,minio,postgres,supabase,artifacts} && tree -L 2 storage || ls -R storage\n\n# Content‑address an artefact\ndigest=$(sha256sum output.zip | awk '{print $1}')\ncp output.zip storage/artifacts/${digest}.zip\n```\n\n## Why Internal Data Planes Matter\n\nKeeping storage internal reduces the attack surface and simplifies compliance.  Data never leaves the environment without explicit signing and approval.  When combined with provenance tracking, this approach ensures that every piece of data can be traced back to its origin and verified—critical for regulated environments and supply‑chain integrity.\n# Combined Framework & Architecture of ark‑os‑noa\n\n## High‑Level Overview\n\n**ark‑os‑noa** is an **agentic AI platform** designed to realise ElementArk/DeFlex’s business model.  It combines hierarchical organisational patterns (NOA → Board Agents → MicroAgentStacks → microservices) with modern infrastructure techniques (Capsule/Full‑Illusion pattern, private data plane, event bus) and an adaptable AI layer (ModelSelectorAgents and Digest Agent).  The result is a **“hive mind”** of specialised agents capable of digesting, reasoning about and producing artefacts across software, data and SaaS systems.\n\n## Layers & Hierarchy\n\n### 1. Strategy & Orchestration Layer\n\n- **NOA:** The ExecutiveCommanderChiefAgent at the top.  Transforms business goals into actionable plans, assigns Board Agents, sets policies, and monitors execution.\n- **Board Agents:** Domain‑specific executives (Strategy/CTO, COO, CFO/FinOps, Legal/Compliance, Security, Growth/Partnerships, Digest).  Each can commission work via MicroAgentStacks and request ModelSelector assistance.\n\n### 2. Execution Layer\n\n- **MicroAgentStacks:** On‑demand work pods orchestrated by a CommandChiefAgent.  Each stack contains Operators, Adapters and Guards and runs through a defined lifecycle (Bootstrap → Execute → Validate → Package → Archive).  Stacks interact with external sources (repos, CRMs, APIs) and internal services via Adapters.\n- **Expanded Digest Pipeline:** A set of microservices (Intake, Classifier, Graph Extract, Embeddings, Env Synthesis, Safety, Runner, Integrator, Registrar) that perform the actual work.  Each is loosely coupled via an event bus and runs inside the Capsule environment.  CRM Strangler and Model Serving are additional services.\n\n### 3. Infrastructure Layer\n\n- **Capsule Architecture (Full Illusion):** Encapsulates stacks and services in a sandbox that forwards build operations and network traffic to the outer runtime.  Capsule sidecars (Build‑Proxy, Service‑Mirror, Policy Agent, Telemetry Agent, optionally vcluster) provide the illusion of Docker‑in‑Docker and Kubernetes‑in‑Kubernetes without their drawbacks【716409907369096†L1037-L1067】.\n- **Event Bus & Orchestration:** Redis Streams (primary) and optional NATS enable asynchronous communication.  A workflow engine coordinates the pipeline steps, handling retries and backoff.\n- **Data Plane:** Private OCI registry, MinIO, Postgres (+ pgvector/Supabase) and optionally Qdrant.  This plane stores everything from container images to embeddings and ensures data stays within the trust boundary.\n- **Observability & Security:** OTel tracing, Prometheus metrics, policy agents, SBOM/vulnerability scanners and secrets management.  The **no DinD** policy and user namespaces reduce privilege escalation risk【43537238352704†L1068-L1088】.\n\n## How the Pieces Fit Together\n\n1. **Goal Intake:** A high‑level goal arrives.  NOA normalises it into a WorkPlan and determines which Board Agents are responsible.\n2. **Board Planning:** Board Agents refine the goal, assign budgets, define SLAs and set policies.  They request MicroAgentStacks and ModelSelectorAgents as needed.\n3. **Stack Deployment:** For each task, a MicroAgentStack is spawned.  The stack uses Adapters to fetch sources (repos, CRMs), Operators to parse/analyse, and Guards to enforce policies.  Microservices implement the digest pipeline, orchestrated via the event bus.\n4. **Model Selection & Execution:** When a service or operator needs AI inference (embeddings, summarisation, code explanation), it calls a ModelSelectorAgent.  The selected model is executed via local model servers or remote APIs.\n5. **Data Persistence:** Outputs from each step (SBOMs, graphs, embeddings, demos) are persisted via the Data Plane.  The Registrar Service updates indexes and metadata.\n6. **Completion & Reporting:** Once tasks finish, the stack packages results into a zip and compiled PDF, publishes them to MinIO and the registry, and updates Postgres.  NOA receives a report and archives the run.\n\n## Why This Architecture?\n\n1. **Modularity & Scalability:** By decomposing functionality into microservices and agents, ark‑os‑noa can scale horizontally and update components independently—avoiding the pitfalls of monolithic systems【43537238352704†L1068-L1088】.\n2. **Security & Compliance:** The Capsule pattern, no DinD policy, private data plane and sidecar enforcement minimise the attack surface.  SBOMs, licences and vulnerability scans ensure supply‑chain integrity.\n3. **Intelligence & Adaptability:** ModelSelectorAgents enable adaptive AI usage; the Digest Agent builds knowledge graphs and embeddings; the board can ingest CRMs and SaaS systems without downtime using the strangler proxy.\n4. **Auditability & Provenance:** Every decision, model selection and action is logged in Postgres and associated with a run ID.  Artefacts are content‑addressed and signed.  This supports post‑mortems, compliance and future learning.\n\n## Extensibility\n\n* **New Board roles:** Additional executives (e.g. Marketing, HR) can be added by extending the roster and defining their domains and policies.\n* **Additional microservices:** New processing stages (e.g. code transformers, simulation engines) can be plugged into the pipeline without redesigning the whole system.\n* **Hybrid deployment:** While Compose is used locally, Kubernetes manifests (`k8s/`) can be applied to a cluster; the same Capsule pattern applies.\n* **Model & Connector expansions:** New AI models are registered via the ModelSelector; new connectors are implemented by Adapters to integrate more SaaS or data sources.\n\nThe **Combined Framework & Architecture** unifies strategic planning, microservice execution, security and AI into a cohesive system.  It is intentionally modular to allow continuous growth and improvement.\n# API, Connectors & Front‑End of ark‑os‑noa\n\n## Gateway API\n\nThe **Gateway API** is the central entry point for interacting with ark‑os‑noa’s backend services.  Implemented using FastAPI, it exposes endpoints for ingesting sources, spawning capsules, toggling CRM behaviours, ingesting models and administering the system.\n\n### Key Endpoints\n\n| Endpoint | Method | Description |\n|---------|--------|-------------|\n| `/digest` | POST | Submit a digest request.  The request includes sources (e.g. repo URL, API base URL), intent (integrate, analyse), and optional metadata.  It triggers the Intake Service and returns a job ID. |\n| `/capsule/spawn` | POST | Spawn a new Capsule environment.  Returns Capsule identifiers and access tokens.  Used when custom stacks need to be run manually or via the front‑end. |\n| `/crm/toggle` | POST | Toggle the CRM Strangler Proxy mode for a specific endpoint (e.g. enable write‑through for `/contacts`).  Allows incremental migration from external CRM to internal implementation. |\n| `/models/ingest` | POST | Add a model to the local registry.  Accepts a model identifier (e.g. Hugging Face repo) and optional metadata.  The Model Serving service pulls the model and makes it available through the ModelSelector. |\n| `/models/benchmark` | POST | Run evaluations on local or remote models.  Returns latency, cost and accuracy metrics that feed into the ModelSelector’s decision graph. |\n| `/admin/*` | GET/POST | Administrative endpoints for tasks such as inspecting job statuses, viewing SBOMs, retrieving logs, enabling/disabling features (NATS, Supabase, vcluster) and rotating secrets.  Protected via authentication and authorisation. |\n\nAll endpoints accept and return JSON; error responses include descriptive messages and relevant codes.  The Gateway uses request identifiers and attaches trace IDs to facilitate debugging and correlation across services.\n\n## Connectors & Integrations\n\nark‑os‑noa interacts with the outside world via **Adapters** and **Connectors**.  These modules encapsulate authentication, rate limiting, and protocol details, allowing the rest of the system to remain agnostic to third‑party specifics.\n\n### Built‑in Connectors\n\n- **GitHub Connector:** Uses the GitHub API to search, clone and pull repositories.  It supports scoping by organisation or repository and can read commit logs and PR metadata.\n- **CRM Connector:** Provides read/write access to CRM systems (e.g. Salesforce, HubSpot).  Initially operates in shadow mode (read‑only) via the CRM Strangler Proxy; write‑through can be toggled per endpoint.  Handles pagination, rate limits and authentication.\n- **Model Hub Connector:** Interfaces with external model repositories (e.g. Hugging Face).  Supports pulling models, downloading tokenizers and retrieving licences.  Works in conjunction with the Model Serving service.\n- **Other API Connectors:** Additional connectors (e.g. for Slack, Notion, Jira) can be added by implementing the Adapter interface.  Each connector is packaged as its own microservice or plugin to preserve modularity.\n\n### Internal Connectors\n\n- **Registry & Object Store:** Adapters communicate with the private OCI registry and MinIO using signed URLs.  They ensure that images and artefacts are pushed/pulled securely and that content addressing is respected.\n- **Database & Vector Store:** Adapters abstract database interactions.  They provide typed functions to query or insert metadata, run logs and embeddings without exposing SQL directly to the application logic.\n\n## Front‑End (Admin Console)\n\nThe **Admin Console** is a web interface built with Next.js.  Its primary function is to give administrators and power users visibility and control over the system.  Major features include:\n\n* **Jobs Dashboard:** Displays active and past digest jobs, their statuses, progress bars and any errors.  Users can drill down into individual jobs to view their `profile.json`, `system_card.md`, SBOMs and vulnerability reports.\n* **Capacities & Capsules:** Shows currently running Capsules, their resource usage and health status.  Offers controls to spawn or destroy Capsules.\n* **Artefacts Explorer:** Lists generated artefacts (zip files, PDFs, embeddings, SBOMs).  Allows downloading via signed URLs and cross‑referencing to their origins.\n* **SBOM & Security:** Provides a dedicated section to review SBOMs, vulnerabilities, licences and risk scores.  Policies can be configured here (e.g. accepted licence list, vulnerability severity thresholds).\n* **Model Registry & Selector:** Displays available models, their metadata, benchmarks and usage statistics.  Administrators can add models to the ingestion queue or deprecate existing ones.  The ModelSelector’s decisions and rationales are visible for transparency.\n* **CRM Controls:** Allows toggling of CRM endpoint modes (shadow/write‑through), viewing recent calls, and measuring divergence between external CRM data and internal state.\n* **Settings & Feature Flags:** Provides toggles for enabling/disabling optional services (NATS, Supabase, vcluster) and adjusting environment variables.  Also offers secret rotation and certificate management.\n\n## Interaction Patterns\n\n* **External Clients:** Use the Gateway API to submit work.  They receive job IDs and can query progress or results.  Authentication tokens limit access based on roles.\n* **Internal Agents:** Call endpoints via Adapters.  For example, a CommandChiefAgent may call `/digest` to start digestion for a new source or `/models/ingest` to add an in‑house model.  Internal calls attach run IDs and context for traceability.\n* **Front‑End Users:** Access the Admin Console to monitor and control the system.  When they trigger actions (e.g. toggling a CRM endpoint), the console issues calls to the Gateway API on their behalf.\n\nBy exposing a clear API and a rich front‑end, ark‑os‑noa ensures that humans and agents can seamlessly interact with the system, inspect its state and adapt its behaviour without compromising security or traceability.\n# Intelligence & Learning in ark‑os‑noa\n\n## Vision\n\nark‑os‑noa aspires to be more than an automation platform—it aims to embody **agentic intelligence**.  Intelligence here means the ability to understand complex systems (codebases, data sets, SaaS integrations), reason about them, learn from past executions, anticipate future scenarios, and adapt models and workflows accordingly.  Learning is achieved through a combination of semantic understanding (knowledge graphs and embeddings), model evaluation, feedback loops and simulation of alternative futures (“branchwise foresight”).\n\n## Semantic Understanding\n\nAt the heart of ark‑os‑noa’s intelligence lies a **semantic representation** of the world:\n\n* **Knowledge Graphs:** Built by the Graph Extract and Digest services, these graphs link code symbols, data entities, API endpoints, configuration keys and other artefacts.  They capture relationships (calls, imports, reads/writes, dependency edges) and annotate nodes with metadata (e.g. licence, language, risk).  Knowledge graphs enable graph‑based queries and reasoning—answering questions like “Which services write to table X?” or “What code paths handle payment processing?”\n* **Embeddings & Vector DB:** The Embeddings Service converts source code, documentation and natural‑language descriptions into high‑dimensional vectors.  Stored in pgvector or Qdrant, these vectors power similarity search and clustering, enabling retrieval of semantically related items even if keywords differ.\n\n## Model Evaluation & Evolution\n\nThe **ModelSelectorAgent** plays a central role in learning.  By recording the performance (latency, cost, accuracy) and outcomes of each model used for a task, the system builds a knowledge base of model behaviours.  Over time, the selector’s heuristics can be tuned or even replaced by learned policies that maximise utility subject to constraints.  Benchmark results and feedback loops allow the system to retire underperforming models and onboard new ones seamlessly.\n\n## Feedback Loops & Trace Learning\n\nEvery execution produces a **Trace**—a record of inputs, actions, decisions, outputs and outcomes.  These traces are stored in Postgres along with logs and metrics.  Post‑run analyses mine these traces to identify patterns:\n\n* **Success patterns:** Which workflows succeeded quickly with minimal retries?  Which models performed best on certain task types?\n* **Failure modes:** Which tasks frequently hit policy violations or vulnerabilities?  Which connectors are unreliable?\n* **Cost hot‑spots:** Where is budget being spent?  Are there cheaper alternatives?\n\nInsights from these analyses can feed back into NOA’s planning and ModelSelector policies, closing the loop between execution and learning.\n\n## Mind Maps & Branchwise Foresight\n\nThe system leverages the knowledge graph and embeddings to construct **mind maps**—visual or conceptual maps of relationships between components, tasks and dependencies.  These maps assist in reasoning about the impact of changes, identifying missing connections and planning new integrations.\n\n**Branchwise foresight** refers to simulating multiple potential futures or scenarios before committing resources.  For example, before migrating a CRM function internally, NOA can instruct a MicroAgentStack to:\n\n1. **Simulate Strategy A:** Keep the external CRM; use the strangler proxy in shadow mode; measure divergence.\n2. **Simulate Strategy B:** Implement a minimal internal replacement for a specific endpoint; run synthetic load; compare latency and correctness.\n3. **Simulate Strategy C:** Replace the CRM entirely with internal modules and measure performance, cost and user impact.\n\nBy comparing the outcomes of these branches, NOA and the Board Agents can choose a course of action informed by data rather than intuition.  This approach aligns with the idea of **compound AI systems**, where tasks are decomposed into specialised modules and their outputs orchestrated【438618440126565†L248-L292】.\n\n## Continuous Learning & Improvement\n\nLearning in ark‑os‑noa is continuous:\n\n* **Auto‑patch loops:** When tests fail, Graph Extract proposes diffs, Runner applies them, and Safety verifies the fixes.  Successful patches can be proposed back to source repositories as pull requests.\n* **Change intelligence:** Scheduled self‑digests detect changes in upstream sources; the system predicts breaking changes and generates migration guides.\n* **Policy refinement:** The Board and NOA adjust policies (licence lists, vulnerability thresholds, model selection heuristics) based on operational data and emerging requirements.\n\nBy combining semantic representations, model analytics, feedback loops and foresight simulations, ark‑os‑noa evolves beyond a static workflow runner into an adaptive system capable of strategic reasoning and self‑improvement.\n"
      },
      "docs/combined_framework_architecture.md": {
        "language": "markdown",
        "code": "# Combined Framework & Architecture of ark‑os‑noa\n\n## High‑Level Overview\n\n**ark‑os‑noa** is an **agentic AI platform** designed to realise ElementArk/DeFlex’s business model.  It combines hierarchical organisational patterns (NOA → Board Agents → MicroAgentStacks → microservices) with modern infrastructure techniques (Capsule/Full‑Illusion pattern, private data plane, event bus) and an adaptable AI layer (ModelSelectorAgents and Digest Agent).  The result is a **“hive mind”** of specialised agents capable of digesting, reasoning about and producing artefacts across software, data and SaaS systems.\n\n## Layers & Hierarchy\n\n### 1. Strategy & Orchestration Layer\n\n- **NOA:** The ExecutiveCommanderChiefAgent at the top.  Transforms business goals into actionable plans, assigns Board Agents, sets policies, and monitors execution.\n- **Board Agents:** Domain‑specific executives (Strategy/CTO, COO, CFO/FinOps, Legal/Compliance, Security, Growth/Partnerships, R&D/Digest).  Each can commission work via MicroAgentStacks and request ModelSelector assistance.\n\n### 2. Execution Layer\n\n- **MicroAgentStacks:** On‑demand work pods orchestrated by a CommandChiefAgent.  Each stack contains Operators, Adapters and Guards and runs through a defined lifecycle (Bootstrap → Execute → Validate → Package → Archive).  Stacks interact with external sources (repos, CRMs, APIs) and internal services via Adapters.\n- **Expanded Digest Pipeline:** A set of microservices (Intake, Classifier, Graph Extract, Embeddings, Env Synthesis, Safety, Runner, Integrator, Registrar) that perform the actual work.  Each is loosely coupled via an event bus and runs inside the Capsule environment.  CRM Strangler and Model Serving are additional services.\n\n### 3. Infrastructure Layer\n\n- **Capsule Architecture (Full Illusion):** Encapsulates stacks and services in a sandbox that forwards build operations and network traffic to the outer runtime.  Capsule sidecars (Build‑Proxy, Service‑Mirror, Policy Agent, Telemetry Agent, optionally vcluster) provide the illusion of Docker‑in‑Docker and Kubernetes‑in‑Kubernetes without their drawbacks【716409907369096†L1037-L1067】.\n- **Event Bus & Orchestration:** Redis Streams (primary) and optional NATS enable asynchronous communication.  A workflow engine coordinates the pipeline steps, handling retries and backoff.\n- **Data Plane:** Private OCI registry, MinIO, Postgres (+ pgvector/Supabase) and optionally Qdrant.  This plane stores everything from container images to embeddings and ensures data stays within the trust boundary.\n- **Observability & Security:** OTel tracing, Prometheus metrics, policy agents, SBOM/vulnerability scanners and secrets management.  The **no DinD** policy and user namespaces reduce privilege escalation risk【43537238352704†L1068-L1088】.\n\n## How the Pieces Fit Together\n\n1. **Goal Intake:** A high‑level goal arrives.  NOA normalises it into a WorkPlan and determines which Board Agents are responsible.\n2. **Board Planning:** Board Agents refine the goal, assign budgets, define SLAs and set policies.  They request MicroAgentStacks and ModelSelectorAgents as needed.\n3. **Stack Deployment:** For each task, a MicroAgentStack is spawned.  The stack uses Adapters to fetch sources (repos, CRMs), Operators to parse/analyse, and Guards to enforce policies.  Microservices implement the digest pipeline, orchestrated via the event bus.\n4. **Model Selection & Execution:** When a service or operator needs AI inference (embeddings, summarisation, code explanation), it calls a ModelSelectorAgent.  The selected model is executed via local model servers or remote APIs.\n5. **Data Persistence:** Outputs from each step (SBOMs, graphs, embeddings, demos) are persisted via the Data Plane.  The Registrar Service updates indexes and metadata.\n6. **Completion & Reporting:** Once tasks finish, the stack packages results into a zip and compiled PDF, publishes them to MinIO and the registry, and updates Postgres.  NOA receives a report and archives the run.\n\n## Why This Architecture?\n\n1. **Modularity & Scalability:** By decomposing functionality into microservices and agents, ark‑os‑noa can scale horizontally and update components independently—avoiding the pitfalls of monolithic systems【43537238352704†L1068-L1088】.\n2. **Security & Compliance:** The Capsule pattern, no DinD policy, private data plane and sidecar enforcement minimise the attack surface.  SBOMs, licences and vulnerability scans ensure supply‑chain integrity.\n3. **Intelligence & Adaptability:** ModelSelectorAgents enable adaptive AI usage; the Digest Agent builds knowledge graphs and embeddings; the board can ingest CRMs and SaaS systems without downtime using the strangler proxy.\n4. **Auditability & Provenance:** Every decision, model selection and action is logged in Postgres and associated with a run ID.  Artefacts are content‑addressed and signed.  This supports post‑mortems, compliance and future learning.\n\n## Extensibility\n\n* **New Board roles:** Additional executives (e.g. Marketing, HR) can be added by extending the roster and defining their domains and policies.\n* **Additional microservices:** New processing stages (e.g. code transformers, simulation engines) can be plugged into the pipeline without redesigning the whole system.\n* **Hybrid deployment:** While Compose is used locally, Kubernetes manifests (`k8s/`) can be applied to a cluster; the same Capsule pattern applies.\n* **Model & Connector expansions:** New AI models are registered via the ModelSelector; new connectors are implemented by Adapters to integrate more SaaS or data sources.\n\nThe **Combined Framework & Architecture** unifies strategic planning, microservice execution, security and AI into a cohesive system.  It is intentionally modular to allow continuous growth and improvement.\n"
      },
      "docs/combined-architecture-v.2.txt": {
        "language": "text",
        "code": "﻿NOA - ExecutiveCommanderChiefAgent\nOverview\nArk-AI-NOA is a local-first agentic OS: a hive-mind of orchestrated micro-agent stacks that plan, act, learn, adapt, and self-upgrade your entire software/hardware environment. It replaces traditional apps and cloud-fragility with a neural runtime + dynamic UI that digests code/data, composes tools on demand, and continuously optimizes itself across Server, Network, PC and mobile. Long-term, NOA is the autonomous command center that owns your stack end-to-end-air-gapped when needed, auditable, and capable of running any business autonomously without SaaS.\nDefinition & Purpose\nNOA (sometimes called the ExecutiveCommanderChiefAgent) is the top-level orchestrator of the ark-os-noa platform. It acts like a CEO for the agent ecosystem: it translates high-level business goals into concrete plans, delegates work to Board Agents and MicroAgentStacks, and ensures that every deliverable meets business, technical, and compliance requirements.\nFramework\n• Inputs: high-level goals, success criteria, budgets, SLAs, risk appetite and constraints. NOA normalises these into a WorkPlan. Each plan captures tasks, checkpoints, deadlines and deliverables.\n• Outputs: action plans, stack assignments, acceptance tests and post-mortems. For each goal NOA produces a package of artefacts (e.g. zip file and compiled PDF).\n• Control loop: Sense → Plan → Act → Verify → Report. NOA constantly senses progress and risks, replans when necessary, acts by spawning or destroying MicroAgentStacks, verifies outputs against acceptance criteria, and finally reports to the business owner.\nGoals\n1. Disambiguate and decompose: convert ambiguous goals into measurable objectives and step-by-step tasks.\n2. Resource allocation: assign Board Agents and MicroAgentStacks based on domain expertise, constraints and availability.\n3. Policy enforcement: apply safety, security and legal policies; ensure no Docker-in-Docker (Capsule/Full-Illusion pattern) and maintain audit logs.\n4. Model selection: orchestrate ModelSelectorAgents to pick appropriate AI models for each task, balancing accuracy, latency and cost.\n5. Packaging & archiving: guarantee that outputs are packaged into deliverable artefacts (zip + PDF) and stored internally.\nCapabilities\n• Decomposition & scheduling: build dependency graphs, schedule tasks across stacks and board seats, and respect deadlines.\n• Auto-retry & escalation: detect failures or blockers and retry tasks with backoff; when automation fails, summarise context and ask for human input.\n• Observability: generate unique run IDs, attach traces and metrics, and centralise logs for all stacks.\n• Safety & compliance: enforce licensing, vulnerability thresholds and secret scanning. Use outer BuildKit and containerd with sidecars rather than nested containers to avoid security risks【43537238352704†L1068-L1088】.\nObjects & Definitions\n• WorkPlan: a structured representation of a goal → tasks → checkpoints → deliverables → review gates.\n• Assignment: mapping between Board Agents, MicroAgentStacks and tasks; includes SLAs and ownership.\n• Trace: evidence of inputs, actions, tools, models and outputs for audit and reproducibility.\nLifecycle\n1. Intake & Normalise: accept a business goal and convert it into a WorkPlan.\n2. Resource Match: choose which Board Agents and stacks are needed and spin them up.\n3. Execution: coordinate tasks across microservices; check progress with periodic checkpoints.\n4. Validation & Packaging: verify results, run security and licence scans, and package deliverables.\n5. Report & Archive: summarise results, produce a post-run report, archive artefacts with retention policies.\nTools & Resources\nNOA can invoke various tools through subordinate agents, including: web research, code & data analysis, file search, and automations. It delegates model selection to ModelSelectorAgents and leverages microservices to execute tasks. It works with the internal data plane (OCI registry, MinIO, Postgres/pgvector, Supabase) to store and retrieve artefacts, always within the trust boundary.# Board Agents - Executive Team of ark-os-noa\nDefinition & Role\nThe Board Agents sit at the top of the ark-os-noa organization just below NOA. They are analogous to an executive board in a company: each agent owns a domain (strategy, operations, finance, legal, security, partnerships, research) and has authority to commission MicroAgentStacks to execute work. By design they are few in number but broad in scope-their purpose is to translate NOA's vision into specific missions, ensure alignment with ElementArk/DeFlex's business model, and provide governance across all stacks and agents.\nRoster & Responsibilities\n• Strategy/CTO Agent - Sets technical direction: system architecture, Capsule (Full-Illusion) adoption, environment policies (no Docker-in-Docker), cohesion across services.\n• COO Agent - Owns operational runbooks, SLAs, scheduling and change management. Coordinates delivery timelines and resource utilization.\n• CFO/FinOps Agent - Manages budgets and spend telemetry. Optimizes cost across compute, storage and model usage.\n• Legal/Compliance Agent - Ensures license compliance, data governance, export controls and regulatory adherence. Maintains policy frameworks.\n• Security Agent - Enforces secrets management, supply-chain security, SBOM attestation and vulnerability thresholds. Gatekeeper for risk.\n• Growth/Partnerships Agent - Curates ingestion roadmaps for repos, APIs and CRMs; drives ecosystem strategy and partnership integrations.\n• Digest Agent (R&D) - Sits on the board as the research arm. Its role is to digest everything (code, data, SaaS, models) and surface insights. See digest_agent.md for details.\nOperating Rules\n1. Delegation: Board Agents can spin up one or more MicroAgentStacks to accomplish tasks. Each stack has its own CommandChiefAgent orchestrating the details, leaving the Board Agent to focus on strategy and oversight.\n2. Specialization: When a task requires sophisticated model selection, a Board Agent requests a ModelSelectorAgent to choose the most appropriate AI model or tool. This ensures tasks are executed with the right balance of cost, latency and accuracy.\n3. Governance: Board Agents enforce policies across stacks-licensing, vulnerability gates, security posture, and budget limits. They maintain decision logs and risk registers for audit.\n4. Parallelism: Multiple stacks can run concurrently. Board Agents schedule tasks to maximise throughput while respecting resource constraints.\nCapabilities\n• Multi-project scheduling: assign and monitor numerous tasks across different domains and stacks; handle dependencies and deadlines.\n• Cross-repo initiatives: coordinate wide-sweep digest operations (e.g., SBOM/security posture across all repos) by commissioning multiple stacks.\n• Program governance: maintain an overarching view of risks, mitigations, budget spend, and deliverable quality.\n• Policy enforcement: integrate security scanners, license gates, and compliance checks into the workflow.\nTools & Signals\nBoard Agents interact with the system through:\n• Research & analysis tools: for web search, code parsing and data exploration within the current year's context.\n• Change control & telemetry: CI/CD gates, policy engines (e.g. OPA), vulnerability scanners and cost dashboards.\n• Observability feeds: real-time traces, metrics and logs aggregated from MicroAgentStacks and sidecars. These signals inform decisions on scaling up/down stacks or raising alerts.\nRelationship to Other Components\n• NOA: Board Agents receive missions from NOA and report status back. They provide domain expertise and enforce governance while letting NOA handle high-level planning and cross-domain coordination.\n• MicroAgentStacks: Board Agents are the owners of stacks. They commission stacks to achieve defined objectives and decommission them when tasks complete. Each stack operates autonomously but reports progress to its Board Agent.\n• ModelSelectorAgents: When tasks require AI model inference, Board Agents request a ModelSelector to choose among local or hosted models. The selection is recorded in the trace for audit.\n• Digest Agent: The Digest Agent is part of the Board but behaves like an R&D lab-collecting raw information, synthesising knowledge graphs and summarising findings for the board to act on.\nBy keeping the Board Agents separate from execution details yet close enough to enforce policy, ark-os-noa achieves a balance between strategic oversight and operational agility. # ModelSelectorAgents - Choosing the Right Tool for the Job\nPurpose\nA ModelSelectorAgent specializes in selecting the best AI model or tool for a given task. In the context of ark-os-noa, tasks vary widely-from reasoning and planning to code analysis, to data transformation. Selecting the wrong model can waste resources or compromise privacy. The ModelSelector provides an intelligent arbitration layer, helping Board Agents and MicroAgentStacks achieve high quality results while respecting cost, latency and privacy constraints.\nFramework\n• Inputs: Each call to a ModelSelector includes a task description, input size (e.g. document length, number of files), the privacy tier (public, sensitive, confidential), latency budget, and a cost cap. These parameters come from the requesting agent (often a Board Agent or CommandChiefAgent).\n• Decision Graph: The ModelSelector applies a decision graph:\n Task classification - Is this reasoning/planning, bulk transformation, code/data manipulation, or something else?\n Complexity estimation - How large or intricate is the input? This influences whether to use a bigger model or a lightweight one.\n Model/Tool selection - Choose from a catalogue of available models (remote APIs, local models served via llama.cpp/Ollama, code runners, data converters) using heuristics or learned policies.\n Guardrails assertion - Check licensing, privacy levels and security requirements. For example, confidential data must stay on-prem and use local models.\n• Outputs: A plan specifying the chosen model or tool, the expected cost/latency, and a rationale. The rationale becomes part of the execution Trace, enabling auditing and future optimisation.\nDefault Policy\nThe default policy can be tuned, but common guidelines include:\n1. Reasoning / Planning tasks: Use high-quality generalist models (e.g. GPT-5). These tasks benefit from advanced reasoning and tolerance for slower latency when results matter.\n2. Bulk transforms / formatting: Use fast, cost-efficient models; they handle repetitive conversions without needing deep reasoning.\n3. Code & data tasks: Prefer dedicated code analysis tools or local runtimes for safety. Use sandboxed execution to evaluate code or parse data. Employ smaller codex models when summarising code.\n4. Offline/local fallbacks: If the privacy tier demands on-prem processing or if network latency is unacceptable, use local models served via llama.cpp, vLLM or similar frameworks. This reduces latency and eliminates external data exposure.\nTools & Telemetry\n• Model catalogues: The selector maintains metadata about available models-accuracy, context limits, token costs, latency benchmarks, licensing and hardware requirements. It syncs with the local model server and remote provider APIs.\n• Cost/latency forecaster: Predicts cost and latency using historical telemetry and dynamic system load. This helps decide when to use a cheaper but slower model vs. a more expensive high-performance one.\n• Performance feedback: The selector ingests feedback after tasks complete (e.g. success, error rate, user satisfaction). Over time it learns to better match tasks to models.\nRelationship to Other Components\n• Board Agents: Request ModelSelector assistance when their tasks involve AI/ML. They set budgets and specify privacy tiers. The ModelSelector returns a plan and rationale.\n• MicroAgentStacks: CommandChiefAgents invoke ModelSelectors inside their stacks when a task requires AI processing. This ensures each stack uses consistent policies and optimal models.\n• NOA: Maintains overarching policies for model selection (allowed licenses, vulnerability gates, GPU quotas). The ModelSelector enforces these policies and logs decisions back to NOA's audit trail.\nBenefits\n• Efficiency: Avoids blindly calling the largest or default model for every task, saving compute and cost.\n• Compliance: Ensures tasks adhere to privacy and licensing requirements-confidential data stays internal.\n• Transparency: Provides a clear rationale for each selection so decisions can be audited and improved.\n• Extensibility: New models or tools can be added to the catalogue; the decision graph can be refined with new criteria or learned policies.\nBy delegating model/tool choice to a dedicated ModelSelectorAgent, ark-os-noa keeps business logic and AI expertise separate, resulting in better outcomes and traceable decisions. # MicroAgentStack - Cooperative Work Pods\nDefinition\nA MicroAgentStack is a deployable cluster of cooperative agents assembled to accomplish a bounded objective. Think of it as a project team spun up on demand: each stack has its own CommandChiefAgent (the stack master), a set of specialized Operators, Adapters and Guards, and a dedicated workspace. Stacks can be created, scaled and destroyed rapidly, making them the primary execution units within ark-os-noa.\nComposition\n• CommandChiefAgent (Stack Master): Orchestrates the stack, decomposes tasks, assigns work to subordinate agents, monitors progress, resolves conflicts and enforces SLAs.\n• Operators: Specialized agents that perform specific functions. Examples include code runners (execute code), data wranglers (transform data), doc generators (produce reports), testers (run unit/integration tests) and packagers (build zips, PDFs).\n• Adapters: Connectors to external systems (repos, CRMs, APIs) and publishers to internal services (registry, MinIO, Postgres). Adapters abstract away details like auth and rate-limits.\n• Guards: Policy enforcement points-security scanners, license checkers, quality gates. They ensure the stack adheres to policies defined by NOA and the Board Agents.\nGoals\n1. Deliver end-to-end outcomes: A stack should own the entire life cycle of its objective-from cloning a repo to producing a digest report, from running tests to publishing a package.\n2. Scale horizontally: Multiple stacks can be spun up concurrently when tasks are independent or parallelizable. This enables large scale operations like digesting hundreds of repos simultaneously.\n3. Clean teardown: After completion, a stack cleans up its resources (containers, temporary volumes) and archives logs, SBOMs and artefacts with proper retention policies.\nLifecycle\n1. Bootstrap: Given inputs (e.g. repo URL, CRM base URL, model list), the CommandChiefAgent creates a WorkPlan, prepares the environment and mounts necessary sidecars. It avoids Docker-in-Docker by using Capsule sidecars to talk to the outer BuildKit/containerd environment【43537238352704†L1068-L1088】.\n2. Execute: The stack runs its Operators in parallel where possible. Retrying tasks with exponential backoff ensures resilience; failures trigger controlled retries or escalation to the Board Agent.\n3. Validate: Once tasks finish, Guards run acceptance tests (e.g. unit tests, SBOM scans, license checks) and produce human-readable summaries. If acceptance criteria fail, the stack either retries or fails the WorkPlan.\n4. Package: On success, the stack assembles outputs into deliverables (zip file, compiled PDF, JSON indices). It updates internal registries (OCI images, Postgres metadata, vector DB) and publishes logs and traces.\n5. Archive: The stack removes its runtime environment and persists all logs, SBOMs, run IDs, and checksums. Retention policies decide how long to keep each artefact.\nOne-liners & Conventions\n• Stacks are named by timestamps or descriptive identifiers (e.g. stack-20250822-103045).\n• They maintain their own directory structure (in/, work/, out/, logs/) for clarity and reproducibility.\n• Each stack produces a unique run ID and attaches it to all outputs and logs for traceability.\nRelationship to Other Components\n• Board Agents: Create and oversee stacks. Each stack reports to its Board Agent. Board Agents can run multiple stacks in parallel.\n• ModelSelectorAgents: When a stack requires AI processing, the CommandChiefAgent requests a ModelSelector to choose the appropriate model and logs the rationale.\n• Digest Agent: Often uses MicroAgentStacks to perform large-scale digestions across many repos or datasets. Each stack digests one or more sources and returns results to the Digest Agent.\nMicroAgentStacks bring structure, scalability and reliability to ark-os-noa's execution model. By isolating work into bounded pods, the system can handle complex, parallel workflows without turning into a monolith. # Digest Agent - R&D Engine for ark-os-noa\nRole & Position\nThe Digest Agent operates as the research and development arm of the Board Agents. Its primary mission is to \"digest everything\"-code repositories, datasets, documents, APIs, SaaS systems (including live CRMs) and even AI models. By analysing these sources, the Digest Agent extracts structured knowledge, builds semantic indices, and surfaces insights that inform strategic decisions. Though part of the Board, it behaves like a self-contained lab, spinning up MicroAgentStacks to perform large-scale digestions.\nPipeline\n1. Discover: Identify sources to digest. This includes scanning internal GitHub repos, listing connected APIs/CRMs, and reading the current model ingestion list. Discovery may rely on board directives or scheduled tasks.\n2. Fetch: Clone or synchronise the source material. For code repos, perform a shallow clone and gather dependency lock files. For CRMs or APIs, pull metadata and sample records while respecting rate limits. Handle authentication using secure tokens from the secrets manager.\n3. Parse: Use language-specific parsers (Python AST, ts-morph for JS/TS, go/ast, Rust syn, JavaParser) to analyse code and extract modules, functions, classes and call graphs. For API schemas, parse OpenAPI/GraphQL definitions. Build an SBOM to capture all packages and versions.\n4. Analyze: Generate embeddings for code, documentation and data using models selected via the ModelSelectorAgent. Build a knowledge graph linking functions, data structures, APIs and entities. Identify external API calls, config surfaces and extension points. Apply entity linking to unify references across sources.\n5. Summarize: Produce layered summaries: per file, per module, per repository and across repositories. Summaries highlight the system's purpose, architecture, dependencies, risks and extension points. The Digest Agent uses LLMs to craft human-readable reports and cross-links to original sources.\n6. Surface: Publish outputs as markdown dossiers, dashboards and vector DB upserts. Persist profile.json, system_card.md, kg.json, and embeddings. Offer search and retrieval APIs for downstream agents.\n7. Secure: Scan for secrets and vulnerabilities using tools like Trivy, Grype and Gitleaks. Classify findings by severity and quarantine sensitive information. Tag licences and export-control flags【43537238352704†L1068-L1088】.\nTools\n• Web research: limited to current-year sources, retrieving official documentation and examples.\n• Language parsers & AST tools: Python's ast, TS's ts-morph, Go's go/ast, Rust's syn, Java's JavaParser.\n• Security scanners: Syft to produce SBOMs; Grype and Trivy to scan for vulnerabilities; Gitleaks to detect secrets; Semgrep for static analysis.\n• Embeddings & vector DB: Sentence transformers or llama.cpp embedding models; pgvector or Qdrant to store vectors and link them to original files.\n• Visualization & reports: Graph builders, markdown generators and PDF compilers.\nOutputs\nThe Digest Agent delivers:\n• Digest reports: Markdown documents (e.g. 2025-08-22_digest_report.md) summarizing findings.\n• Structured indices: JSONL files representing the knowledge graph, call graph and embedding metadata. These feed search and retrieval APIs.\n• SBOM & security reports: Comprehensive lists of dependencies and vulnerabilities.\n• Vector store entries: Embeddings asserted to the chosen vector DB for semantic search.\nRelationship to Other Components\n• Board Agents: Commission digestion tasks and consume the Digest Agent's findings when making strategic decisions.\n• MicroAgentStacks: Used to parallelize large digests-each stack handles a set of sources and feeds results back to the Digest Agent. Use t-digest as needed. \n• ModelSelectorAgents: Select embedding models and summarization LLMs appropriate for each source type. For example, code summarization may use a codex model, while plain text summarization uses a general LLM.\n• Data & Storage layer: Stores artefacts and indices in MinIO, Postgres and the vector store. The Digest Agent ensures proper metadata tagging and retention policies.\nBy systematically consuming and analyzing every relevant piece of information, the Digest Agent turns unstructured data into actionable knowledge for ark-os-noa's decision makers. # Backend - Services & Infrastructure of ark-os-noa\nPurpose\nThe backend of ark-os-noa comprises all of the runtime services and infrastructure that turn high-level plans into concrete work. It includes the event bus, microservices that implement the Expanded Digest Pipeline, sidecars that enable the Capsule pattern, and internal data stores. Together, these components provide a robust, scalable and secure environment for executing tasks, orchestrated by NOA and the Board Agents.\nServices & Microservices\nCore Pipeline Services\nThe digest-everything pipeline is decomposed into a series of microservices, each responsible for a discrete stage. Running them as independent services ensures that each can scale, fail and be updated independently, which is aligned with microservice best practices【43537238352704†L1068-L1088】.\n1. Intake Service: Receives digest requests; validates inputs (repo URLs, API endpoints, model lists); creates provenance records and initializes workspace directories.\n2. Classifier Service: Detects programming languages, build systems, service types (CLI, API, library) and licences. Produces a profile.json summarising the source.\n3. Graph Extract Service: Parses code and schemas to build call graphs, data flow graphs and config surfaces. Supports multi-language parsing (Python, JS/TS, Go, Rust, Java). Outputs kg.json and system_card.md.\n4. Embeddings Service: Generates embeddings for code and documentation using models selected by ModelSelectorAgents. Upserts vectors to pgvector or Qdrant.\n5. Env Synthesis Service: Emits Dockerfiles, docker-compose YAML, Kubernetes manifests, .env.example, Makefile targets and config schemas. Ensures reproducible builds using outer BuildKit (no DinD).\n6. Safety Service: Runs SBOM generation (Syft), vulnerability scans (Grype/Trivy), secret scans (Gitleaks) and static analysis (Semgrep). Applies policy gates; stops the pipeline on critical issues.\n7. Runner Service: Builds and runs the source in a controlled container environment; executes existing tests or generates smoke tests; produces demo.md.\n8. Integrator Service: Generates adapters (SDKs for Python, Node, Go), telemetry hooks and policy stubs; prepares packaging instructions.\n9. Registrar Service: Writes outputs and metadata to storage (registry, MinIO, Postgres); registers embeddings; updates indexes for search.\nAuxiliary Services\n• CRM Strangler Proxy: Provides a transparent layer between internal clients and an external CRM. It records requests/responses, supports shadow and write-through modes, and allows incremental internal re-implementation of CRM features.\n• Model Serving: Hosts local models using frameworks like llama.cpp, Ollama or vLLM. Exposes endpoints for inference and embedding generation. Each model server is packaged in its own container with health checks.\n• Gateway API: A FastAPI service exposing endpoints: /digest, /capsule/spawn, /crm/toggle, /models/ingest, /models/benchmark, /admin/*. Acts as the single entry point for external clients and the front-end.\nEvent Bus & Orchestration\n• Redis Streams: Provides the primary event bus for inter-service communication. Services consume and produce events in a decoupled fashion. The bus also supports message persistence and backpressure.\n• NATS (optional): A lightweight publish/subscribe system for high fan-out or cross-cluster communication. Enabled via a feature flag.\n• Workflow Engine: A simple DAG engine built on Redis to coordinate pipeline tasks with retries and backoff. Temporal or Argo Workflows can be integrated later for more sophisticated orchestrations.\nCapsule Sidecars\nAll containers run inside a \"Capsule\" to simulate container-in-container and Kubernetes-in-Kubernetes workflows without the security and performance drawbacks【716409907369096†L1037-L1067】. Capsule sidecars include:\n1. Build-Proxy: A lightweight service that proxies inner docker build and nerdctl commands to the outer BuildKit daemon. It exposes a local socket inside the Capsule but forwards build requests externally, avoiding duplicate layer storage.\n2. Service-Mirror: Watches inner service definitions and publishes corresponding services in the outer service mesh with mTLS and SLO configurations. This allows inner services to be reachable and observable from the outer plane.\n3. Policy Agent (OPA): Enforces egress rules, resource quotas, and other policies at the Capsule boundary. It integrates with eBPF to block unauthorised traffic.\n4. Telemetry Agent: Collects traces, metrics and logs from the inner services and sidecars. It forwards data to the central observability stack with proper trace-ID propagation.\n5. vcluster (optional): Provides a lightweight Kubernetes API server inside the Capsule for tools that require kubectl. It maps pods to the parent cluster's nodes without duplicating container runtimes.\nData Stores\n• OCI Registry: Stores container images, compiled outputs and Capsule definitions. The registry uses content-addressed storage and enforces immutable tags.\n• MinIO: Stores large artefacts, zipped deliverables, SBOMs and data sets. Supports versioning and server-side encryption.\n• Postgres (+ Supabase): Maintains metadata (profiles, system cards, run logs), traces, job statuses and vector search indices. Supabase provides developer APIs and pgvector integration.\n• Vector Store: For embeddings. The backend can be pgvector in Postgres or an external Qdrant instance. A feature flag chooses which driver to enable.\nSecurity & Compliance\nThe backend enforces numerous policies:\n• No DinD: Build operations are forwarded to outer BuildKit/containerd; containers run with user namespaces and seccomp, preventing container-root escalation【43537238352704†L1068-L1088】.\n• Licence & vulnerability gates: The Safety service halts builds on critical issues; the Board Agents define accepted licence lists and vulnerability thresholds.\n• Secrets management: Secrets are never stored in environment variables. They are mounted as files via Vault or similar systems, and sidecars are responsible for retrieving them.\n• Audit trails: Every API call, pipeline event and model selection decision logs context (who, what, when, rationale). These logs live in Postgres and are tied to run IDs.\nDevelopment & Testing\n• Makefile: Provides convenience targets (make up, make down, make logs, make demo, make scan, make lock-images) for developers. It ensures consistent environment setup and teardown.\n• Docker-Compose: Defines services and dependencies; profiles enable optional components like NATS, Supabase and vcluster. Compose is used for local development. For production, manifests under k8s/ can be applied to a Kubernetes cluster.\n• Automated tests: Unit and integration tests run within the Runner Service; security scanners run in the Safety Service. CI pipelines (to be implemented post-launch) build images, run tests, generate SBOMs and publish artefacts.\nBy modularising the backend into clear services and infrastructure layers, ark-os-noa achieves the flexibility of microservices with the discipline of reproducible builds and strong security controls. # Data & Storage - Securing the ark-os-noa Data Plane\nPrinciple\nThe data layer of ark-os-noa is built around a core principle: keep all storage within the trust boundary. All artefacts-images, datasets, logs, metadata, SBOMs-are retained internally, signed and versioned. Only signed, approved deliverables are exported. This ensures confidentiality, integrity and provenance across the platform.\nComponents\n1. Private OCI Registry: Hosts container images, Capsule definitions, build outputs and adapters. Using a private registry prevents untrusted images from entering the environment and allows BuildKit to push/pull from a controlled backend.\n2. MinIO (S3-compatible object store): Serves as the main artefact store. It holds large files (zip archives, compiled PDFs), dataset fragments, SBOM documents, vulnerability reports and even model shards. MinIO offers versioning, server-side encryption (SSE) and lifecycle management.\n3. Postgres: Stores structured metadata: run logs, profiles (profile.json), system cards (system_card.md), call graphs (kg.json), job statuses, policy decisions and audit trails. Postgres also stores vector embeddings via the pgvector extension.\n4. Supabase: A self-hosted instance of Supabase augments Postgres with developer APIs, authentication and real-time features. It provides a convenient interface for front-end applications and external tools until the platform fully internalises these capabilities.\n5. Vector Store: Embeddings generated by the Embeddings Service are stored in either pgvector (Postgres) or a dedicated Qdrant cluster. pgvector is enabled by default for simplicity; Qdrant can be turned on via a feature flag to support larger vector workloads.\nPolicies & Best Practices\n• Immutability: Artefacts are stored content-addressed using SHA-256 digests. Tags or names are pointers to immutable content; rewriting tags triggers new versions. This prevents tampering and ensures reproducible builds.\n• Lineage & Provenance: Each deliverable (zip, PDF, image) links back to its inputs, tools, models and run ID. Build provenance is stored as JSON attestation, capturing the environment, command, dependency versions and commit hashes.\n• Retention: Short-lived runs (e.g. experimental digests) are kept for a limited period; long-term artefacts (e.g. official releases) are retained indefinitely. Policies can be configured per project or domain.\n• Access Control: The data plane uses least privilege. Microservices receive temporary scoped tokens to access the object store or registry; access is audited. Secrets (e.g. tokens, keys) are stored in a secrets manager (Vault) and mounted as files, never as environment variables.\nIntegration with Other Components\n• Backend services: Interact with the registry and MinIO via signed URLs or direct API calls. BuildKit pushes images to the registry; the Registrar Service writes artefacts to MinIO and records metadata in Postgres.\n• Digest Agent: Reads and writes to MinIO and Postgres; uploads embeddings to the vector store. It uses the registry to store intermediate build images.\n• Model Selector and Model Servers: Use Postgres (via pgvector or Qdrant) to store model metadata and evaluation results. Models themselves may be stored as OCI artefacts or in MinIO shards.\n• Front-end: Accesses Supabase for real-time updates and uses signed URLs to fetch artefacts from MinIO.\nOne-Liners & Conventions\n# Create local directories mirroring services (for dev/testing)\nmkdir -p storage/{oci,minio,postgres,supabase,artifacts} && tree -L 2 storage || ls -R storage\n\n# Content-address an artefact\ndigest=$(sha256sum output.zip | awk '{print $1}')\ncp output.zip storage/artifacts/${digest}.zip\nWhy Internal Data Planes Matter\nKeeping storage internal reduces the attack surface and simplifies compliance. Data never leaves the environment without explicit signing and approval. When combined with provenance tracking, this approach ensures that every piece of data can be traced back to its origin and verified-critical for regulated environments and supply-chain integrity. # Combined Framework & Architecture of ark-os-noa\nHigh-Level Overview\nark-os-noa is an agentic AI platform designed to realise ElementArk/DeFlex's business model. It combines hierarchical organisational patterns (NOA → Board Agents → MicroAgentStacks → microservices) with modern infrastructure techniques (Capsule/Full-Illusion pattern, private data plane, event bus) and an adaptable AI layer (ModelSelectorAgents and Digest Agent). The result is a \"hive mind\" of specialised agents capable of digesting, reasoning about and producing artefacts across software, data and SaaS systems.\nLayers & Hierarchy\n1. Strategy & Orchestration Layer\n• NOA: The ExecutiveCommanderChiefAgent at the top. Transforms business goals into actionable plans, assigns Board Agents, sets policies, and monitors execution.\n• Board Agents: Domain-specific executives (Strategy/CTO, COO, CFO/FinOps, Legal/Compliance, Security, Growth/Partnerships, Digest). Each can commission work via MicroAgentStacks and request ModelSelector assistance.\n2. Execution Layer\n• MicroAgentStacks: On-demand work pods orchestrated by a CommandChiefAgent. Each stack contains Operators, Adapters and Guards and runs through a defined lifecycle (Bootstrap → Execute → Validate → Package → Archive). Stacks interact with external sources (repos, CRMs, APIs) and internal services via Adapters.\n• Expanded Digest Pipeline: A set of microservices (Intake, Classifier, Graph Extract, Embeddings, Env Synthesis, Safety, Runner, Integrator, Registrar) that perform the actual work. Each is loosely coupled via an event bus and runs inside the Capsule environment. CRM Strangler and Model Serving are additional services.\n3. Infrastructure Layer\n• Capsule Architecture (Full Illusion): Encapsulates stacks and services in a sandbox that forwards build operations and network traffic to the outer runtime. Capsule sidecars (Build-Proxy, Service-Mirror, Policy Agent, Telemetry Agent, optionally vcluster) provide the illusion of Docker-in-Docker and Kubernetes-in-Kubernetes without their drawbacks【716409907369096†L1037-L1067】.\n• Event Bus & Orchestration: Redis Streams (primary) and optional NATS enable asynchronous communication. A workflow engine coordinates the pipeline steps, handling retries and backoff.\n• Data Plane: Private OCI registry, MinIO, Postgres (+ pgvector/Supabase) and optionally Qdrant. This plane stores everything from container images to embeddings and ensures data stays within the trust boundary.\n• Observability & Security: OTel tracing, Prometheus metrics, policy agents, SBOM/vulnerability scanners and secrets management. The no DinD policy and user namespaces reduce privilege escalation risk【43537238352704†L1068-L1088】.\nHow the Pieces Fit Together\n1. Goal Intake: A high-level goal arrives. NOA normalises it into a WorkPlan and determines which Board Agents are responsible.\n2. Board Planning: Board Agents refine the goal, assign budgets, define SLAs and set policies. They request MicroAgentStacks and ModelSelectorAgents as needed.\n3. Stack Deployment: For each task, a MicroAgentStack is spawned. The stack uses Adapters to fetch sources (repos, CRMs), Operators to parse/analyse, and Guards to enforce policies. Microservices implement the digest pipeline, orchestrated via the event bus.\n4. Model Selection & Execution: When a service or operator needs AI inference (embeddings, summarisation, code explanation), it calls a ModelSelectorAgent. The selected model is executed via local model servers or remote APIs.\n5. Data Persistence: Outputs from each step (SBOMs, graphs, embeddings, demos) are persisted via the Data Plane. The Registrar Service updates indexes and metadata.\n6. Completion & Reporting: Once tasks finish, the stack packages results into a zip and compiled PDF, publishes them to MinIO and the registry, and updates Postgres. NOA receives a report and archives the run.\nWhy This Architecture?\n1. Modularity & Scalability: By decomposing functionality into microservices and agents, ark-os-noa can scale horizontally and update components independently-avoiding the pitfalls of monolithic systems【43537238352704†L1068-L1088】.\n2. Security & Compliance: The Capsule pattern, no DinD policy, private data plane and sidecar enforcement minimize the attack surface. SBOMs, licences and vulnerability scans ensure supply-chain integrity.\n3. Intelligence & Adaptability: ModelSelectorAgents enable adaptive AI usage; the Digest Agent builds knowledge graphs and embeddings; the board can ingest CRMs and SaaS systems without downtime using the strangler proxy.\n4. Auditability & Provenance: Every decision, model selection and action is logged in Postgres and associated with a run ID. Artefacts are content-addressed and signed. This supports post-mortems, compliance and future learning.\nExtensibility\n• New Board roles: Additional executives (e.g. Marketing, HR) can be added by extending the roster and defining their domains and policies.\n• Additional microservices: New processing stages (e.g. code transformers, simulation engines) can be plugged into the pipeline without redesigning the whole system.\n• Hybrid deployment: While Compose is used locally, Kubernetes manifests (k8s/) can be applied to a cluster; the same Capsule pattern applies.\n• Model & Connector expansions: New AI models are registered via the ModelSelector; new connectors are implemented by Adapters to integrate more SaaS or data sources.\nThe Combined Framework & Architecture unifies strategic planning, microservice execution, security and AI into a cohesive system. It is intentionally modular to allow continuous growth and improvement. # API, Connectors & Front-End of ark-os-noa\nGateway API\nThe Gateway API is the central entry point for interacting with ark-os-noa's backend services. Implemented using FastAPI, it exposes endpoints for ingesting sources, spawning capsules, toggling CRM behaviors, ingesting models and administering the system.\nKey Endpoints\nEndpoint\nMethod\nDescription\n/digest\nPOST\nSubmit a digest request. The request includes sources (e.g. repo URL, API base URL), intent (integrate, analyze), and optional metadata. It triggers the Intake Service and returns a job ID.\n/capsule/spawn\nPOST\nSpawn a new Capsule environment. Returns Capsule identifiers and access tokens. Used when custom stacks need to be run manually or via the front-end.\n/crm/toggle\nPOST\nToggle the CRM Strangler Proxy mode for a specific endpoint (e.g. enable write-through for /contacts). Allows incremental migration from external CRM to internal implementation.\n/models/ingest\nPOST\nAdd a model to the local registry. Accepts a model identifier (e.g. Hugging Face repo) and optional metadata. The Model Serving service pulls the model and makes it available through the ModelSelector.\n/models/benchmark\nPOST\nRun evaluations on local or remote models. Returns latency, cost and accuracy metrics that feed into the ModelSelector's decision graph.\n/admin/*\nGET/POST\nAdministrative endpoints for tasks such as inspecting job statuses, viewing SBOMs, retrieving logs, enabling/disabling features (NATS, Supabase, vcluster) and rotating secrets. Protected via authentication and authorisation.\nAll endpoints accept and return JSON; error responses include descriptive messages and relevant codes. The Gateway uses request identifiers and attaches trace IDs to facilitate debugging and correlation across services.\nConnectors & Integrations\nark-os-noa interacts with the outside world via Adapters and Connectors. These modules encapsulate authentication, rate limiting, and protocol details, allowing the rest of the system to remain agnostic to third-party specifics.\nBuilt-in Connectors\n• GitHub Connector: Uses the GitHub API to search, clone and pull repositories. It supports scoping by organization or repository and can read commit logs and PR metadata.\n• CRM Connector: Provides read/write access to CRM systems (e.g. Salesforce, HubSpot). Initially operates in shadow mode (read-only) via the CRM Strangler Proxy; write-through can be toggled per endpoint. Handles pagination, rate limits and authentication.\n• Model Hub Connector: Interfaces with external model repositories (e.g. Hugging Face). Supports pulling models, downloading tokenizers and retrieving licences. Works in conjunction with the Model Serving service.\n• Other API Connectors: Additional connectors (e.g. for Slack, Notion, Jira) can be added by implementing the Adapter interface. Each connector is packaged as its own microservice or plugin to preserve modularity.\nInternal Connectors\n• Registry & Object Store: Adapters communicate with the private OCI registry and MinIO using signed URLs. They ensure that images and artefacts are pushed/pulled securely and that content addressing is respected.\n• Database & Vector Store: Adapters abstract database interactions. They provide typed functions to query or insert metadata, run logs and embeddings without exposing SQL directly to the application logic.\nFront-End (Admin Console)\nThe Admin Console is a web interface built with Next.js. Its primary function is to give administrators and power users visibility and control over the system. Major features include:\n• Jobs Dashboard: Displays active and past digest jobs, their statuses, progress bars and any errors. Users can drill down into individual jobs to view their profile.json, system_card.md, SBOMs and vulnerability reports.\n• Capacities & Capsules: Shows currently running Capsules, their resource usage and health status. Offers controls to spawn or destroy Capsules.\n• Artefacts Explorer: Lists generated artefacts (zip files, PDFs, embeddings, SBOMs). Allows downloading via signed URLs and cross-referencing to their origins.\n• SBOM & Security: Provides a dedicated section to review SBOMs, vulnerabilities, licences and risk scores. Policies can be configured here (e.g. accepted licence list, vulnerability severity thresholds).\n• Model Registry & Selector: Displays available models, their metadata, benchmarks and usage statistics. Administrators can add models to the ingestion queue or deprecate existing ones. The ModelSelector's decisions and rationales are visible for transparency.\n• CRM Controls: Allows toggling of CRM endpoint modes (shadow/write-through), viewing recent calls, and measuring divergence between external CRM data and internal state.\n• Settings & Feature Flags: Provides toggles for enabling/disabling optional services (NATS, Supabase, vcluster) and adjusting environment variables. Also offers secret rotation and certificate management.\nInteraction Patterns\n• External Clients: Use the Gateway API to submit work. They receive job IDs and can query progress or results. Authentication tokens limit access based on roles.\n• Internal Agents: Call endpoints via Adapters. For example, a CommandChiefAgent may call /digest to start digestion for a new source or /models/ingest to add an in-house model. Internal calls attach run IDs and context for traceability.\n• Front-End Users: Access the Admin Console to monitor and control the system. When they trigger actions (e.g. toggling a CRM endpoint), the console issues calls to the Gateway API on their behalf.\nBy exposing a clear API and a rich front-end, ark-os-noa ensures that humans and agents can seamlessly interact with the system, inspect its state and adapt its behaviour without compromising security or traceability. # Intelligence & Learning in ark-os-noa\nVision\nark-os-noa aspires to be more than an automation platform-it aims to embody agentic intelligence. Intelligence here means the ability to understand complex systems (codebases, data sets, SaaS integrations), reason about them, learn from past executions, anticipate future scenarios, and adapt models and workflows accordingly. Learning is achieved through a combination of semantic understanding (knowledge graphs and embeddings), model evaluation, feedback loops and simulation of alternative futures (\"branchwise foresight\").\nSemantic Understanding\nAt the heart of ark-os-noa's intelligence lies a semantic representation of the world:\n• Knowledge Graphs: Built by the Graph Extract and Digest services, these graphs link code symbols, data entities, API endpoints, configuration keys and other artefacts. They capture relationships (calls, imports, reads/writes, dependency edges) and annotate nodes with metadata (e.g. licence, language, risk). Knowledge graphs enable graph-based queries and reasoning-answering questions like \"Which services write to table X?\" or \"What code paths handle payment processing?\"\n• Embeddings & Vector DB: The Embeddings Service converts source code, documentation and natural-language descriptions into high-dimensional vectors. Stored in pgvector or Qdrant, these vectors power similarity search and clustering, enabling retrieval of semantically related items even if keywords differ.\nModel Evaluation & Evolution\nThe ModelSelectorAgent plays a central role in learning. By recording the performance (latency, cost, accuracy) and outcomes of each model used for a task, the system builds a knowledge base of model behaviours. Over time, the selector's heuristics can be tuned or even replaced by learned policies that maximise utility subject to constraints. Benchmark results and feedback loops allow the system to retire underperforming models and onboard new ones seamlessly.\nFeedback Loops & Trace Learning\nEvery execution produces a Trace-a record of inputs, actions, decisions, outputs and outcomes. These traces are stored in Postgres along with logs and metrics. Post-run analyses mine these traces to identify patterns:\n• Success patterns: Which workflows succeeded quickly with minimal retries? Which models performed best on certain task types?\n• Failure modes: Which tasks frequently hit policy violations or vulnerabilities? Which connectors are unreliable?\n• Cost hot-spots: Where is budget being spent? Are there cheaper alternatives?\nInsights from these analyses can feed back into NOA's planning and ModelSelector policies, closing the loop between execution and learning.\nMind Maps & Branchwise Foresight\nThe system leverages the knowledge graph and embeddings to construct mind maps-visual or conceptual maps of relationships between components, tasks and dependencies. These maps assist in reasoning about the impact of changes, identifying missing connections and planning new integrations.\nBranchwise foresight refers to simulating multiple potential futures or scenarios before committing resources. For example, before migrating a CRM function internally, NOA can instruct a MicroAgentStack to:\n1. Simulate Strategy A: Keep the external CRM; use the strangler proxy in shadow mode; measure divergence.\n2. Simulate Strategy B: Implement a minimal internal replacement for a specific endpoint; run synthetic load; compare latency and correctness.\n3. Simulate Strategy C: Replace the CRM entirely with internal modules and measure performance, cost and user impact.\nBy comparing the outcomes of these branches, NOA and the Board Agents can choose a course of action informed by data rather than intuition. This approach aligns with the idea of compound AI systems, where tasks are decomposed into specialised modules and their outputs orchestrated【438618440126565†L248-L292】.\nContinuous Learning & Improvement\nLearning in ark-os-noa is continuous:\n• Auto-patch loops: When tests fail, Graph Extract proposes diffs, Runner applies them, and Safety verifies the fixes. Successful patches can be proposed back to source repositories as pull requests.\n• Change intelligence: Scheduled self-digests detect changes in upstream sources; the system predicts breaking changes and generates migration guides.\n• Policy refinement: The Board and NOA adjust policies (licence lists, vulnerability thresholds, model selection heuristics) based on operational data and emerging requirements.\nBy combining semantic representations, model analytics, feedback loops and foresight simulations, ark-os-noa evolves beyond a static workflow runner into an adaptive system capable of strategic reasoning and self-improvement.\n1\n\n"
      },
      "docs/data_storage.md": {
        "language": "markdown",
        "code": "# Data & Storage — Securing the ark‑os‑noa Data Plane\n\n## Principle\n\nThe data layer of ark‑os‑noa is built around a core principle: **keep all storage within the trust boundary**.  All artefacts—images, datasets, logs, metadata, SBOMs—are retained internally, signed and versioned.  Only signed, approved deliverables are exported.  This ensures confidentiality, integrity and provenance across the platform.\n\n## Components\n\n1. **Private OCI Registry:** Hosts container images, Capsule definitions, build outputs and adapters.  Using a private registry prevents untrusted images from entering the environment and allows BuildKit to push/pull from a controlled backend.\n2. **MinIO (S3‑compatible object store):** Serves as the main artefact store.  It holds large files (zip archives, compiled PDFs), dataset fragments, SBOM documents, vulnerability reports and even model shards.  MinIO offers versioning, server‑side encryption (SSE) and lifecycle management.\n3. **Postgres:** Stores structured metadata: run logs, profiles (`profile.json`), system cards (`system_card.md`), call graphs (`kg.json`), job statuses, policy decisions and audit trails.  Postgres also stores vector embeddings via the `pgvector` extension.\n4. **Supabase:** A self‑hosted instance of Supabase augments Postgres with developer APIs, authentication and real‑time features.  It provides a convenient interface for front‑end applications and external tools until the platform fully internalises these capabilities.\n5. **Vector Store:** Embeddings generated by the Embeddings Service are stored in either `pgvector` (Postgres) or a dedicated Qdrant cluster.  pgvector is enabled by default for simplicity; Qdrant can be turned on via a feature flag to support larger vector workloads.\n\n## Policies & Best Practices\n\n* **Immutability:** Artefacts are stored content‑addressed using SHA‑256 digests.  Tags or names are pointers to immutable content; rewriting tags triggers new versions.  This prevents tampering and ensures reproducible builds.\n* **Lineage & Provenance:** Each deliverable (zip, PDF, image) links back to its inputs, tools, models and run ID.  Build provenance is stored as JSON attestation, capturing the environment, command, dependency versions and commit hashes.\n* **Retention:** Short‑lived runs (e.g. experimental digests) are kept for a limited period; long‑term artefacts (e.g. official releases) are retained indefinitely.  Policies can be configured per project or domain.\n* **Access Control:** The data plane uses least privilege.  Microservices receive temporary scoped tokens to access the object store or registry; access is audited.  Secrets (e.g. tokens, keys) are stored in a secrets manager (Vault) and mounted as files, never as environment variables.\n\n## Integration with Other Components\n\n- **Backend services:** Interact with the registry and MinIO via signed URLs or direct API calls.  BuildKit pushes images to the registry; the Registrar Service writes artefacts to MinIO and records metadata in Postgres.\n- **Digest Agent:** Reads and writes to MinIO and Postgres; uploads embeddings to the vector store.  It uses the registry to store intermediate build images.\n- **Model Selector and Model Servers:** Use Postgres (via pgvector or Qdrant) to store model metadata and evaluation results.  Models themselves may be stored as OCI artefacts or in MinIO shards.\n- **Front‑end:** Accesses Supabase for real‑time updates and uses signed URLs to fetch artefacts from MinIO.\n\n## One‑Liners & Conventions\n\n```bash\n# Create local directories mirroring services (for dev/testing)\nmkdir -p storage/{oci,minio,postgres,supabase,artifacts} && tree -L 2 storage || ls -R storage\n\n# Content‑address an artefact\ndigest=$(sha256sum output.zip | awk '{print $1}')\ncp output.zip storage/artifacts/${digest}.zip\n```\n\n## Why Internal Data Planes Matter\n\nKeeping storage internal reduces the attack surface and simplifies compliance.  Data never leaves the environment without explicit signing and approval.  When combined with provenance tracking, this approach ensures that every piece of data can be traced back to its origin and verified—critical for regulated environments and supply‑chain integrity.\n"
      },
      "docs/ark-os-noa_framework_flow.md": {
        "language": "markdown",
        "code": "# Ark-OS-NOA — Framework Flow Visuals\n\nThis page includes the exported image plus a Mermaid representation for in-repo rendering.\n\n![Framework Flow](ark-os-noa_framework_flow.png)\n\n## Mermaid Diagram\n```mermaid\nflowchart TD\n  subgraph SANDBOX / RESEARCH\n    D[Sources] --> I[Ingestor]\n    I --> S[Sandbox Runners (Ephemeral)]\n    S --> G[SBOM & Capability Graph]\n    S --> T[Test Benches]\n    S --> R[Risk & License Analyzer]\n  end\n  subgraph COORDINATOR (CONTROL PLANE)\n    G --> C[Capability Registry]\n    T --> SC[Scorecards]\n    R --> SC\n    C --> P[Promotion Controller]\n    SC --> P\n  end\n  subgraph TRIFECTA-COURT\n    EX[Executive: NOA Commander]\n    LE[Legislative: Board Policies]\n    JU[Judicial Engine]\n    P --> JU\n    JU --> P\n  end\n  subgraph DEPLOYED NOA APP\n    N[NOA ExecutiveCommanderChiefAgent] --> B[Executive/Board Agents]\n    B --> MS[ModelSelectorAgents]\n    MS --> MAS[MicroAgentStacks]\n  end\n  P -->|Canary| N\n  MAS -->|Telemetry| P\n```\n"
      },
      "docs/ark-os-noa_all-in-one_v2.pdf": {
        "language": "binary",
        "encoding": "base64",
        "code": "JVBERi0xLjMKJZOMi54gUmVwb3J0TGFiIEdlbmVyYXRlZCBQREYgZG9jdW1lbnQgaHR0cDovL3d3dy5yZXBvcnRsYWIuY29tCjEgMCBvYmoKPDwKL0YxIDIgMCBSIC9GMiAzIDAgUiAvRjMgNCAwIFIKPj4KZW5kb2JqCjIgMCBvYmoKPDwKL0Jhc2VGb250IC9IZWx2ZXRpY2EgL0VuY29kaW5nIC9XaW5BbnNpRW5jb2RpbmcgL05hbWUgL0YxIC9TdWJ0eXBlIC9UeXBlMSAvVHlwZSAvRm9udAo+PgplbmRvYmoKMyAwIG9iago8PAovQmFzZUZvbnQgL1phcGZEaW5nYmF0cyAvTmFtZSAvRjIgL1N1YnR5cGUgL1R5cGUxIC9UeXBlIC9Gb250Cj4+CmVuZG9iago0IDAgb2JqCjw8Ci9CYXNlRm9udCAvU3ltYm9sIC9OYW1lIC9GMyAvU3VidHlwZSAvVHlwZTEgL1R5cGUgL0ZvbnQKPj4KZW5kb2JqCjUgMCBvYmoKPDwKL0NvbnRlbnRzIDE2IDAgUiAvTWVkaWFCb3ggWyAwIDAgNjEyIDc5MiBdIC9QYXJlbnQgMTUgMCBSIC9SZXNvdXJjZXMgPDwKL0ZvbnQgMSAwIFIgL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0KPj4gL1JvdGF0ZSAwIC9UcmFucyA8PAoKPj4gCiAgL1R5cGUgL1BhZ2UKPj4KZW5kb2JqCjYgMCBvYmoKPDwKL0NvbnRlbnRzIDE3IDAgUiAvTWVkaWFCb3ggWyAwIDAgNjEyIDc5MiBdIC9QYXJlbnQgMTUgMCBSIC9SZXNvdXJjZXMgPDwKL0ZvbnQgMSAwIFIgL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0KPj4gL1JvdGF0ZSAwIC9UcmFucyA8PAoKPj4gCiAgL1R5cGUgL1BhZ2UKPj4KZW5kb2JqCjcgMCBvYmoKPDwKL0NvbnRlbnRzIDE4IDAgUiAvTWVkaWFCb3ggWyAwIDAgNjEyIDc5MiBdIC9QYXJlbnQgMTUgMCBSIC9SZXNvdXJjZXMgPDwKL0ZvbnQgMSAwIFIgL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0KPj4gL1JvdGF0ZSAwIC9UcmFucyA8PAoKPj4gCiAgL1R5cGUgL1BhZ2UKPj4KZW5kb2JqCjggMCBvYmoKPDwKL0NvbnRlbnRzIDE5IDAgUiAvTWVkaWFCb3ggWyAwIDAgNjEyIDc5MiBdIC9QYXJlbnQgMTUgMCBSIC9SZXNvdXJjZXMgPDwKL0ZvbnQgMSAwIFIgL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0KPj4gL1JvdGF0ZSAwIC9UcmFucyA8PAoKPj4gCiAgL1R5cGUgL1BhZ2UKPj4KZW5kb2JqCjkgMCBvYmoKPDwKL0NvbnRlbnRzIDIwIDAgUiAvTWVkaWFCb3ggWyAwIDAgNjEyIDc5MiBdIC9QYXJlbnQgMTUgMCBSIC9SZXNvdXJjZXMgPDwKL0ZvbnQgMSAwIFIgL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0KPj4gL1JvdGF0ZSAwIC9UcmFucyA8PAoKPj4gCiAgL1R5cGUgL1BhZ2UKPj4KZW5kb2JqCjEwIDAgb2JqCjw8Ci9Db250ZW50cyAyMSAwIFIgL01lZGlhQm94IFsgMCAwIDYxMiA3OTIgXSAvUGFyZW50IDE1IDAgUiAvUmVzb3VyY2VzIDw8Ci9Gb250IDEgMCBSIC9Qcm9jU2V0IFsgL1BERiAvVGV4dCAvSW1hZ2VCIC9JbWFnZUMgL0ltYWdlSSBdCj4+IC9Sb3RhdGUgMCAvVHJhbnMgPDwKCj4+IAogIC9UeXBlIC9QYWdlCj4+CmVuZG9iagoxMSAwIG9iago8PAovQ29udGVudHMgMjIgMCBSIC9NZWRpYUJveCBbIDAgMCA2MTIgNzkyIF0gL1BhcmVudCAxNSAwIFIgL1Jlc291cmNlcyA8PAovRm9udCAxIDAgUiAvUHJvY1NldCBbIC9QREYgL1RleHQgL0ltYWdlQiAvSW1hZ2VDIC9JbWFnZUkgXQo+PiAvUm90YXRlIDAgL1RyYW5zIDw8Cgo+PiAKICAvVHlwZSAvUGFnZQo+PgplbmRvYmoKMTIgMCBvYmoKPDwKL0NvbnRlbnRzIDIzIDAgUiAvTWVkaWFCb3ggWyAwIDAgNjEyIDc5MiBdIC9QYXJlbnQgMTUgMCBSIC9SZXNvdXJjZXMgPDwKL0ZvbnQgMSAwIFIgL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0KPj4gL1JvdGF0ZSAwIC9UcmFucyA8PAoKPj4gCiAgL1R5cGUgL1BhZ2UKPj4KZW5kb2JqCjEzIDAgb2JqCjw8Ci9QYWdlTW9kZSAvVXNlTm9uZSAvUGFnZXMgMTUgMCBSIC9UeXBlIC9DYXRhbG9nCj4+CmVuZG9iagoxNCAwIG9iago8PAovQXV0aG9yIChhbm9ueW1vdXMpIC9DcmVhdGlvbkRhdGUgKEQ6MjAyNTA4MjIyMDEyMjkrMDAnMDAnKSAvQ3JlYXRvciAoUmVwb3J0TGFiIFBERiBMaWJyYXJ5IC0gd3d3LnJlcG9ydGxhYi5jb20pIC9LZXl3b3JkcyAoKSAvTW9kRGF0ZSAoRDoyMDI1MDgyMjIwMTIyOSswMCcwMCcpIC9Qcm9kdWNlciAoUmVwb3J0TGFiIFBERiBMaWJyYXJ5IC0gd3d3LnJlcG9ydGxhYi5jb20pIAogIC9TdWJqZWN0ICh1bnNwZWNpZmllZCkgL1RpdGxlICh1bnRpdGxlZCkgL1RyYXBwZWQgL0ZhbHNlCj4+CmVuZG9iagoxNSAwIG9iago8PAovQ291bnQgOCAvS2lkcyBbIDUgMCBSIDYgMCBSIDcgMCBSIDggMCBSIDkgMCBSIDEwIDAgUiAxMSAwIFIgMTIgMCBSIF0gL1R5cGUgL1BhZ2VzCj4+CmVuZG9iagoxNiAwIG9iago8PAovRmlsdGVyIFsgL0FTQ0lJODVEZWNvZGUgL0ZsYXRlRGVjb2RlIF0gL0xlbmd0aCAyMDQ1Cj4+CnN0cmVhbQpHYXQ9LEQsMioyJkg6Tm4waUZoXT8iRl0/Iy4tcGRUWS5XbSVUIUshI0gxZz1mOjJRcFs5J2RxQyY3LjZgY19EZ10zQSxVIl9IQldiV1BMQDFMcDljTWEpWGlSP1tjbSdCbCJbVGcrJyEhVz5sPiJIczNRU1wzVDtodD47IyVvPCltSkZOcD1MQmZMXkBIU3BqWlVoSnVRIkZDZGc6RU5OUixOcCxxZk8yI1UwSGNgQC5Hc0VQJGFhLCs4cDljZ15hVmRuPUMrTlU0X1wsbjViQ09pXTU/VGI2VWtuO0FjTi5Yck5zZik3TkBTZWEtZ2ppMTIuOC1aMUtMcSdKW0BZV0VdIl0qSVMuY3RLb19IOGpQYFhWPF4pRmknSD0zTGRecTRgQmcqUDJySm05NGxhY0ZDWjBEVWoiX0FLJzg1UE8uUUtlRio3KVVmLlg9ZjVaaEQ6RmlOTEs5Rkc6MSIjYExkNzBeP19MLGtyPitQRTImRS0oMFdFYjJmSzVjSmZXbk1hQXVxMlttIyVDXkNaRT05V2QrQF5sWD9vWEEuNyoyRkBYdTsuVyk3Ry10UmghWjFhZjNrakhyL1YjWnJxbm8xVzpVXFVSXUAlQyphNSc+TVA5K1NLRzJ1MDAkIjQ3ZUQ0UF9sQHR1NHVnbjlSajJRIj1jQlUiUkYwPkljL1NzQ2oiMmlqQTxsLSJaRjo8PkpEPnIsZF1xOGtjN21Wa0JlP1lPJyszLjUoZSo5XlgmcnJyZzRiLSdwb3JedCRxMXQhcURVNUJML1BBNUBRYjxWM0ZGayo+IlpUWzdGIzxmZ3E7PGU1Qk0pdVlrLCk+S2I1QkcvZmFKajdcPGYvTjYnRUorczo/VmlzVjEkLlwlI2FXaCM9ajxPU1I5az85KmtPQWQtckxqY1ZlaDlcTj9EYHBdVi0+QFFyb3BUczE+Xz9PMGlQRERva21tdEphVjlXT05tYWo0bEslcFonXFpydENhdTYiQ09fKUAzNyMyalJJZUR1YGlsaXNZLDFgXFYyMEZgSVBAIUkoTzJoPD90cixYTmRaTW1MWD9pK1FiXDkiKCpSOmtfU2BXTlEuKSNFbEpoIj8xMElpKmJCQkBCaDs4TGY5bnBuYz40Xi1DQV1bZiMwT0szSEQwMS9nWXByIV5IbFhuUWFkayhrbU5wQE1sKzwzRjFmLHRrYTVdRHI+cDBMNSNIKTFzWkE+b2cnaDVEciVIQ2pLQV8rXzJUbFJpUF4hQVZSXiJYdDs9OWwhUjo6NFVuZzVEQWozWGgtK11jYV5VXW4xQTRuV1prR1xpX0g+KFBCNCtGQF9RXj91ajY7UUZMK0NHc2RmOzsoJClPNHEqW2NoYDdpbmJsOEhdUVlHUWMtK1YtRUcpXiZfbzpDYF9vQ2ApXzkuJ1U2WlNZQXFoXGRHZkNnWG5FSDVyTihDanBAZyJAYmhNO0o6TGZLXnVVTytNdCNhPVI0W29LJj8jWigjZSViZHFDQypYbFguRDE9RFlqZmNAI3UnVWVHJ2pLcTRMX2c1OHNAY0BjJD48YG1aaiUwa1BBI2gxUWRLcl1KMDlPTjlgclgoRUktNmZTa1tZcmRtPCVXLlhDU1VXPS0qIStfQ0htcE8oSkElVG4qQkQqVzFoJCg8KCtTQjJiMXFjLUdBJzZcMzguOHMyLHQ7aDhdKTlrQTlLPWJyVjRJK21pWktDUmclMic9ZzkqdUxgcG5WbUYvLjcwIl4wI1hoXFs8b1ZKczM8RihhWVpSczxbMykmJz0lZVJKTEMvNEhxO1BBQz0wZ28+amc+QkJ0L1lzbTNjYEgkYSRKNkE9ZW9lVDUzLjhPSEEzOycyRXNiRCotaTVYdWJJU0k0TWlXPWonaSpOLCZgPiYqTEhCRTcqSWdfYDc4aE5wXWBUVnUtcHVsISQtXTQqcislUVksUENadU5BRkIoLDApRzItTz1hIj4oZ0RmTEE4SThgJW4lLHVkPzM6Uz5uQTxMaFVlNypZVkxrX2hhbkVfZGNnaCprLEpgRnREU0RSVUg4VFdUWmBaIz8zXXVnL2AkX2dJVV8uV3FlSFoqbFFyOHFzJm9dQz9VcU1wMGckVjdWaFNYLEc2ZCE7blBDcGNRTjJjOiVIZj0xUE5uYFpWJS1pRFZzLVtgRzhgbi5YY2daWjBJcUIxWmlpQD84Oiw+I21AaSthVVglbjwpV2QsW1I6aWNcPmQnZlUhWVdaTlQjQWIxXy9QZ2NKKzFdNjEvb21AWFs8ZG1QZWZKRE1IXmpTcidBcHVFK2xSSDNFOmJZYCw7KjgkUGE2Pyg9Ii06Ui0rMlBZJWIwZyFuQSQ0cV8zNUlxUDRRWWkiWlJEXipSSWddLkdMbC9zb20vc1ZMLjcuQnJgWyhuaDQ+VkYndVE/XUFiLzopWzBKbmZZK1hjRiE8VkhyKD5MO2orWEdQV0RCKnA7KFxhLjEiZ1kqOlxOJD9uRVkkRGQuR2QyJEllWChuSlpFIllAYkNoX25GVWA1JS9oL09FOnEhIzdeTXQ3by9pR3I4NSNXU0xEISozVEZjJFk+akJlQmU1T3A5TXBfTVxEVzolS2FzajQ3ayVzZGNqQUFDLjEwdSFCbCw5ZmI2Y25rPVBbVUhFKGVvRS1ZcS5BLycsSy4+NkBmcFkrQGgiVklhPmd0ViJRLmxbOVxqUl5Dcjt0b2kxN2M4RTleXlQkQjA7bks1P1lxIUF+PmVuZHN0cmVhbQplbmRvYmoKMTcgMCBvYmoKPDwKL0ZpbHRlciBbIC9BU0NJSTg1RGVjb2RlIC9GbGF0ZURlY29kZSBdIC9MZW5ndGggMjAyMAo+PgpzdHJlYW0KR2F0JSNJbyMpYSZILilDYE1iO1g4c0dNPCMwUGFuL0M5KyxRNkszbF0oUThFaVxdTD1FUm87Olx1WWV0MmcxQjtYPWZXOUxyT0glMmtHPFRSRmAzMm5aUUxmXWJvXEYnViZTPj4mQlcyZC07WnFANjAiYGwrOkU9QyQrLzdCM1JBXVk3IWprQSFrODRKLF5RQlA7TyI5TS5yXkIlaUFvOFZcaTRmVUVGN1ZvRDdTPGo4QGc4VkkqX0dyPTtaKENOLGw7VDQ5P1tfWWl1JGMqZ2NkMXIuUnVkWTdYYFZIRjFEYE1LJFRrQjZBWVFsZVNnbk1hLnNmdS9SVmZpJT9ZM1FCSjouaCZjUWw+XnU5S1lKW148cF0vSEopLDw5ZUk7STo+Y11GS290JXArRXRvTCU4U0BrSik3Z1I7XUJzdS1cbjNqIVoiPiZCWlhWaXQmL3QuLjxhXiQ8RF9aLVRgJnFXY11NKCNlRmovKDwhaHNpOCg/LXI+J1Q0aWVgRmg7Yj91JTZmMVpeYCYwaWBAXkIpYUkwPWRtTCRyYyQuUWZAJTUlKStMRyhUUWE7UFpOdSk0M1RsNUMvQVhddHA7Pm1PJ2sjJ05GOjNSLGZVMk9tT3UpXl5Jb0NvPTw1Xl8uRlFdI2YvMExOTm11ITghOEQsYyIkO1tqLGA0PWVTLWYjRzgpOD5hbHEpaWhrbDBZdF5WcVdrQj9ocC9hYz9bVUU1dD9KUy0uakQ/QlFARlcwLWo6Oy5kJSQ9Yjo2InFtMlUmW28+SCV1NVhKcHBLP2FWJCcwJ0FkQUwoYUJMb0Q/YkhAZ2MsRldUQSRvLlphWGZUNl9hVjtpO1MiPFRyT1FDQCoxKiNHS1QqbXJMNW02L0QzJzpdPV1bLEwuckh0TDhkNGZNIm8qcSU9bk5sVS9vcjtodFRBQUtKNkYnU0pvVlhRSTwpJFFZMC5dZmshZ2IxMm8uQTYoYj9fRispYWElXj9tOGVwJ0VITGlDOkxtMCxjX1YqKTFsRiRrKCNCM0xgLHIqT21BTzVrLlRmMjYhPkJRQlU8IVE4SyVKTSowSyVKM2VzR01tYCo+OmlqYlA1OSRhKlY+Lk9CbFo4WlQpRkRcbmAxPCgwL0EoWHRAPmFOcitRa1czbyU1PF5KLThFWlY9WCcobko/JnJpQWEoS1RwI1V0VEUjNWlkZmxOMGYzMXVdc2QwXEcsbTg3IWFtK1JyJScwTjlxdS82Uk50Lko3UGZcOGNBMVxAby4pP1RNITA+RzI/ISp0XnBURFtWS0k/VydtNFhQTTI5cUBYVHJVbVAyP0duTyRtLzdiNHNeM25wc0FWNjZUXjFLUW9ITCllYjhuYStRW2ZEJl5qTzhqXzpzVls8LGNVZ05mTk5JL21DXzdYSG0sYUkrYGRCPTQqX2RfRjctMUs/bjkzKC5eO0RUO0ZyWzoyYTRkOVJvL2tPbGY+L1YwRFFGK1BPYGpBbGhYciVAYyp0ciQiZTZxITQ/QywlQyNtME4hdCRXUEBnclBwITE5P2VUOzdfXEdMVmkvUCxmSD5pPC1AW1w7aHA1MS09MnAwa0ZibiVOS1FIRF08WypQVDJNMz5wayhYNTNcTkA7PV1BQy1WTzQ/KmJNaUopVkw0XkQwPDpMMCIybl5IaTRyakFdZFcrUGwjdG5cUk5qX0YjRVIuYWRycVhdRnEwWVouUXQ6R2JUaz1VZ0Qna0knbDxoOVBvT083RiQyWmA6JWltQ1twKilORjtGU1NrLmptTzVMaUlGWm1dRFIjTXE/S1VZSyZOa2U5a3UkVi1APCJuZmxKa01SN1wkWS1ON2EjUmo2J18sckcpTixIOWU5bE9jZmpTNjhsOkdGb0h0Qk1VckNGLW1EXygxOFMqWWA3TEFKV0NPUS8wVTlKaTNRJyxdQmo3ND1IaTxsM1wiXj5BODJjZCI4NCJHRCRvaFFrKzcicSdkU2g5JilYNTZcMVxAMipqW1tRNyJTTmNzQEpQJWFtRTwsMkVjYF4qJEBFMmA8K0s2IidrVmlPMydLYHJyNFlaSDtgcikhbENoRWReajs4W0JzXSMqJFVNKDpmVSNOWSlJaDNSQFUjR0dYaDcjbztlLkMlaUNVcFNLckFHPSRnKVZkUyw2KkVQb1BDM1hBRk9YOURXTCQhXmswNVYjYmE4Ti8wQWRFWEBHcSNfRGdgbzRgNW9tPlAxZzRkZEJrKiVHazUzWXUtTEdXanU6SEZuaSgiYDlWMFc2MzdgNi9gJ0tbaiJiOls6JTFLZzxiTFVlaihHYCddWTBtaHM/I2ZHIUlQZmx0SVgrJyM0NDFAOENvX1Y4b3JCZl1BYCsuaSI8MDVFQCc+NT4+VT1XT2VrcCdHZmdsJyVAal9DMXJTLilqXjhIO11fJ2JrJChWNDkxdE5KTCFZOzBcay5NTkA1OCVaImJGQSErcWdgLi1EQWRIXl1XcWdNMDtaa1UzRTc5XzQiTTUpdEsjU0VlW0dRI3RcXkxQbXBCREVkXDIuVVc/N2IxJSFESEImRShXbDo4LG4pI0tlUSNMcVUkUFA1MkhyLyFwZGxrWTFrWVhUakM0QCJtTEMsLGQ9cjVEUjcpYURiQk1jPUMkOkZjUlYwb3QiRW5eIy9qUClVWEdSbXQ+bDNuNyk6Sk0mM20rLlZUOklJLkVUcVtaRSk+UU9+PmVuZHN0cmVhbQplbmRvYmoKMTggMCBvYmoKPDwKL0ZpbHRlciBbIC9BU0NJSTg1RGVjb2RlIC9GbGF0ZURlY29kZSBdIC9MZW5ndGggMTk0OQo+PgpzdHJlYW0KR2F0JSNELDhuVyZIOk5uMGtzSyFVaUBEOjAyUVtNLjFpLWEiSlJxUmwvV0IuZlVJKylIZTVhPTo8NmAwSWYlQ0QlWVFxMSgqT2dSWFFTXTVCOmJNTmQpJGtQcnUzM2BWYzBmUSosby9NMCM2XyFtKGk2M2NEUFQoa0g0WztJNilMQyI1T0csWz8iYWJeanVaZUY8TW9gN1VuazVWbS43N1tcYVxDMWFKTmk3Y09VUVAzUF89Il90KHA5Z0VdXVdecGdSS10xSjZfcDxzazJCYFpAKC9wJFdkXSpnTVA5ajRhMGA7NClgWERlJT9MRTs7W0FHK2spKDFTRUhxcipTMTFtJFtKaE5LYjVSVSxaI1VnLUg8YTBATTc1Z0gzSClHamNBR2tqOWdqN09aNlNSYUpfXGI2RSo7a0dtTi8obDteaT5mXjJwXSJaUlF1Kic/Ykw3VFloQ1QrKDA5Pi9QRC87ZlNNRiRbSGNULy8mRi9YU1VCK2BCLFB1OjZEU2VlWFc6VjhQYSt1P1I6YGBNSz9RXk8zQFpFJmdbblJPIXJIWGwxQyMoXWstLEJxXkw0ak9ELWBcRVpbOUwxW3MnV2I+UCVza0YmcVBrRGIkM1UuS0xsJ1pDNHByWm5RdCxYMic+ZiciVVZPa25VRD0haWducWQmXW9WamI0XlFrYiEwXlopK2hyP2BDdDJZOU4mTkIzUCEmdS0+Qj8+MkpbNktGOl48PF8uJFU4XksnYzc2Z3VdSDJnLVBtQiMyYj5JQHJsbFFTTEc9YTxiPyRKPzpIL21cZT8/QE06MUUqdDciOmo7QSQ6ZyJnVi81QU9XNVQ2OFk3bXJtSUktZFIvLD9tLyouMmFYWjRCNSkwUVhmLXU5WSFKSmVfWiohalMhJCtjSkNUYycoWWdIJFpPYXNxP250KCdKT0sqZU9yMkFXKUciU2tkJkNEWFguJHU9YSxlRnJwbDZiQ0BhX18/KVJrSW5oK21FTSg9Llo+LGBPNk1GT2wrSmBYckxKVShFPygiclYmQzJKL205W1pNL0tKYyYwXyQ4My5JUVJZblhpYmxBLFpNPFIyMWBRcjUmVj9obj1mUGxzMklWXUUiLjlGL0hmcyI+QitJX3A8MlZKMHBnVHI9KixYOzhpanVOS1Q5UiVfKl9NXFNOOjJCaGpkSD5lL2dYKWE1KV1fWjQpVT8zJy5RamlZc1guWUwzSzJfNGpXcW1gWmg2XU5MUlFNVEV1az8oKTJxZ2kkJmNHLXNQLUxMaGUkNTQuaE9fNnUsYiYmWy5SViVuOj1sQDJvSEk0UjtJZGJaJVpMTzs+aCRfc1xENUlCKUQnXGppN05KZmcmK1UoOFpdTTVgKC1HWEwuPmRMKSo5MnRwaDlMWFY0JGk9dVFLLV11ZGc7X0Q3Oz5IYXUnVUxDYVI5NTIwVy8yNTIqIm5LMS1Zbmg+RmkjJVRAS1UxUWQoOWRpT2shZDY5JlpAaSg7Nm8mcWdwZ0V0Y0sjTihVP1BiVm1oVjBcKGhYMFBQNjBiRzhbPSRtYXM/RVhqVTAkU20mOnReWnIzM01kLVdSaUN0J2IsLitePSpRSyw1ZlRRU0ROTF0pUlNLITVyMCReNnJvazxjNmFaM1NROlZiZWdLXXBIXEctQl9SLmxzN0ApZyUvSiVCVDcsQE8uSz1rbklKQCtSVFBQLylYOEtaLSdqVz03X1szTzgjamo2WT8wL0ZCTjdEIjFOdVl0bl9rVDcqOydHQVYyWC9rTGRTTTNCVl8raCVcJEI5XkdqNSlcPVMjTjxiQlBNN0tcV2tBTkxWXkxnRFYvVlBpXV9aPGFVP3MoUCUjTzokaCpQR1ltWmpSTVsiT15ePWlYNUw2KitWRzYqTGxEaTghTGtsJl9uMCQ4UTVEak9kQi1MMV5SWT43czEtT0RhNTY6cjBwOmYscExcb2NqNCltOy1UL1xVMkc7OlFQPkFtN3FlZUVFIUsrOTE/UWNDZlFVOz5CUCVuY2MrQ0hzbDNVUlokNUA3XVc6T00lNSRaMz02aF1LMGkkQUVESF5QcHFBY1M/clNwJE4zPElLLD1vVF9hLHQvVVUmP08tJ1JxcmY3QnRFVTRrRmdEXyxPYzE2IWtkYiQ1V2g3SE8kWGRtM2Y8bjRcUWBiZEgwQ1onRWtTTDlWQlU4JHFCbUxJQW4+cU5tTTBsZzczJjFpaitEWTxUYTVIYjk9cnNpNEVmSzgzKUlXZW9eVFVdXWdmZkAqZDdwOCkrTyszN0BJdC9XKWRsSF4rSnQsVF5JMitjNURYMDtDYkFNYiokZyRdPDQ3RSpqak5IcjBra2EqL0xLKEI0MCR1aytaTU8+aiQydFxrTXQlcTg2PkdtK10lVSpbQjtqYXVZRnBMLXIlJlNRZWRgSVxLYFxZUT46LyQ0ZHRJSmErXidMbUpzRjI7W09EVm9AODtJRWwkXURxOkhKXCRMZFtONiNsTnMwVFNKK2QjLCtCNDY/JUZcRT1VVmBNW15EQE9GUykiP25FQEdMWy5OSk0jIm1DQHFpRSsnPnRnZm9scCdGX1pKPW42Qj1IOm8xNihaQE5GQ09eWFRQaiRpfj5lbmRzdHJlYW0KZW5kb2JqCjE5IDAgb2JqCjw8Ci9GaWx0ZXIgWyAvQVNDSUk4NURlY29kZSAvRmxhdGVEZWNvZGUgXSAvTGVuZ3RoIDE1NjkKPj4Kc3RyZWFtCkdhc2JbRCw5MU8mOmhPYVk4RytASj8hPVAoSjUocFViNjQ9LGhQT1VnJjVrTW1DSi8vcSEtTG9tQmdpbGE1OGpKJGA+O0U2OixCSVNpPXRYMVxJRSVJcFZxOGMyXiUmXz5XX09rSk1CTz9KI1dvSDM5TV8mIkU9bG8iRyhvZXVLTipMTiFrN0BARyQraiNCT19yPEszajJlOVMqUGhGc08jPHQ4JE0uLyE4MWRtKyNHN1J1ODtqTTM2XSgiaFhfTDhybydISyZIbE1JRVQ6MXFFWjwxRD8zIz1yWi0qQC5JWj1EOG0uX0RtcydIM1RmaSJBTS0jQExATWY5PCYtVjBPbDs4QFkkMlo1L101IiRVWidhXGFEPVkqZlRzJ2paPWI9UExfXi4/Pk9HaTdTOkMqIyMoLyNNVjwzQ2RcUGU4MTtcXjxKciNmMilORG90SV1MaEZXQDZnP15NTDU9KHFgdEI9Zl1mQWEmU2lTa11GTz9HMXJiMC5bXjkkSixbW1IpUXRFX1MyXFVyckVCMlgpV3VdYGYpaWshMHFrX2JzNykncDwqaSsoUGlOZ2ZpWWgvNVZtMWUrLGJzMlxkX0RJZi06Ti1LT1BFXCprUDJMPVMyW09valQ3KWtFSCVtKjErMCclazhFRCFVLEVBNkNZMDpOUTdyQGM5PktcWW1rc0Z1JXBtK2pQV0JsIVYiLnFwI1pKKkBucCdwWlA7QXJeQiQkNjIlUCo7VFNNPkE8Iyw7T1pJLT5nPU01J1dRUmZebUJIMmh1ck0zbU5qQiZFcyJgOGlLYWMrdDpwaSo9LjhcI10lPzBSOkFoV1UxNzxkJlxjKEc9ZUQjZE9gbilWM25SbUcnY1xQU0FKTj4zTlQmXGxLRzFLUik7YzlvbTgrc0xLL2EhRTs8JFttKD85T2IsMnUqOHVUVCY2TkNAUjlaQ0hjW09dPjZnai90ZFBaIlpSPE0qNzxgXk40Q0ApZ01XN1llMjklNWQ/biI8OyphZi10UmRvbUkwRSdIUjInRz1LOVw0OD0nTWxhVGdRXGJRN0k4aCUkQ11dZVBmQlVtNFdvN08nRXA4bVFOTnVLYUA5MDU5KERjNS47aXQndU1HJCY4KiFdcllUSW84Zk05TylbMSQ3IydaMGdzKkpTMjNvRUJIOm9XcSpPRCNjOlBoXWJVU242Tj5nVVZxTToqO2Z1KXRaPnRwSFlnNCFtTC8zMl5RK0xKK2MrXz5VSkkjSEFbLl09T15wbHFfMWczTjEnJ1BJMmtQdEkuampvKGk+ZzxMIyFTcmh1JTB1T3BKUUkzc3InJUVFdVNCSjxNPkkyO3RkLDEsUTV1JDFrUWxeKDtcSnMiTS9JWlY5Pkg1anQsOWpzbFg8XitPMTk+RjdFNmI6WDtOOV1sQWJWUUZASkgkVDRWSiEiNWpzYCNqcChLS2lOJ00vRC5qLSMrL3JBNWhMKiFSaGkuJGwtS0Y+TU1RV2FbP29eWGxWPEtDU1lTQik/TC4ibU9ZTUZpdVcra3QhLUY9ZF5ic0dWb1tsJzdTZHMuZTRpLmxxKi1cSy9bbFQvVTVhW01VLVZuKi1BcTxFK3VSMitEZWZfOWZETExAZEJuMUBQUWVgTF47bEk/O2wwMWA4TkM6NmcnIVtsI1RwdUNdLVY6dVpIXDI9bmhnMHVsI11VRmNZOlFhWk9wMmttJGouUSw7MlVzNGdsMS9tXWZEJjRqOUgqMUFGQjBxLlwvW0VFZEFuRls5NGNDPTJVLGJaJFplQWgiOikiLV06NzA0LmdqU1xbcTZZc242Sms7cCIlbiZsNUhtbWRpaWMuMVdKUzQmcU4sWUwoL19OXFtFXyEramUzMS4ldVw9PTtPUHQ5MVZaIWlydW8vZ1ZbQ2ZTT3J1RTJTNi1CQl9KVnVbc2xJWicyKl8hXEd0UEQrVXNvKmZlSDA0TiYvQVE5VWxramkkdDgrWGgmSEBnUUhoVjwqIl08WzJcL1NOPTVAYylkWSI5ISchZ11XRUEwSSZUJ0lGLTErMTokL1NGKzYtPE9AV1JUMVNXNC1EJVgpWERZbitTY0U/JWlnaCFALDpPYjV+PmVuZHN0cmVhbQplbmRvYmoKMjAgMCBvYmoKPDwKL0ZpbHRlciBbIC9BU0NJSTg1RGVjb2RlIC9GbGF0ZURlY29kZSBdIC9MZW5ndGggMTM3MAo+PgpzdHJlYW0KR2F0JWJEL1wtISY6aE9pPSxgPDZlOFRTak4/UClnZV43Mz44LSxJQzk2RFZYQThSQ3QoPkowSFkrYksuclR1TyUjLDUkak0zKmclYFxUXHBjXHIwKXFPJEJSKEJdJiheX2lNSj4yVE5rZzJDaElEVyU7XUMzU01jY2BQKmE9WGUlPUUrc0kxTTtfMShFTFI3TmhfYztnaS1ZUiduSDJZOy9rJ25yMWQ6TkwoTWU6aVxuUkdYITA8MiVXRTxYVzZdQGFDcTlFIUhPcTIqK0dRYlFOaTlxWWxibmxMVCQmZGE8KkVfYzstaSNKQ1FlZDtBSERzWVBuJlFTZ1N1RFJDKy5daWc7IUJfUWVrPV5ZTyQrKXEvRmMjNSFEZUMuXy5McyVLKGsiXC8jLiVgU3Q1cXE6cihhNE9jJU9QLSlXNzorcGloQStRSGM2IUtSZTJLbyh0Km9uSF1KY3IiISk0NlNFcmw9NmhcWVd1OVonWiNQUCNhKk4iJm5qNWkyNDpBXFlDMSFOQ0Jlb1csUVY2bC8iQ2QsKWptNiRZXk8oVCxAOjQvIiRNQSw3TyI1aSVvM3JoUSpxSV07QTZVaCwtZDcwZW5cdURHTGwlaj4jZCQ7SEcsOUpeITZCSzNPSXJjMF02dU5PJzA9OChmTlYrcmU6SW1XREo1cG9RSSpfOU5XYzNVI2MtRzxpOkFyWFdmXl5LaGlDP1IsIWJNUi5bI2EjLiY9TGNATU5pa0FFLS1hcE80TFdBJyYsUkVAPU1BR1VyJCFicVFpUy9GOVtpdVVsNkhGaCNRQ2pyKS4pdC5bZklXblpZPU5Ya2lFT0MncnMzZyFQZjdKOipZNm1gYSlETWIyTkkyPGYjcE9xTjhRRUBNIjZrTydrPlxwRSIlTU5SRF1eIT1PYnQqV10mZHI3P0hBI1oqXGxQaVNyK28tZVU3SWltIyQuZmlsTyomKSMvYlZeREJgZyxQQk9wLFAyWlkxNWE2YS5ZWDlLVWtJIjhLUDw3QSVJWXVfNEo8RD1JUDo6UjtqOVtRRGVHLVVCclpETyQ/akddNSFhL1pOPzRab0tCbF04WG9BTFJgSzcyXU9lbmpnOzohSUdFJ1BIbVM8V1pGZjYlXi0+OytyTWxYWzAscDA8VFEpX0Y+ZGw6KEZtUGRyRzRgW2smW01Fa2dZQWFfK2dBY1o4KGpdSl10OlZmcSUrQj9Fa2Rdb2clVVkuWE41JCNZPWtNMms+SUtrZ0Jva2RdTjRARkQ2SmJkOWlmQG8kb2opIUQ+a0FJbmNDM2p1J2dcVFpLWVE7TTgpKlVga3JKMCJyMmExLkdeXSN1TjY5VkFcVCtXMGZIOXFSN0IoSklpQ0w2REZFI2tbXjlFZTRWSVAnUDkwPWpbclRfKCE3KkNoTT4ubTBSOD8nZkxrIjkiNk46IUMxI2hKbkVlSDhfPyk3YC5HNEFmaSUrMiMvdS8rM2VFbFBlbys5ZWthPks9bEhKIjdpYEw8JzMpcTlVYC1jLTpRM1d1TSRBVVNYSSdlQVklYVhqT3EyV0tvLFhcPm8zIlxKTzteTUw9Yjk8WkkxN3FNW2pXY08xYksuNSIiYyhjaVFgKDNSNCtxcyM1PlRLTWhxQCxdUiNtMidoUjY6P19GRGheWSx1QzMtaEhGPUtYdVEmS0JzTj9QTmAoXWNKJiRTckJPMFxnR1pEbjFzV0kldCUmL10iP0A8JHM0USJPTDE9YWlbYHI9ayxAWHMpUiVmKCsoWzltPHVYXEVGZCcyNDVwWSNNcnRgRiQuVj9AR2Y2VWRiLVNPMD9qI10wM3FAQ11gLy1sfj5lbmRzdHJlYW0KZW5kb2JqCjIxIDAgb2JqCjw8Ci9GaWx0ZXIgWyAvQVNDSUk4NURlY29kZSAvRmxhdGVEZWNvZGUgXSAvTGVuZ3RoIDE0OTcKPj4Kc3RyZWFtCkdhc2FvRCw5MU8mSDlEWUBeTExfV2hzWF1vRUM9V2w7R2JLOypfSz4rImpKLzlkWnVcJzBCaGdqY0s5LTJlZ1xWZlEwPWotdW07UkdUUDBuMUc2JnVFRUUxWCddQWomUk5pVlImI00oa0lgJHMqMi1gaGlYT2dbV0ZgNG5XPFdGLV5ITDNtaTtgRmknSEAhYHAxRmcpUixXVVZEaF87MjJPMWovSWxuP2FHMmVXQy1iNyNrRkthQihDKVJzMyllZ0gzPz5oPzBpcGJnLyksPE1MXz0qUlpuLyY2M1QiUT07S15jQGBxUTRuUnEkI1g4R0o5KionIVQuaE02IU40IzZdU1tuQjlqZmU5I2EhMEdERWpDQ21KSS4rKEVJYmAqQS5lYlhGP2pTUkszVlMiI3NLWDY4bkJDSjFTXVdgUEFPNWNzYDZiRCImUjI3bWs7XTdsYjBdcyheYWVtLmJTUz0vQFIiJDgic1BVJSUzcXRyPFc+KF4+VSxTUyxDIWEsWWQhM11uaWZOcShLbzE0SWglNCMwdDpqSVgyYm1tOlIiZz4sKyghZlE+MmdMaykwc0giRXFrKWZSRiZFM0xYNSw0SDY3SEEtTFlzU0MrXE1mKFBZIUtkJVpYP1o6dTFCJjchcUNFVmNVbGQhO0AyKj1zQjJLO1FjNmBnOmphaDdZOVNjX0g1QFQyLVRYXitARyFmLDcjcEZwVElDKkFlO2RlY3BTTyooSykxXWhqUC0wUmooV0BKOmNCaWgxPzxvXiYpQGIqPWVnIi5TQ1RtIzBwInNpL3JwZzUzaj5ZXVApcTNnQyZVKG5LZ0kqIUJDVUBkZClZbjUuJXE+cWVLWy4ySnUqZGojQydZXkwpXzdFLFlmamkjJkRxZHE+UD4wKUdJcW1BMFBzMHRPQyZqa1UlOi9BQ0YoUjEqTnIoYF85QkhnQSRWbmk4LTFWJEFQIz8pMjVcLFo+OlslPFdbKjAiSWpqVnE3I0FSYU4vRy83SmdBOkglNT4yX1Q8QGhNbiFoLT1iKzJBVkNEcEBKQUxLMlRbRWQ4XWhZUmEpaFw1T10ybUxlOzdsQitVby5uJytuZEFWPipLQ0BgVU4oXEEyOzhOOXBQYzhfTzFFYm47KDwiLGY5USFgbiFYO1MyZyQ4W1habC1ePGgtVFRTWT9BI1BKQVJbLEI6PXFoXDo2NWw1Ii8vOWYkKi4oI1ApVCsmIyk9QiIyXlhFJEhyaTRjLkI+Im9LY1pRMls3WTIkPDVOaDlyZCJdcWohO1VBVkloZGdGRCNlJm1uc0Y7Oz0vYkRKRVVkUS9wUU42KGxAMy9JYC9zQUtjWlpNLGopQ0hgPkJLX08+OiJwJGUqQi8yaDI8OmM9NkpzTypXUGA1VVs8RSNDYFZvUDhmZzJxSERiZmZGLEdkXEw1MEdEW0ohKF5KKT1JMiQjLid0VW0lTl1vWjxWQkpgLzdEP0U6XHIoU3M3MjpkdV5eUF9pWjE2NU9YbDFfLz9RaG9iO2tqLjV0O1RbXiRscipBS1lVbVdHdU9oQyUhKUk9YFQrJlZCKW8pIl51S2VYbXBKZEEoYCRoPFIoTE1LPl9VSzVOQFtabFEpbWFeIWMjKW5IKT9FOGI5YW9vbUMtJ3Avc0knaicnaE03OV1UKEc3M0NwdCRaO1hBQ0NNLkw2NGRwNnA3K2RRQSlPXSRUZVgsXEZ1LigqOTkoKitlbFBxbTUpYE49a3VVOz5jTFphalBFWmgzVlhTIl1QOmc3TkklaGREN3A6Mi9VaVI5RTgkZVhjZUNRVUVBb1ZmM2w7Q1JTSHIwbWgtJEhALD1wKWdVMWhccW9Lbjk6OXUyZjdUUmM9OTM2W0daKWFcPGo3U1VtOW9tO1RoMT9rRk5tYSVXLDxYXTJ0ayh1czgyZTEqXFlBSydiZVglcj5RJ3RFOkdRTkU+OGhHJ3QoOC9VSXA2SGhZQUsyM1dcbkBBTjhIMyFxPjs5WSQkT0p+PmVuZHN0cmVhbQplbmRvYmoKMjIgMCBvYmoKPDwKL0ZpbHRlciBbIC9BU0NJSTg1RGVjb2RlIC9GbGF0ZURlY29kZSBdIC9MZW5ndGggMTkyNQo+PgpzdHJlYW0KR2F0PStELDkxXSZIOk5uMG5OPT0tbWlrLUo7Xj81IlJiSWNKazFvI2VQcyk9NGdxaSlHQ0ApPWRlJ15CXXNFLm9VOGs+cTcpRmVvbz8/VmJjYi1hcSpWc21Mcyc+YkczSls8JihWMmJzI0xJVVM/J3NOY3AmKUdlSU9EbmZIYiVsXyE8dDBIb004bmU1UlpOS0csO1xaTnE0SyM4S2xHOmtlRGdJKFxcSk9FSTdjWGhkTSEvMComW28kKl5iWTBhYkcibi91Ni9EOzNPYFlScCt0XG8qUSFxPUVlJzI4Y2FxXjtiYEFfW0VXO0c6WkkmTWhkJ0EoJUUnSEZsM0AjTCdQcFlIOjJya3BDKEguOyFbX3UjXComJyhvQ0JEbTBPVDw7aWtPNj5qcS5CRlFgLEgmKC5ZIlhMZ1FPOF0kYVVNT1hxWT5TcEVBOWBybWFcOlo3NTZUQCE0MGknY19DXXBgUyEqLCdIMGVZbExKMlZAakJKMzxzaSFnOitnUG4/XFZyJmYpaytTSTsnXE1lbnFbR2FjQVshMlFJU0hfImVjJWE7JGY8XGVUYVAtKl8zLVdFPyMpPlhtP007XEUzVkJROS0xcjxxQUArWy1MLl4uTUBGXWhpQmJSI19VSVBhVWpZPVFSJ2ZZQS5VZlQ6Z3BoZF1Jak9wQVUsTnBUOkw1RDkkYlQjJk5VUzYoX1IoYWcqbk9ZUyw/UVxcNzIzJGw7Jy8qSEtvSz5oTSxYcSkpJTZrX29ddWM6UUhZKm5uaDtnO04uaCkrJCcnT2hNIT5rb24tITE7S2VHQVEnLG9SMUhMIk5DRzdDJk5nYGtWUkBnWHU7UkJbU1UhX006NlBLJDk9Vy9OV01GWF5DR1gtYWI9aEEzZzFLMVNaR1IqU1l0LldMJ21tXU9CM15RPWsxJSFPSDBVUjVdM09lPkUhcVNMMERbUiVoZ2wmKmlRKFwpLVM1amBgPGxzQ0QmVDVYck1SPzdlMydgKHVocFsjOF1KJzo6MCMkKz82WmteJEMnRS9PLSdqQTUqLjNDLlRDcHNZbChgRGZbbzZSWW9iRDUyQGBOZTJYMSJRayNGJi5SViREKClhP2psI2w9YVBUVilvNzkuIk5MNCFRXWVfVSQnXnM+TF9gI1tsJlJuVkJ1IS10L1ghQnJURUZyLFhgUWZHIjU2WzlbOk06UVhkaE1KMmNDIk4wLTknV3FbY1U5VStNMC5JSCU5LzhOWDswL2RlKj9qcGxhJyErbl1gIlVRZCo4QyhPKz85ZnIrPmNkPGdPcl42bztEajAqQ2MuT1MucThMMS9RNlk5WEBPdU81LExPNjsvXV5KKTwtLWgzTHRdSEs3SGlpWWdmNlIvNzNfKDhgQ2tYOXNdNV5Hc1tMSmM7NTdrUFxrOFQyQkJFcjc3PysiOWhRPVFSKj05QG9Xc3FVJFdlNCxJQ18yKyRmV2tEZ24lMjtSdVUrXG5WV0gjXytCOT86OVVDMl9KSTEsOVInUS8hNmhjMj0zI0EqLCtIZDJaTyg0Z1hWODdiPlc8MjVrYTFcYls0XXJpMmBzMjJYVzQ5PmZJMyNTVjUwcVc5JCpTcUQmYiRHJ1pDOi9XZyxGdUw7JGtsR1p0TjUzV2s7ayhiR3RIPjlkLyJgQmgxX3BUdGhDO043KHRsVzlBbS4lcUoxPilTJEJbND9UOkRFNFRUX1o/Ol4vNzdBIUVuVkdfZ1FnImohLyRCN1o8WDgiJ1tMI1VPZT1ETzpwRGlcWnVYcUtVcD5PUC4nRDFAJWFfKlNBWFdSKVspYk9zcTRKWVVDblc2Qj5oKUs5KmRGJz0vT0NrOSVLUTNIUjo1dG9XVkBfLVVeMjNJaGpKaC8yOVlOPydgS0U9UFknJ1I4ZW5hUmRCX1VYZC5xL2FpJWlGZi1DL10uKjYhQEFJMC5XJTZlYTdOTllOXExyOV83NkJJOXBLRyNHQTJtbzo/bTlsRVYqQmM1KlUsKktRUmcwKG1vLHQ9YiJESFYiTWc8I1ZUclhVRjVaXmtSa2Y5QjopQWk6c0NbYDoxVFVtPTg2O1ReRlwmNzk4cFMjMzU8cF9eNmotZD9mLE9DYSFPS0FgWj9GRCshZE87aDAqI1lFXm9lcTw4TzJVU1VnW1JUclVHSFY/JjtfMihZSWFwOShHZ1VHSmBiSi8ra2twRTspKWFvdHBUIV9bOSNANDdLJS90QWVpUF82PERjMDdYVSsiSWk0KGxcJT08UWRSPHQ1cjZPcVNIPjBOMTc2JzdxQj1tck9GakZsJU8vWUJQNlAvXydDbFExY1cpcEMiNWQyQUduWSxETUpfPjYsQGcoRiFxZ1JVcCZKKDtHXEhFV0QkYytYN0FaJ2U4SkIyKyMzMVdHW0ExVWUuWlhSaFRuTWo+VGRQRWlzMGNYMlYoUDtmYVBFJUdWSz5qUzhsRzxgY0M7TWkpRVFqQFtCU0IlQXE0XW4zTDJKbV10Ll8rOSc5Wk9WJF5GWCRMb0QuZVBdQGdOLkgmJzlSXE1WTy80JTRVJ0FccXUiWHFmMzlzLSteVHBHWmxVLTlNfj5lbmRzdHJlYW0KZW5kb2JqCjIzIDAgb2JqCjw8Ci9GaWx0ZXIgWyAvQVNDSUk4NURlY29kZSAvRmxhdGVEZWNvZGUgXSAvTGVuZ3RoIDE3MTAKPj4Kc3RyZWFtCkdhc2FvZ01ScmgnUlw1LiomcVlAWCZkZl9wZjhWLmpuS0lgT1knW01NUDteOU1ML0I1YCRNbDw9LE1sX0kiczYqbmo/RywkbEJBMGpJRkU7KjRHJjJKJCYiTmJfYVY4UFsoVnBlWVoyNVhtWUwtTlNgLkdrZilUWTYrLFMrWEw/W3IqLVVTVkYkY1hsRyk4RDJxRDh0Olxqck9BMWhxREpCRFpBVW9BXWJxTzgkRUheMWwtZEQwPUhXOS1cSlNWRG9mPTkuLSw/JVBrPCdrdWI6XUhxI1piUT9IVGpwQTEtSmxHTWBebkUwLl5WdUdoMnBBL0FXPS9jZyxULkJkN1ElQ05zcDxfNE9fPjtNYzVbJnJYNlo2WTlbNm9HYWoxXDI9TkojRDo1MCVgRjkxODAsLi9fUiE5J0ZtRG5dMENyaFQmXC5dO1onMDVRLFFvWVhlKGZQKkctZC5DSS9JcCVaUy4sJlwiX2tcL0clcUhfb1dybG8mXUlTWF9fcFtUV2ROQk9uYShiO2AqUCgnMzVSQXMpNW42Y3R0UDhdR1hkYTY2bURgI2ckYCU9QEAzJGlEaHJldGstOi5cNGxdLEooMkVrK3QpR0QiajxJQ1NiPXBGL2VoalsvaiJdZWJpJiM4MHFnZEtGLC5ZQTpCUjpWMEVURGxwamBUZGVGPloxbCRLL3VWSWI6clA0UV5bImcxKkBYcE9fMzZRJWZlVU03MUZlb2NaT21DQGUmb280KDt1RjEnQjAiIzJLUzBja0M9W1AjJF1gU045UjFHOmdsdHFiLURhXStoVVQrVGVvTDVvLzstOlBPSjUxWWdcJGVlUEtkXTIvLUkrUCJXQT1LaEVHKkkvVz0nQGdeKnItSlpoMG8pWSROO1clYG86am10bT5RZVY0PEFDRUxDZTU3WjpUUko3PkY3SC9CODtHTUU/UT1CJXBmT0RQOFFJInFJKzs4TDk2KHVIbzNZKXFhQiQhalZeTEhMTHBQbVYwVG9sbSMyQ2InTkVAUDA1WjdyJyNbLEcnYzlsMWUzLHM/NnQuLDlKN2tRcTNgcnMxb0VJN3JCW0I3LUlqZ043ImZPcjRwOigjVEdyTF0qbiEsPzo2cENJZ2dkIXVZYDFsZGI7VS5cMDZgYSRHcHJRLEVPVlkhLERALHQhcVo/Ly5TY2o/QVZHSCFJNW0rL11XLEhqZ11pIXQnIlpMYEBQZzA0Ol4sbDdrQS1nRWIrX040LGs8UXJaNFdqPzBJLlhfZlg2WmVdZk5OZ2ZnRkQlNSNrOjVVaWpCTHRgIzRuNlZuTmU6aF4/XmlTPksrP144IUFvYFwsVU5abCdfcjtsRSxHbGFKLkhwMlhrRzo+aSxySCRlSEMkKEMrQiosRj0oY29GNzZNUiI+dSVQXmFpWVxtQyg2SEwrSW1SYCJhVlRhXUlpUDY+XDNuQyc2TFRdZ2YvIUIqcDhgWmskbmlZIitRJlY/cFA3PilpUTUvXGhXZF1VUjRpPClrbj5PS28ocGhAZlBLMWBvRmVTdWFVXUxudFErPUdYSCdNbUFyIlJVUjg/T1VOQjBAX2AwSCskUkVgLFRuPFc2M1NyWkBvMVpQYWU4KVNIZiU9aGpeYVpwNlddaE5zXiJpRj5yY09WUC4pLDk8RkQuPyQsViQ7SiZaYUNbOGdkbThrIzI1JFpjNzM0bkNVJm4xI2dXWlNvQ2d1MWJKSzUzLDBIQit0KFtZSyFTMkk9a1pFMGNLNyRvVUYnJFo4LDBbU1NwMUw8ZzovVGltOChJcUdiKF9rbjJKMG5EXnAzTG0hYTkpbWNZUyhRWS0uTHJhPkdIRlBOJ2ooZ2tkUFo6bjlSPlNxSl4hXj8qSj9hJ1lzSkZeSzlHMUZxM0N0Z2FmNXNaNyxATi5BblJsLTBtLzBMRSE4ZVBcWCNeIVJtIy9nZmJCc09KIldQJUxfVDdaMUo1V0ptQVZrMnI4NVEtYEdqaWE7YEZFLid1RG5sW2NZdUhLPDQvbGFEVktoPlRTaz5BTytzYzUwbSpFT0pyPmBnX29iYk1HQT5SUiFLPCY/Nj8qOG4wYGVRWyFYOmYscUZBQGtdZVozPGcvLk5bbihSOiQzPnJRLk1fSm9nLFwiNWRvZjRDXyooRy5CNm1CYFE8X248SyFVTChXc109bi9lVHNeKDJXXDBjLDtWYidMO1BtUTBDVlcjUkRMWyphXVdCLVEzbm5ROGxvYEo6ZiwpV09MRWFWTFBScU5vXC1Fam4qZUhCbGo4cnJEXTZMRT9+PmVuZHN0cmVhbQplbmRvYmoKeHJlZgowIDI0CjAwMDAwMDAwMDAgNjU1MzUgZiAKMDAwMDAwMDA3MyAwMDAwMCBuIAowMDAwMDAwMTI0IDAwMDAwIG4gCjAwMDAwMDAyMzEgMDAwMDAgbiAKMDAwMDAwMDMxNCAwMDAwMCBuIAowMDAwMDAwMzkxIDAwMDAwIG4gCjAwMDAwMDA1ODYgMDAwMDAgbiAKMDAwMDAwMDc4MSAwMDAwMCBuIAowMDAwMDAwOTc2IDAwMDAwIG4gCjAwMDAwMDExNzEgMDAwMDAgbiAKMDAwMDAwMTM2NiAwMDAwMCBuIAowMDAwMDAxNTYyIDAwMDAwIG4gCjAwMDAwMDE3NTggMDAwMDAgbiAKMDAwMDAwMTk1NCAwMDAwMCBuIAowMDAwMDAyMDI0IDAwMDAwIG4gCjAwMDAwMDIzMjEgMDAwMDAgbiAKMDAwMDAwMjQyNiAwMDAwMCBuIAowMDAwMDA0NTYzIDAwMDAwIG4gCjAwMDAwMDY2NzUgMDAwMDAgbiAKMDAwMDAwODcxNiAwMDAwMCBuIAowMDAwMDEwMzc3IDAwMDAwIG4gCjAwMDAwMTE4MzkgMDAwMDAgbiAKMDAwMDAxMzQyOCAwMDAwMCBuIAowMDAwMDE1NDQ1IDAwMDAwIG4gCnRyYWlsZXIKPDwKL0lEIApbPDMxYjBkNWI2N2Y4NzEzZmIzYTQ4YWM0ZjExN2E0ZDg4PjwzMWIwZDViNjdmODcxM2ZiM2E0OGFjNGYxMTdhNGQ4OD5dCiUgUmVwb3J0TGFiIGdlbmVyYXRlZCBQREYgZG9jdW1lbnQgLS0gZGlnZXN0IChodHRwOi8vd3d3LnJlcG9ydGxhYi5jb20pCgovSW5mbyAxNCAwIFIKL1Jvb3QgMTMgMCBSCi9TaXplIDI0Cj4+CnN0YXJ0eHJlZgoxNzI0NwolJUVPRgo="
      },
      "docs/Ark-OS-NOA Full Rebuild Engineering Plan.docx": {
        "language": "binary",
        "encoding": "base64",
        "code": "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"
      }
    },
    "next": "noa-part4.json"
  }
}